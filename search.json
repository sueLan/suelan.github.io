[{"title":"Exploring Swift Concurrency","url":"/2022/11/06/20221106-swift-concurrency/","content":"\n> Since Apple introduce Swift Concurrency, I've been always having an idea to write something about swift concurrency. But then I got a new job, and work has taken quite a lot of my time and energy; thus hardly i can find spare time to write something interesting.\n\n\nIn iOS development realm, we have several ways to write asynchronous code and parallel code.  People usually use `closures` and `completion handlers` to write asynchronous code. But too many closures and completion handler make code become more complicated. \n\nHere is an example from WWDC, it is to fetch thumbnail from cloud. \n\n```swift\nfunc fetchThumbnail(for id: String, completion: @escaping (UIImage?, Error?) -> Void) {\n    guard let url = URL(string: \"https://itunes.apple.com/search?term=taylor+swift&entity=album\") else {\n        completion(nil, NSError(domain: FetchUrlDomain, code: -1))\n        return\n    }\n    \n    let task = URLSession.shared.dataTask(with: url) { data, response, error in\n        if let error = error {\n            completion(nil, error)\n        } else if (response as? HTTPURLResponse)?.statusCode != 200 {\n            completion(nil, NSError(domain: FetchUrlDomain, code: -4))\n        } else {\n            guard let image = UIImage(data: data!) else {\n                completion(nil, NSError(domain: FetchUrlDomain, code: -2))\n                return\n            }\n            image.prepareThumbnail(of: CGSize(width: 40, height: 40), completionHandler: { thumbnail in\n                guard let thumbnail = thumbnail else {\n                    completion(nil, NSError(domain: FetchUrlDomain, code: -3))\n                    return\n                }\n                \n                completion(thumbnail, nil)\n            })\n        }\n    }\n    task.resume()\n}\n```\nWe can see some problem from the above codes snippet: \n\n1. Pyramid of doom\n- deeply-nested closures make the code difficult to read and keep trace of.   \n2. Error handling \n- callbacks make error handling difficult and verbose. There are 6 places in a single function to handle the error \n3.  Conditional execution is hard and error-prone\n- After get data from cloud, it has to go to different condition branch to handle different situation\n4. Many mistakes are easy to make\n- simply returning without calling the correct completion-handler block. When forgotten, it is hard to debug \nYou can check out more problems for using too many closures and completion handlers here [proposal-async-await.md](https://github.com/apple/swift-evolution/blob/main/proposals/0296-async-await.md#motivation-completion-handlers-are-suboptimal)\n\nAs we've seen so many problems from closures and completion handlers. Apple introduce asynchronous function or so-called async-await to Swift. In fact, async/await pattern has been embraced in many languages\n\n> F# added asynchronous workflows with await points in version 2.0 in 2007\n> Microsoft released a version of C# with async/await for the first time in the Async CTP (2011). \n> Haskell lead developer Simon Marlow created the async package in 2012.[9]\n> Python added support for async/await with version 3.5 in 2015\n> TypeScript added support for async/await with version 1.7 in 2015.\n> Javascript added support for async/await in 2017 as part of ECMAScript 2017 JavaScript edition.\n> Rust added support for async/await with version 1.39.0 in 2019\n> C++ added support for async/await with version 20 in 2020\n> Swift added support for async/await with version 5.5 in 2021, adding 2 new keywords async and await.\n\nAfter applying async/await to `fetchThumbnail` function, it becomes far more concise.  \n```swift\nfunc fetchThumbnailV2(for id: String) async throws -> UIImage {\n    guard let url = URL(string: \"https://itunes.apple.com/search?term=taylor+swift&entity=album\") else {\n        throw NSError(domain: FetchUrlDomain, code: -1)\n    }\n    \n    let(data, response) = try await URLSession.shared.data(for: URLRequest(url: url))\n    guard (response as? HTTPURLResponse)?.statusCode == 200 else {\n        throw NSError(domain: FetchUrlDomain, code: -4)\n    }\n    let image = UIImage(data: data)\n    guard let thumbnail = await image?.byPreparingThumbnail(ofSize: CGSize(width: 40, height: 40)) else {\n        throw NSError(domain: FetchUrlDomain, code: -3)\n    }\n    return thumbnail\n}\n```\n\n\n## What is async/await function\n\n### define async function: \n`async`: enable a function to suspend. \n - The thread wont' be blocked and other tasks can run on it when current func is suspended.\n`await`: marks where an async function may suspend execution;\n -  indicate `suspension point` in an async function where it has to give up its thread. \n - the thread is free to execute other work \n - suspend its caller too, so the caller should be async too \n - Onced awaited call completes, execution resumes after the await. \n\nFunction types can be marked explicitly as async, indicating that the function is asynchronous. \n```swift \nfunc asyncFuncA() async -> [String] {\n    return xxx; \n}\n\nfunc ayncFuncB(param: String) async -> [String] {\n    let result =  await asyncFucA() // ayncFuncB suspended and give up control of the trhead. System come to schedule task executions on the thread  \n    return result                   // ayncFuncB resumes and return result to its caller    \n}\n```\n\n```\n\nthread: -->Fun B              -->FuncB\n        (await)               (resume)\nsystem:         --------------\n                  (schedule)\n\n```\n\n\nBesides, a closure can have async function type.\n```swift\n{ () async -> Int in\n  print(\"here\")\n  return await getInt()\n}\n```\n\n## How to use  async/await function\n\n### call async function \n\n1. call it in asynchronous context, or you would get the following error if you don't want to do so\n```\nerror: `async` function cannot be called from non-asynchronous context\n```\nasynchronous context could be: \n- asynchronous function body \n- asynchronous clossures \n- ashnchronous `Task` body\n\n2. write `await` in front of the call to mark the possible suspension point\n```swift \n    let result =  await asyncFucA() // ayncFuncB suspended and give up control of the trhead. System come to schedule task executions on the thread  \n```\n\nThe possible suspension points in this piece of code marked with `await` indicate that the current piece of code might pause execution while waiting for the asynchronous function or method to return. \n\n> This is also called `yielding the thread` because, behind the scenes, Swift suspends the execution of your code on the current thread and runs some other code on that thread instead\n\n\n### call async function in a sync context \n\n`async` enables a function to suspend - when a function suspends itself, it suspends its callers too. So its callers must be `async` as well. When you want to call an async function from a sync function, you can use an `async task` function. An async task packages up the work in the closure and sends it to the system for immediate execution on the next available thread, like the async function on a global dispatch queue.\n\n```swift\nasync {\n    await ayncFuncB()\n}\n```\n\n### use asynchronous sequences\n> [wwdc: Meet AsyncSequence](https://developer.apple.com/videos/play/wwdc2021/10058/)\nbasically, AsyncSequence is just a sequence, but async \n\n A `for-await-in loop` potentially suspends execution at the beginning of each iteration, when it’s waiting for the next element to be available. \n \n```swift\nextension URL {\n  struct Lines: AsyncSequence { /* ... */ }\n  func lines() async -> Lines\n}\n\nfor try await line in myFile.lines() {\n // doing something\n}\n```\n\n Although different from synchronous `for-in-loop`, `for-await-in loop` potentially give up thread control at the beginning of each iteration.But when using asynchronous sequence, elements in the asynchronous sequence is executed one after another. Besides, an error might occurs at each iteration, and you can use ``for-try-await-in loop` \n\n This time, Apple bring a bunch of new APIs leveraging asynchronous sequence \n\n```swift\n// bytes: AsyncBytes in FileHanlde\nfor try await line in FileHandle.standardInput.bytes.lines {\n    // ...\n}\n```\n\n``` swift\n\nlet (bytes, response) = try await URLSession.shared.bytes(from: url)\n```\n\n```swift\nlet notification = await NotificationCenter.default.notifications(named: .NSSystemTimeZoneDidChange).first(where: { noti in })\n```\n\nyou can use your own types in a for-await-in loop by adding conformance to the \n- [Sequence](https://developer.apple.com/documentation/swift/sequence)\n- [AsyncSequence](https://developer.apple.com/documentation/swift/asyncsequence)\n\nCheck out an example from [proposals-asyncsequence](https://github.com/apple/swift-evolution/blob/main/proposals/0298-asyncsequence.md#proposed-solution) \n\n\n## Concurrency Structure\n> Structured concurrency provides a paradigm for spawning concurrent child tasks in scoped task groups, establishing a well-defined hierarchy of tasks which allows for cancellation, error propagation, priority management, and other tricky details of concurrency management to be handled transparently.\n\n\n### async let bindings\n\nasync-let \n-  left side of the `=`, it defines a local constant, a placeholder waiting to be initialed \n-  right side of the `=`, initializer expression is evaluated in a separate, concurrently-executing child task. After child task is completed, fullfill the value or propogate error\n\n![][./let-binding.png]\n\n\nWhen trying to call asynchronous functions in parallel, async-let will come to help. For example: \n\n```swift\nlet firstPhoto = await downloadPhoto(named: photoNames[0])\nlet secondPhoto = await downloadPhoto(named: photoNames[1])\nlet thirdPhoto = await downloadPhoto(named: photoNames[2])\n\nlet photos = [firstPhoto, secondPhoto, thirdPhoto]\nshow(photos)\n```\n\n This piece of code has some drawbacks: although the download is asynchronous and lets other work happen while it progresses, only one call to downloadPhoto(named:) runs at a time. Each photo downloads completely before the next one starts downloading.\n\n\n To call an asynchronous function and let it run in parallel with code like this: \n\n```swift\nasync let firstPhoto = downloadPhoto(named: photoNames[0])\nasync let secondPhoto = downloadPhoto(named: photoNames[1])\nasync let thirdPhoto = downloadPhoto(named: photoNames[2])\n\nlet photos = await [firstPhoto, secondPhoto, thirdPhoto]\nshow(photos)\n```\n\nWhile using async let binding, 3 child tasks created and executed parellely while not blocking current thread and they run parallelly, and fullfill `firstPhoto` \n, `secondPhoto` and `thirdPhoto` later. After 3 constants all fullfiled values, it goes to show photos.\n\n```\n-> download firstPhoto --------------   |\n---> download secondPhoto -----------   | \n-------> download downloadPhoto -----   | \n                                        |  await --> show photos\n```\n\n### Task \n\nA task is the basic unit of concurrency in the system. Every asynchronous function is executing in a task.\n\n- A task can be in one of three states:\n\n```\n    suspended      <--->       running    --->  completed\n```\n\n- task operation\n    - [cancellation](https://developer.apple.com/documentation/swift/task/cancel()), task will not stop immediately after cancel  \n    \n\n- `Child tasks`: Each task can create and have child tasks. Child tasks inherit some of the structure of their parent task, including its priority, but can run concurrently with it.\n\n![](./task_parent.png)\nIn this picture, `fetchOne` task create two child tasks, data and metadata by using async-let binding, construct a well-structured task tree. \n\n#### Structured Task \n\n> [Explore structured concurrency in Swift](https://developer.apple.com/videos/play/wwdc2021/10134)\n\n- Parent task can be completed only after all child tasks completed \n![](./task_parent_tree_complete.png)\n\n- one child task failed, an error throw; Swift automatically marks another task as cancelled \n![](./task-tree.png)\n\n- when a task is called, it won't be stoped immediately, just marked the result of it is unneeded. After data task is cancelled, its subtasks will be cancelled as well.  \n![](./task_tree_cancel.png)\n- use task group and get result from task group \n![](./task_group.png)\n\n\n## Actor\n> - [actor proposal](https://github.com/apple/swift-evolution/blob/main/proposals/0306-actors.md) \n- [Protect mutable state with Swift actors](https://developer.apple.com/videos/play/wwdc2021/10133/)\n\n### Basic\n\n- provide a way to solve the data race in Swift concurrency programming \n- similar capabilities to structs, enums, and classes\n- it is reference type \n- Unlike classes, actors allow only a single thread to access their mutable state at a time, which is called as `data isolation`, enforced statically by the Swift compiler through a set of limitations on the way in which actors and their instance members can be used,\n\n```swift\nactor Counter{\n    var value = 0\n    func increment() -> Int {\n        value += 1\n        return value\n    }\n    \n    func resetSlowly(to newVlaue: Int) {\n        value = 0\n        for _ in 0..<newVlaue {\n            increment()\n        }\n    }\n}\n\nlet counter = Counter()\n\nfor _ in 0...100 {\n    Task.detached {\n        print(await counter.increment())\n    }\n}\n\n```\n\nBecause the actor allows only one task at a time to access its mutable state, if code from another task is already interacting with the logger, this code suspends while it waits to access the property.\n\n### User case \n\nThis is a common pattern: a class with a private queue and some properties that should only be accessed on the queue. We replace this manual queue management with an actor class:\n\n```swift\nactor class PlayerRefreshController {\n  var players: [String] = []\n  var gameSession: GameSession\n\n  func refreshPlayers() async { ... }\n}\n```\n\n#### Things to note about this example:\n- Declaring a class to be an actor is similar to giving a class `a private queue` and `synchronizing all access to its private state through that queue`.\n- Because this synchronization is now understood by the compiler, you cannot forget to use the queue to protect state: the compiler will ensure that you are running on the queue in the class's methods, and it will prevent you from accessing the state outside those methods.\n- Because the compiler is responsible for doing this, it can be smarter about optimizing away synchronization, like when a method starts by calling an async function on a different actor.\n\n### Sendable types \n> [senable type roposal](https://github.com/apple/swift-evolution/blob/main/proposals/0302-concurrent-value-and-concurrent-closures.md)\n\n- safe to share concurrently, each copy independent\n    - Value types\n    - Actor types\n    - Immutable classes\n    - internally-synchronized class \n    - @Sendable function types\n\n\n## Behind the scenes\n\n> [Swift concurrency: Behind the scenes](https://developer.apple.com/videos/play/wwdc2021/10254/)\n\nThe widely-used GCD has its darkside like excessive concurrency, like thread explosion, sheduling overhead due to too many threads and memory overhead caused by blocked threads holding stacks.\n\n**Excessive context switch**: CPU runs less efficiently because CUP clock wasted in context switch instead of executing real task. \n![](./thread_context_switch.png)\n\n- [Building Responsive and Efficient Apps with GCD](https://developer.apple.com/videos/play/wwdc2015/718/)\n- [Modernizing Grand Central Dispatch Usage](https://developer.apple.com/videos/play/wwdc2017/706)\n \nSwift concurrency leverage [Continuations](https://github.com/apple/swift-evolution/blob/main/proposals/0300-continuation.md) to get task's continuation which suspends the task, and produce code that synchronous can then use a handle to resume to task. \n> [CheckedContinuation](https://developer.apple.com/documentation/swift/checkedcontinuation)\nA mechanism to interface between synchronous and asynchronous code, logging correctness violations.\n\nSo, there is no thread switching cost but only function calls. And the concurrency runtime only creates as many threads as device's CPU cores and maintain cooperative thread pool to avoid thread explorsion and excessive context switches. \n\n\n ### Swift Runtime \n\n In one thread, when a function is called, a function frame will be allocated and put into the thread's stack. A function frame basically a chunk of memory to store local variables, return address. When that function finishes, function frame's pop from the stack.\n\n![](./function_stack.png)\n\nBut in async function, things work a little bit different. \n\n![](./async_function.gif)\n\nIn this short video, there is an example \n\n```\n\nfunc add(_ newArtibles: [Articles]) async throws {\n    let ids = try await database.save(newArtibles, for:self)\n    for(id, article) in zip(ids, newArtibles) {\n        articles[id] = article\n    }\n}\n\nfunc updateDatabase(...) async {\n    await feed.add(articles)\n}\n\n```\n\nWhen `updateDatabase` hits the thread suspend point, its function frame is put in the heap and then `add` function frame added to the stack\n ![](./async_heap.png)","categories":["iOS"]},{"title":"How to use SignPost","url":"/2021/10/02/20211001-signpost-custome-instrument/","content":"\n`SignPost` is part of the `os_log` family delivered by Apple for iOS10 and above. It allows developers to place performance-focused time markers which can be displayed in Instrument for visualization. Or we can say, `SignPost` APIs enable us add some lightweight instrumentation to code for collection and visualization by performance analysis tooling. Now, here comes two basic concepts in `os_signpost` APIs. \n\n- `intervals `:  interesting periods of time. `os_signpost` interval begin and end matching  matching begins and ends is restricted to single threads.\n- `events`: single points in time\n\n## Instruments\nAs I said, we can use it with signpost logs to  \n- Aggregate and analyze signpost data\n- Visualize activity over time\n\nHere comes a piece of code demonstrating how to use `OSLog`   \n\n```swift\nimport os.signpost\n\n// 1. create a container of related log messages. Each log contains a subsystem and a category, which you define and helpful when sorting and displaying them. Can see category in console.log  \nlet refreshLog = OSLog(subsystem: \"com.example.your-app\", category: \"RefreshOperations\")\n \n// 2. A different signpost name for this different interval\nos_signpost(.begin, log: refreshLog, name: \"Refresh Panel\")\n\nfor element in panel.elements {\n  os_signpost(.begin, log: refreshLog, name: \"Fetch Asset\") fetchAsset(for: element)\n  os_signpost(.end, log: refreshLog, name: \"Fetch Asset\")\n}\nos_signpost(.end, log: refreshLog, name: \"Refresh Panel\")\n \n```\n\n### Signpost Names\n\n- The string literal identifies signpost intervals\n- The name must match at .begin and .end\n\n### Signpost IDs\n\nIntervals with the same log handle and interval name can be in flight simultaneously. Signpost id is needed to correctly match begin signposts with end signposts. So we have to identify each interval with a signpost id. \n\n- Use signpost IDs to tell overlapping operations apart\n- While running,use the same IDs for each pair of `.begin` and `.end`\n\n```swift\nlet spid = OSSignpostID(log: refreshLog)\nos_signpost(.begin, log: refreshLog, name: \"Fetch Asset\", signpostID: spid)\n\nos_signpost(.end, log: refreshLog, name: \"Fetch Asset\", signpostID: spid)\n```\n\n### Making Signpost IDs\n\n```swift\nlet spid = OSSignpostID(log: refreshLog, object: element)\n```\n\n- Signpost IDs are process-scoped\n- Making from object is convenient if you have the same object at .begin and .end\n\n## Organizing Signposts: A Hierarchy\nYou can use `subsystem`, `category` and `name` to organize signposts. \n```swift\nlog = OSLog(subsystem: \"com.example.your-app\", category: \"RefreshOperations\")\nos_signpost(.begin, log: log, name: \"Fetch Asset\", signpostID: spid)\n```\n\n![image-20210108175744504](image-20210108175744504.png)\n\n### Custom Metadata in Signpost Arguments\n\nYou can add more data when calling `os_signpost` \n- Add context to the .begin and .end\n- Pass arguments with os_log format string literal\n- Pass many arguments with different types\n- Pass dynamic strings\n- The format string is a fixed cost, so feel free to be descriptive!\n\n```swift\nos_signpost(.begin, log: log, name: \"Compute Physics\", \"%d %d %d %d\",\nx1, y1, x2, y2)\n```\n\n### Signpost Events\n\n```swift\nos_signpost(.event, log: log, name: \"Fetch Asset\",\n```\nTo add events between `.begin` and `.end`. They will become `Points of Interest ` displayed in instrument later. \n\n## Signposts Are Lightweight\n\n- Built to minimize observer effect\n- Built for fine-grained measurement in a short time span\n\n## Enabling and Disabling Signpost Categories\n\n```swift\nOSLog.disabled\n```\n\n```swift\n \nlet refreshLog: OSLog\nif ProcessInfo.processInfo.environment.keys.contains(\"SIGNPOSTS_FOR_REFRESH\") {\n   refreshLog = OSLog(subsystem: \"com.example.your-app\", category: \"RefreshOperations\") \n} else {\n   refreshLog = .disabled\n}\n```\n\n## Signposts in C\n\nWell, if you want to use `os_signpost` in C, Apple also provides a series of APIs for C. \n\n![image-20210108180102653](image-20210108180102653.png)\n\n\n### Points of Interest \n\nWe may want to focus on timing of some important events. We can promote these events by using `points of interest`  as the category of `OSLog` .  Instrument then will look for this special category and display it in a separated sections. \n\n![image-20210117174557365](image-20210117174557365.png)\n\nWe later can see these events displayed  and correlate these events with other performance data.  \n\nIn non-swift source code, we can use `OS_LOG_CATEGORY_POINTS_OF_INTEREST`.  And use `os_signpost(.event, ...)` to emit import events. \n\n```\n#ifndef __swift__\n#define OS_LOG_CATEGORY_POINTS_OF_INTEREST \"PointsOfInterest\"\n#endif\n```\n\n![image-20210117224415205](image-20210117224415205.png)\n\nIn Instrument, we can use `Points of Interest` template. \n\n## How to use it in Instrument \n\nAfter opening the instrument, we can chose `Logging template` \n\n![image-20210117172127316](image-20210117172127316.png)\n\nOr we can add `os_signpost`  here\n\n![image-20210117170856013](image-20210117170856013.png)\n\nWhat I like most in Instrument is that we can always zoom in and zoom out to select the region we interest. \n![](demostration.gif)\n\n### Analysis time of the intervals \n\nChoose `summary:Intervals` . We can see the summary of intervals. The count, duration, min duration, average duration, maximum duration of each signpost we collects. \n\n![image-20210117230659066](image-20210117230659066.png)\n\n### Analysis the metadata \n\n`Summary:Metadata Statistics` \n\n#### Analysis Points of Interest \n\nBy choosing the `Points of Interest` section, we can see the points of interest and its meta data. Besides, we can use points of interst together with other section, like Time Profile to check how is the performance like when these importance events happen. \n\n![image-20210117230047705](image-20210117230047705.png)\n\n## Options \n\nThe default recording mode is `immediate`, which means it records all the signposts immediately. This could bring overhead if your app emits thousands of signposts per second.  However, we can still work around that by changing to window mode and only collecting data for the last 5 seconds.  It is very useful to collect data to analyze stutters. \n\nSteps: \n\n1. long press the record button and select recording options \n\n   ![image-20210117182658245](image-20210117182658245.png)\n\n2. Expand `Grobal Options`\n\n![image-20210117182537413](image-20210117182537413.png)\n\n3. Choose `Last`, filling 5 seconds. \n   ![image-20210117172616368](image-20210117172616368.png)\n\nWhen recording in `Windowed Mode` , the Instrument shows a blank white screen with a hint `Recording in Windowed Mode`.\n\n![image-20210117224703454](image-20210117224703454.png)\n\nWhen stoping recording, the Instrument showing a progress view and analyzing the collected data. \n\n![image-20210117224757983](image-20210117224757983.png)\n\n## Ref\n\n- [Apple doc/logging](https://developer.apple.com/documentation/os/logging)\n- [WWDC/Measuring Performance Using Logging](https://developer.apple.com/videos/play/wwdc2018/405/)","categories":["iOS"]},{"title":"react-native-instrument","url":"/2021/08/13/20210813-react-native-instrument-profile/","content":"\n<!--more-->\n\nSometimes, you may encounter heavy performance issue in RN page, like laggy and unresponsive pages. And you do want to take a deep look at how many data are passed through JSBridge and what's going on there. You may found some people leverage `spy` function in `MessageQueue.js` to check the traffic volume through JSBridge. [Blog here](https://callstack.com/blog/react-native-how-to-check-what-passes-through-your-bridge/ ). It looks cool and helpful. However, in real life, you could see the your app performance is dragged down dramatically, even totally unresponsive when using this debug tool. So I was trying to find out a more efficient way to monitor traffic volume in JS bridge. Luckily, I saw a native performance monitoring logger inside react native framework, which appears in almost every crucial points in the workflow of JS-Native method calling. Then, I realized, maybe, I can use it to achieve the goal to spy bridge messages efficiently since it is in C++ realm and I can store all the data I collect in memory or use `SignPost`  to make data visualized in Instrument. Finally, I made [react-native-bridge-instrument](https://github.com/sueLan/react-native-bridge-instrument).  \n\n## NativeModulePerfLogger in React Native\n\nHere, I gonna talk about how I implement it. In some crucial classes in react-native, you can see `NativeModulePerfLogger` is used to collect execution data. For example, in `RCTNativeModule:invokeInner` function, which is to dispatch function calling from JS to native, there are stubs using  `NativeModulePerfLogger`  in namespace `BridgeNativeModulePerfLogger`.\n\n```c++\n if (context == Async) {\n    BridgeNativeModulePerfLogger::asyncMethodCallExecutionStart(moduleName, methodName, (int32_t)callId);\n    BridgeNativeModulePerfLogger::asyncMethodCallExecutionArgConversionStart(moduleName, methodName, (int32_t)callId);\n  }\n  \n  if (context == Sync) {\n      BridgeNativeModulePerfLogger::syncMethodCallExecutionStart(moduleName, methodName);\n    } else {\n      BridgeNativeModulePerfLogger::asyncMethodCallExecutionArgConversionEnd(moduleName, methodName, (int32_t)callId);\n    }\n    \n  if (context == Sync) {\n      BridgeNativeModulePerfLogger::syncMethodCallExecutionEnd(moduleName, methodName);\n      BridgeNativeModulePerfLogger::syncMethodCallReturnConversionStart(moduleName, methodName);\n    } else {\n      BridgeNativeModulePerfLogger::asyncMethodCallExecutionEnd(moduleName, methodName, (int32_t)callId);\n    }\n```\n\nIf you look into `BridgeNativeModulePerfLogger`, it basically calls functions in  `NativeModulePerfLogger`  to collect data. Basically,  `NativeModulePerfLogger` is a virtual class, a platform-agnostic interface to do performance logging for native modules and tubomodules.  We can inherit  `NativeModulePerfLogger` and implement all its pure virtual functions. These functions are for initializing Native Module object, JS require , sync method calls, async method calls,pre-processing async method call batch, async method call execution etc. \nYou may want to check out more details about these functions in the source file in [Github](https://github.com/facebook/react-native/blob/57aa70c06cba3597725f7447943613e8905ae11d/ReactCommon/reactperflogger/reactperflogger/NativeModulePerfLogger.h#L18). With the help of `NativeModulePerfLogger`, we can inject our own logger implementation, collecting performance data without modifying react-native SDK heavily.  \n\n## SignPost\n\n`os_signpost` is delivered by Apple for developers to collect performance data for visualization on iOS 10 and above. It allows you to place markers which can be displayed in instrument so that it is easier for developers to discern where the bottleneck is. The good is that Apple also provides C based APIs so I can basically use them in my c++ class which implements  `NativeModulePerfLogger`. \n\n![image-2021010`8180102653](image-20210108180102653.png)\n\nI finally wrote [react-native-bridge-instrument](https://github.com/sueLan/react-native-bridge-instrument) to combine the power of  `NativeModulePerfLogger` and `SignPost` and help your monitor function callings happening in JS bridge much more efficiently.\n\nFor example, I place a markers when an async method calling starts; then place another related marker at the moment when this method calling ends. Instrument will help us wrap up all these data and visualize them for us well. \n\n```c++\nvoid Cxx ::asyncMethodCallArgConversionStart(\n                                                    const char *moduleName,\n                                                    const char *methodName) {\n  os_signpost_interval_begin(async_method_call_logger, OS_SIGNPOST_ID_EXCLUSIVE, function_name(__func__), \"%s %s\", moduleName, methodName);\n};\n\nvoid CxxNativeModulePerfLogger::asyncMethodCallArgConversionEnd(\n                                                    const char *moduleName,\n                                                    const char *methodName) {\n  os_signpost_interval_end(async_method_call_logger, OS_SIGNPOST_ID_EXCLUSIVE, function_name(__func__), \"%s %s\", moduleName, methodName);\n};\n```\n\n## How to use it\n\nBecause I implemented `CxxNativeModulePerfLogger` in C. Basically, you have to write a method in `mm` file to use these C++ functions.\n\n```\n#include <ReactNativeBridgeInstrument/CxxNativeModulePerfLogger.h>\n// make sure `CXXFLAGS += -std=c++14` or 14 above in your Xcode building settings\n#include <memory>\n\n- (void)initializeInstrument\n{\n  facebook::react::CxxNativeModulePerfLogger logger = facebook::react::CxxNativeModulePerfLogger();\n  facebook::react::BridgeNativeModulePerfLogger::enableLogging(std::make_unique<facebook::react::CxxNativeModulePerfLogger>(logger));\n}\n\n```\n\nTo test it, I integrate these `CxxNativeModulePerfLogger` to [`RNTester`](https://github.com/facebook/react-native/tree/main/packages/rn-tester) and run `RNTester` locally, then use Instrument to collect performance data. \n\n1. Open the instrument,  choose `Blank` template in Instrument ![image-20210926173249306](https://tva1.sinaimg.cn/large/008i3skNgy1guu5vkkpu7j61880aemyj02.jpg)\n\n2. Then , add `os_signpost`  to current template,  and start recording. \n\n![image-20210926173031427](https://tva1.sinaimg.cn/large/008i3skNgy1gv18fu3r64j628009c40202.jpg)\n\n3. pay attention to our customed logger Volume. There are 4 parts, \n\n- `async_method_call`:  collect data for asynchronous methods running through JSBridge\n- `js_require`  : used to calculate time interval to initialize modules \n- `module` : used to calculate time interval to create `RCTModuleData` \n- `sync_method_call` :  collect data for synchronous methods running through JSBridge\n\n![image-20210926174136104](https://tva1.sinaimg.cn/large/008i3skNgy1gv18fv7bi9j61ht0u0wjn02.jpg)\n\nFor example, after scrolling a FlatList, I checked `async_method_call` volume. I saw `createView` , `setChildren` and `managedChildren` mthods  in `UIManager`  are called frequently. In `1.91` seconds, `createView` are called 2886 times, taking up `1.16` seconds. Although the average duration for this method is about `402.27us` , which may look like not a big deal; considering its high frequency, this method finally tops first in our analysis panel. \n\n![image-20210926175209847](https://tva1.sinaimg.cn/large/008i3skNgy1gv18hjuyerj61jk0u0ti402.jpg)\n\nIn the `summary` panel,  you can also see `total`, `min`, and `avg`  time intervals for any other specific method. Besides, you may would like to check the time interval to load module data. \n\n![image-20210926180112597](https://tva1.sinaimg.cn/large/008i3skNgy1gv18hn21d0j61g70u0agn02.jpg)\n","categories":["iOS"]},{"title":"EXC_BREAKPOINT when forced unwrapping optional in Swift","url":"/2021/07/24/20210724-EXC-BREAKPOINT-in-forced-unwrapping-optional/","content":"\nWhen unforced unwrapping optional in Swift, we will see the exception type in crash report is `Exception Type:  EXC_BREAKPOINT (SIGTRAP)` instead of `EXC_BAD_ACCESS` in Objective-C. That intrigued me. So I did some investigations on it. \n\nAs Mike Ash mentioned in [the article about swift memory layout](https://www.mikeash.com/pyblog/friday-qa-2014-08-01-exploring-swift-memory-layout-part-ii.html)\n\n> Swift optionals are represented just like Objective-C: a plain address when pointing to an object, and all zeroes for nil.\n\nHe gave an example like this, there are 4 variables\n\n```swift\n    let obj: NSObject? = NSObject()\n    let nilobj: NSObject? = nil\n    let explicitobj: NSObject! = NSObject()\n    let explicitnilobj: NSObject! = nil\n```\nBasically, they lay out in memory like this: \n```\n    806040c1957f0000\n    0000000000000000\n    70e440c1957f0000\n    0000000000000000\n```\nOptional variable either contains a valid object address or all zero, so-call `nil` in Swift, which is different from `nil` in OC. While, `0000000000000000` in address space actually is an illegal region to access, iOS system raises an exception if you trying to do so. \n\n### PAGEZERO  in Mach-O Executable \n\n> __PAGEZERO: On 32-bit systems, this is a single page (4 KB) of memory, with all of its access permissions revoked. On 64-bit systems, this corresponds to the entire 32-bit address space — i.e. the first 4 GB. This is useful for trapping NULL pointer references (as NULL is really “0”), or integer-as-pointer references (as all values up to 4,095 in 32-bit, or 4 GB in 64-bit, fall within this page). Because access permissions — read, write, and execute — are all revoked, any attempt to dereference memory addresses that lie within this page will trigger a hardware page fault from the MMU, which in turn leads to a trap, which the kernel can trap. The kernel will convert the trap to a C++ exception or a POSIX signal for a bus error (SIGBUS).      ---- Mac OS and iOS internals \n\nWhen the executable is loaded into memory, the first `4G` memory region for this process is `non-executable, non-writable, non-readable`. Trying to access to this region of memory is illegal. \n\n### Example \n\nI wrote a demo to access  underlying value of an optional  by adding an exclamation point (`!`) to the end of the optional’s name. \n\n```swift\nclass ViewController: UIViewController {\n\n    override func viewDidLoad() {\n        super.viewDidLoad()\n        // Do any additional setup after loading the view.\n        let image = UIImage(named: \"aMissingIcon\")!\n        print(image.size)\n    }\n}\n```\n\n### Analyse Crash Report \n\n### Exception Type \n\n```\nException Type:  EXC_BREAKPOINT (SIGTRAP)\nException Codes: 0x0000000000000001, 0x000000010074596c\nTermination Signal: Trace/BPT trap: 5\nTermination Reason: Namespace SIGNAL, Code 0x5\nTerminating Process: exc handler [12523]\nTriggered by Thread:  0\n```\n\n#### EXC_BREAKPOINT (SIGTRAP)  \n\n`EXC_BREAKPOINT (SIGTRAP)  ` is a trace trap interrupted the process. It gives an attached debugger, if any, a chance to interrupt the process at a specific point in its execution.  So when iOS system raises this exception since my process is trying to `access`  `0x00000000`, Xcode debugger can pause the process and show me this fatal error. \n\n![image-20210217115027905](./image-20210217115027905.png)\n\n> On ARM processors, this appears as `EXC_BREAKPOINT (SIGTRAP). `On `x86_64` processors, this appears as `EXC_BAD_INSTRUCTION (SIGILL)`.\n\nThe Swift runtime uses trace traps for specific types of unrecoverable errors—see [Addressing Crashes from Swift Runtime Errors](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/identifying_the_cause_of_common_crashes/addressing_crashes_from_swift_runtime_errors) for information on those errors. \n\n### Backtrace in Crashed Thread \n\n```\nThread 0 Crashed:\n0   InvalideMemoryDemo            \t0x000000010074596c 0x100740000 + 22892\n1   InvalideMemoryDemo            \t0x00000001007458d8 0x100740000 + 22744\n2   InvalideMemoryDemo            \t0x000000010074598c 0x100740000 + 22924\n```\n\n### Disassembling executable in Hopper \n\nGo to file offset `22892`\n\n![image-20210217121336204](./image-20210217121336204.png)\n\n `BRK` is Breakpoint instruction to cause a Software Breakpoint Instruction exception.\n\nAssembly code \n\n![image-20210217121006944](./image-20210217121006944.png)\n\nCompiler already did optimizations for us.  It will use `cbz` command to compare value in register `x19` with zero. If it is zero, then go to label `loc_10000596c`, which causes a Software Breakpoint Instruction exception.\n\n![image-20210217121336204](./image-20210217121336204.png)\n\nFrom Thread State in in the crash report, we got `x19: 0x0000000000000000`. So here it goes to  `loc_10000596c` to raise `EXC_BREAKPOINT` exception.  That is what we see in the crash report. \n\n![image-20210217121128060](./image-20210217121128060.png)\n\nseems, nothing fancy. To be continue ...\n\n- https://www.mikeash.com/pyblog/friday-qa-2014-08-01-exploring-swift-memory-layout-part-ii.html \n- https://www.objc.io/issues/6-build-tools/mach-o-executables/#sections\n- https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/understanding_the_exception_types_in_a_crash_report#3582420\n- https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/identifying_the_cause_of_common_crashes/addressing_crashes_from_swift_runtime_errors\n- https://docs.swift.org/swift-book/LanguageGuide/TheBasics.html#//apple_ref/doc/uid/TP40014097-CH5-ID330","tags":["Swift"],"categories":["iOS"]},{"title":"Understand How MLeaksFinder and FBRetainCycleDetector automatically detect memory leaks","url":"/2021/03/19/20210319-FBRetainCycleDetector/","content":"\n\n# Background \n\nMemory is important resource in iOS. If a application uses too much memory, exceeding the limit based on the device, the iOS system will kill this App by sending `SIGKILL` signal. Besides, minimizing memory usage not only decreases application’s memory footprint, but also reduces the amount of CPU time it consumes. These are mentioned in several WWDC sessions. \n\n- [WWDC: performance and power optimization](https://developer.apple.com/videos/play/wwdc2011/312/)\n- [Advanced Memory Management Programming Guide](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/MemoryMgmt/Articles/MemoryMgmt.html#//apple_ref/doc/uid/10000011-SW1)\n- https://developer.apple.com/videos/play/wwdc2018/219\n- https://developer.apple.com/videos/play/wwdc2018/416/\n- https://developer.apple.com/videos/play/wwdc2020/10078/?time=256\n\nObviously, it is important to keep memory under control. In our daily life, we usually use Xcode memory debugger tool and instruments to detect memory leaks. Basically, lots of manual works. Maybe, a better way is to integrate memory leak detection into internal test phase or regression phase. The earlier we detect the issue, the more time we got to fix it. The less efforts we put in checking memory leaks manually, the more likely we spend less time to optimal memory issues and keep our app away from memory leaks. So, using `MLeaksFinder` and `FBRetainCycleDetector` in dev or test phase sounds like a good idea. \n\n# What is MLeaksFinder for? \n\nAs we know, `MLeaksFinder` is an light-weight tool from `WeChat` team, `Tencent`, which automatically finds leaks in some specific objects. When leaks happening, it will present an alert showing the leaked object and backtrace. \n\n# How does MLeaksFinder work? \n\nThe basic idea for `MLeaksFinder` is to set a timer when the object is about to be released. When the timer is triggered, checked if the reference to the object is still valid. If it is, this object is leaked. Then, it uses this leaked object as seed object for `FBRetainCycleDetector` to figure out the retain cycle using DFS algorithm to traversal object graph. You may see this brief introduction in some Chinese tech articles. While, I found lots of articles introducing `MLeakdsFinder` are outdated. Since its source code is a bit easy to read, let's just start to explore it. \n\n`MLeaksFinder` has several categories for [these classes](https://github.com/Tencent/MLeaksFinder/tree/master/MLeaksFinder): \n- NSObject+MemoryLeak\n- UIApplication+MemoryLeak\n- UINavigationController+MemoryLeak\n- UIPageViewController+MemoryLeak\n- UISplitViewController+MemoryLeak\n- UITabBarController+MemoryLeak\n- UITouch+MemoryLeak\n- UIView+MemoryLeak\n- UIViewController+MemoryLeak\n\n\nTake `UIViewController` as an example, it swizzles `viewDidDisappear:` method, then checks if current view controller has been popped by `UINavigationController`. Why need this check? Because the view controller isn't necessarily popped from view controller stack when `viewDidDisappear:` called. Maybe, another view controller just has been pushed into the view controller stack, cover it and showing on the screen.\n\n```c++\n- (void)swizzled_viewDidDisappear:(BOOL)animated {\n    [self swizzled_viewDidDisappear:animated];\n    \n    if ([objc_getAssociatedObject(self, kHasBeenPoppedKey) boolValue]) {\n        [self willDealloc];\n    }\n}\n```\n\n`kHasBeenPoppedKey` tag here is set by [UINavigationController, code here](https://github.com/Tencent/MLeaksFinder/blob/master/MLeaksFinder/UINavigationController%2BMemoryLeak.m#L56). \n\n![image-20210319225704137](image-20210319225704137.png)\nAs this pic demonstrates, if the view controller was released, the reference the block captured 2 seconds ago is `nil`. If this view controller isn't released, `strongSelf` here would be a valid base address to it. Then `MLeakFinder` will show an alter to warn users. \n\nWe have talked about view controller, how about views?  Well, in `willDealloc` method in `UIViewController`, MLeaksFinder will run self.view's `willDealloc`; then check `subviews` Array. Basically, the view tree in this view controller will be traversed through and checked. \n\n```c++\n@implementation UIView (MemoryLeak)\n​\n- (BOOL)willDealloc {\n    if (![super willDealloc]) {\n        return NO;\n    }\n    \n    [self willReleaseChildren:self.subviews];\n    \n    return YES;\n}\n​\n@end\n```\n\n![image-20210314194009331](image-20210314194009331.png)\n\nIf you enable the `FBRetainCycleDetector` through macro, the current leaked object will be used as  seed object for FBRetainCycleDetector, which will detect the retain cycle. \n\n# What is FBRetainCycleDetector for? \n\nFacebook has a dedicated article about the [FBRetainCycleDetector](https://engineering.fb.com/2016/04/13/ios/automatic-memory-leak-detection-on-ios/)\n> Finding retain cycles in Objective-C is analogous to finding cycles in a directed acyclic graph in which nodes are objects and edges are references between objects (so if object A retains object B, there exists reference from A to B). Our Objective-C objects are already in our graph; all we have to do is traverse it with a depth-first search.\n\nSo, in order to traverse the directed graph, how to get neighbors of each node? How to get objects each node references? For each node in the graph, it could be either an object or block.\n\n# References in object\n\n## strong ivars \n\nFor objects, `FBRetainCycleDetector` get its **ivar list** from the object. \n\n> The first thing we can do is grab the layout of all an object's instance variables (the “ivar layout”). For a given object, an ivar layout describes where we should look for other objects that it references.\n\n```objective-c\nconst uint8_t *fullLayout = class_getIvarLayout(aCls);\n\nIvar *class_copyIvarList(Class cls, unsigned int *outCount)\n\n```\n\n[`FBClassStrongLayout` here](https://github.com/facebook/FBRetainCycleDetector/blob/1ff2adee84a6ee94a1ae82526104a188774eb90a/FBRetainCycleDetector/Layout/Classes/FBClassStrongLayout.mm#L184)\n1. Because `class_copyIvarList` won't include instance variables declared by superclasses. This method has to get ivar list for current, its superclass, all the way up to its ancestoiicoder\n2. get strong ivar by analyzing ivar layout\n3. cache ivar list in a map, `<Class, NSArray<FBObjectReference>>`\n\n\nLet's understand it deeper by taking an example. For the following class, there are 4 strong references to others, 2 weak reference.\n\n```c++\n@interface _RCDTestClassWithMixedWeakAndStrongProperties : NSObject\n@property (nonatomic, strong) NSObject *object1;\n@property (nonatomic, strong) NSObject *object2;\n@property (nonatomic, strong) NSObject *object3;\n@property (nonatomic, weak) NSObject *object4;\n@property (nonatomic, strong) NSObject *object5;\n@property (nonatomic, weak) NSObject *object6;\n@end\n```\n\nusing  `class_copyIvarList`, we can see its Ivar list. Each pointer is 8-byte in memory in 64-bit device, we an see the `offset` for first ivar to the class base address is `8 bytes`; the second ivar is `16 bytes`, the third one is `24bytes`, etc. \n\n<img src=\"image-20210320160316683.png\" width=\"330\" height=\"600\">\n\nThen, use `class_getIvarLayout` to get ivar layout \n\n```c++\n  const uint8_t *fullLayout = class_getIvarLayout(aCls);\n```\n\nBasically, the value of `fullLayout` is \n\n```\n\"\\x03\\x11\"\n```\n\n- In  hexadecimal figure `\\x03`, the high bits represents the number of `non-strong` ivar, the lower bits represents the number of `strong ivar`. `\\x03` indicates that there are zero non-strong ivar and 3 strong ivar, `_object1`, `_object2`, `_object3` in this case. \n- `x11` claims that there comes 1 non-strong ivar,  weak `_object4` in above declaration; and then follows 1 strong ivar `object5`\n\nThe following method is to parse ivar layout according to the above rule and get a set of `NSRange` for index and length for strong ivars in this class. One range is `1 to 3` and the other is `5`. \n\n```c++\nstatic NSIndexSet *FBGetLayoutAsIndexesForDescription(NSUInteger minimumIndex, const uint8_t *layoutDescription) {\n  NSMutableIndexSet *interestingIndexes = [NSMutableIndexSet new];\n  NSUInteger currentIndex = minimumIndex;\n\n  while (*layoutDescription != '\\x00') {\n    // how many non-strong ivar \n    int upperNibble = (*layoutDescription & 0xf0) >> 4; \n    // how many strong ivar\n    int lowerNibble = *layoutDescription & 0xf;\n\n    // currentIndex is to track the first idx of strong ivar currently being analyzed from hexodecimal value\n    // Upper nimble is for skipping `non-strong` ivar\n    currentIndex += upperNibble;\n\n    // Lower nimble describes count of the strong ivar \n    [interestingIndexes addIndexesInRange:NSMakeRange(currentIndex, lowerNibble)];\n    currentIndex += lowerNibble;\n\n    ++layoutDescription;\n  }\n\n  return interestingIndexes;\n}\n```\n\n| Idx  | Weak/strong |         |\n| ---- | ----------- | ------- |\n| 1    | strong      | object1 |\n| 2    | strong      | object2 |\n| 3    | strong      | object3 |\n| 4    | weak        | object4 |\n| 5    | strong      | object5 |\n| 6    | weak        | object6 |\nFor the above case, the ivar layout is `\"\\x03\\x11\"`\n\n|      | upperNibble | lowerNibble | currentIndex | NSRange |\n| ---- | ----------- | ----------- | ------------ | ------- |\n| x03  | 0           | 3           | 1            | {1, 3}  |\n| x11  | 1           | 1           | 5            | {5, 1}  |\n\n\n\nParsing ivar layout to filter out the 4th and 6th ivar and get a set of index range for strong ivar. The result are two ranges, {1, 3} and {5, 1} \n\n```\n<NSMutableIndexSet: 0x7fb7aea8ef40>[number of indexes: 4 (in 2 ranges), indexes: (1-3 5)]\n```\n\n<img src=\"image-20210320161003483.png\" width=\"375\" height=\"500\">\n\n\nThere are other interesting cases in the [FBClassStrongLayoutTests.mm](https://github.com/facebook/FBRetainCycleDetector/blob/master/FBRetainCycleDetectorTests/FBClassStrongLayoutTests.mm), the ivar type can be structure or block, and it can be weak as well. \n\n## References to associated objects \n\n`FBRetainCycleDetector` hooks the calls, `objc_setAssociatedObject` and `objc_removeAssociatedObjects`. Then it store objects and a set of pointers to strongly referred associated objects into a global map. \n\n```c++\nusing ObjectAssociationSet = std::unordered_set<void *>;\nusing AssociationMap = std::unordered_map<id, ObjectAssociationSet *>;\n```\n\nUsing  `OBJC_ASSOCIATION_RETAIN` and `OBJC_ASSOCIATION_RETAIN_NONATOMIC` to trace strong references only\n\n```c++\n   if (policy == OBJC_ASSOCIATION_RETAIN ||\n          policy == OBJC_ASSOCIATION_RETAIN_NONATOMIC) {\n        _threadUnsafeSetStrongAssociation(object, key, value);\n   ...\n```\n\n## Block and captured objects\n\nWhat attracts me most is the capability in `FBRetainCycleDetector` to detect leaked blocks and its reference.  [Amazing method to get references from the block](https://github.com/facebook/FBRetainCycleDetector/blob/1ff2adee84a6ee94a1ae82526104a188774eb90a/FBRetainCycleDetector/Layout/Blocks/FBBlockStrongLayout.m#L79) and strong reference layout in block.  \n\n>  What we can use is [application binary interface for blocks](http://clang.llvm.org/docs/Block-ABI-Apple.html) (ABI). It describes how the block will look in memory. If we know that the reference we are dealing with is a block, we can cast it on a fake structure that imitates a block. After casting the block to a C-struct we know where objects retained by the block are kept.\n\n** ABI for block**\n\nFirst of all, let's take a look at the Block Literal. \n\nFor a block like this\n\n```c++\n^ { printf(\"hello world\\n\"); }\n```\n\nIt will be compiled into \n\n```c++\nstruct __block_literal_1 {\n    void *isa; // initialized to &_NSConcreteStackBlock or &_NSConcreteGlobalBlock\n    int flags;\n    int reserved;\n    void (*invoke)(struct __block_literal_1 *); // 🌟🌟🌟 The invoke function pointer is set to a function that takes the Block structure as its first argument and the rest of the arguments (if any) to the Block and executes the Block compound statement.\n    struct __block_descriptor_1 *descriptor;\n};\n\nvoid __block_invoke_1(struct __block_literal_1 *_block) {\n    printf(\"hello world\\n\");\n}\n\nstatic struct __block_descriptor_1 {\n    unsigned long int reserved;\n    unsigned long int Block_size; // the size of the following Block literal structure.\n} __block_descriptor_1 = { 0, sizeof(struct __block_literal_1) }\n```\n\nand \n\n```c++\nstruct __block_literal_1 _block_literal = {\n     &_NSConcreteStackBlock,\n     (1<<29), <uninitialized>,\n     __block_invoke_1,\n     &__block_descriptor_1\n};\n```\nThis is the initialization of the block literal structure.  \n\nYou can use `clang -rewrite-objc` to convert the Objective-C code into cpp implementation .  \n```\nclang -rewrite-objc xxxxx.m\n```\n\n## What if the block has reference to others?\n\n### Imported const copy variables\n\n```objective-c\nint x = 10;\nvoid (^vv)(void) = ^{ printf(\"x is %d\\n\", x); }\nx = 11;\nvv();\n```\n\nIt will be compiled into \n\n```c++\nstruct __block_literal_2 {\n    void *isa;\n    int flags;\n    int reserved;\n    void (*invoke)(struct __block_literal_2 *);\n    struct __block_descriptor_2 *descriptor;\n    // const copy variable x is here \n    const int x; \n};\n\nvoid __block_invoke_2(struct __block_literal_2 *_block) {\n    printf(\"x is %d\\n\", _block->x);\n}\n\nstatic struct __block_descriptor_2 {\n    unsigned long int reserved;\n    unsigned long int Block_size;\n} __block_descriptor_2 = { 0, sizeof(struct __block_literal_2) };\n```\n\n```c++\nstruct __block_literal_2 __block_literal_2 = {\n      &_NSConcreteStackBlock,\n      (1<<29), <uninitialized>,\n      __block_invoke_2,\n      &__block_descriptor_2,\n      x\n };\n```\nWe can see the variable `x` is appended at the end of `__block_literal_2` structure.  \n\n### Imported const copy of Block reference\n\nIn the following case, block `existingBlock` is captured by `vv`.  \n\n- a Block requires `copy/dispose` helpers in block descriptor if it imports any block variables\n\n```c++\nvoid (^existingBlock)(void) = ...;\nvoid (^vv)(void) = ^{ existingBlock(); }\nvv();\n\nstruct __block_literal_3 {\n   ...; // existing block\n};\n\nstruct __block_literal_4 {\n    void *isa;\n    int flags;\n    int reserved;\n    void (*invoke)(struct __block_literal_4 *);\n    struct __block_literal_4 *descriptor;\n    struct __block_literal_3 *const existingBlock;\n};\n\n// the invoke function for __block_literal_4\nvoid __block_invoke_4(struct __block_literal_2 *_block) {\n   __block->existingBlock->invoke(__block->existingBlock);\n}\n\n// copy helper is needed \nvoid __block_copy_4(struct __block_literal_4 *dst, struct __block_literal_4 *src) {\n     //_Block_copy_assign(&dst->existingBlock, src->existingBlock, 0);\n     // will increase the reference counting for existingBlock\n     _Block_object_assign(&dst->existingBlock, src->existingBlock, BLOCK_FIELD_IS_BLOCK);\n}\n\nvoid __block_dispose_4(struct __block_literal_4 *src) {\n     // was _Block_destroy\n     // will decrease the reference counting for existingBlock\n     _Block_object_dispose(src->existingBlock, BLOCK_FIELD_IS_BLOCK);\n}\n\nstatic struct __block_descriptor_4 {\n    unsigned long int reserved;\n    unsigned long int Block_size;\n    void (*copy_helper)(struct __block_literal_4 *dst, struct __block_literal_4 *src);\n    void (*dispose_helper)(struct __block_literal_4 *);\n} __block_descriptor_4 = {\n    0,\n    sizeof(struct __block_literal_4),\n    __block_copy_4,\n    __block_dispose_4,\n};\n```\n\n```c++\nstruct __block_literal_4 _block_literal = {\n      &_NSConcreteStackBlock,\n      (1<<25)|(1<<29), <uninitialized>\n      __block_invoke_4,\n      & __block_descriptor_4\n      existingBlock,\n};\n```\n\n### Importing `__block` variables into Blocks\n\n- Variables of `__block` storage class are imported as a pointer to an enclosing data structure. see [more here]([Imported  copy of  reference](https://clang.llvm.org/docs/Block-ABI-Apple.html#id5))\n\n```c++\nint __block i = 2;\nfunctioncall(^{ i = 10; });\n```\nwould be compiled into:\n\n```\nstruct _block_byref_i {\n    void *isa;  // set to NULL\n    struct _block_byref_voidBlock *forwarding;\n    int flags;   //refcount;\n    int size;\n    void (*byref_keep)(struct _block_byref_i *dst, struct _block_byref_i *src);\n    void (*byref_dispose)(struct _block_byref_i *);\n    int captured_i;  // the capture variable\n};\n\n\nstruct __block_literal_5 {\n    void *isa;\n    int flags;\n    int reserved;\n    void (*invoke)(struct __block_literal_5 *);\n    struct __block_descriptor_5 *descriptor;\n    struct _block_byref_i *i_holder;\n};\n \nvoid __block_invoke_5(struct __block_literal_5 *_block) {\n   _block->forwarding->captured_i = 10;\n}\n\nvoid __block_copy_5(struct __block_literal_5 *dst, struct __block_literal_5 *src) {\n     //_Block_byref_assign_copy(&dst->captured_i, src->captured_i);\n     _Block_object_assign(&dst->captured_i, src->captured_i, BLOCK_FIELD_IS_BYREF | BLOCK_BYREF_CALLER);\n}\n\nvoid __block_dispose_5(struct __block_literal_5 *src) {\n     //_Block_byref_release(src->captured_i);\n     _Block_object_dispose(src->captured_i, BLOCK_FIELD_IS_BYREF | BLOCK_BYREF_CALLER);\n}\n\nstatic struct __block_descriptor_5 {\n    unsigned long int reserved\n    unsigned long int Block_size;\n    void (*copy_helper)(struct __block_literal_5 *dst, struct __block_literal_5 *src);\n    void (*dispose_helper)(struct __block_literal_5 *);\n} __block_descriptor_5 = { 0, sizeof(struct __block_literal_5) __block_copy_5, __block_dispose_5 };\n```\n\nand \n\n```c++\nstruct _block_byref_i i = {( .isa=NULL, .forwarding=&i, .flags=0, .size=sizeof(struct _block_byref_i), .captured_i=2 )};\nstruct __block_literal_5 _block_literal = {\n      &_NSConcreteStackBlock,\n      (1<<25)|(1<<29), <uninitialized>,\n      __block_invoke_5,\n      &__block_descriptor_5,\n      &i,\n};\n```\n\n- `copy_helper` and `dispose_helper` helper functions are added\n- a structure `_block_byref_i` is generated to store  `__block` variable; see `captured_i` in `_block_byref_i`\n\n### import `__block` object \n\n```c++\nvoid func() {\n    __block NSObject *obj = [[NSObject alloc] init];\n    void (^blk)(void) = ^() {\n        obj = nil;\n    };\n}\n```\n-  structure `__Block_byref_obj_0` holds reference to `NSObject *obj` pointer. \n-  need copy/dispose helper function\n```c++\nstruct __Block_byref_obj_0 {\n  void *__isa;\n  __Block_byref_obj_0 *__forwarding;\n  int __flags;\n  int __size;\n  void (*__Block_byref_id_object_copy)(void*, void*);\n  void (*__Block_byref_id_object_dispose)(void*)\n  NSObject *obj; // capture __block NSObject *obj \n};\n\nstatic void __func_block_func_0(struct __func_block_impl_0 *__cself) {\n  __Block_byref_obj_0 *obj = __cself->obj; // bound by ref\n  (obj->__forwarding->obj) = __null;\n}\n\nstatic void __func_block_copy_0(struct __func_block_impl_0*dst, struct __func_block_impl_0*src) {_Block_object_assign((void*)&dst->obj, (void*)src->obj, 8/*BLOCK_FIELD_IS_BYREF*/);}\n\nstatic void __func_block_dispose_0(struct __func_block_impl_0*src) {_Block_object_dispose((void*)src->obj, 8/*BLOCK_FIELD_IS_BYREF*/);}\n\nstatic struct __func_block_desc_0 {\n  size_t reserved;\n  size_t Block_size;\n  void (*copy)(struct __func_block_impl_0*, struct __func_block_impl_0*);\n  void (*dispose)(struct __func_block_impl_0*);\n} \n\n```\n\n## Block_size\n\nFrom the above cases, we can see in the  descriptor structure `__block_descriptor_2`,  the `Block_size` field is sizeof(struct ` __block_literal_2`) . This is a very import field.  `FBRetainCycleDetector` uses it to get the number of pointers inside\n\n```c++\n  void (*dispose_helper)(void *src) = blockLiteral->descriptor->dispose_helper;\n  const size_t ptrSize = sizeof(void *);\n\n  // Figure out the number of pointers it takes to fill out the object, rounding up.\n  const size_t elements = (blockLiteral->descriptor->size + ptrSize - 1) / ptrSize;\n\n```\n\nLet's take a look at a test case here. Supposed a block captures an object from outside.\n\n```c++\n NSObject *object = [NSObject new];\n  \n  void (^block)() = ^{\n    __unused NSObject *someObject = object;\n  };\n  \n  NSArray *retainedObjects = FBGetBlockStrongReferences((__bridge void *)(block));\n```\n\nThe block literal is like this\n\n```\nstruct BlockLiteral {\n  void *isa;  // initialized to &_NSConcreteStackBlock or &_NSConcreteGlobalBlock\n  int flags;\n  int reserved;\n  void (*invoke)(void *, ...);\n  struct BlockDescriptor *descriptor;\n  // imported variables\n  const void *someObject \n};\n```\n![](block_literal_x.png)\n```\n(lldb) p blockLiteral->descriptor->size\n(unsigned long) $0 = 40\n```\n\n- The value of `blockLiteral->descriptor->size` is 40, indicating the block 40 bytes in memory;\n- `int` is 32 bit, `flags` and `reserved` will be put together into one word, 8 bytes in 64bit processor device. \n- In ARM64 device, the pointer size a `8` bytes.  \n- So it needs 5 pointers to fill out the fake object. \n\n\n>  We create an object that pretends to be a block we want to investigate. Because we know the block’s interface, we know where to look for references this block holds. In place of those references our fake object will have “release detectors.” Release detectors are small objects that are observing release messages sent to them. These messages are sent to strong references when an owner wants to relinquish ownership. We can check which detectors received such a message when we deallocate our fake object. Knowing which indexes said detectors are in the fake object, we can find actual objects that are owned by our original block.\n\nCreate detector for each of the pointer in the faked object. \n\n```c++\n// Create a fake object of the appropriate length.\n  void *obj[elements];\n  void *detectors[elements];\n\n  for (size_t i = 0; i < elements; ++i) {\n    // new detectors to detect whether the pointer inside obj is strong or not\n    FBBlockStrongRelationDetector *detector = [FBBlockStrongRelationDetector new];\n    obj[i] = detectors[i] = detector;\n  }\n```\nNow faked object `obj` contains 5 references to 5 `FBBlockStrongRelationDetector` instances. These 5 detectors are newly created to detect whether the pointer inside obj is strong or not. They are not the original block object in your code, but with same memory layout and reference retain policy.  \n\n```\n(void *[]) obj = ([0] = 0x00007fc07b41c370, [1] = 0x00007fc07b41f4b0, [2] = 0x00007fc07b42c080, [3] = 0x00007fc07b422820, [4] = 0x00007fc07b42e420)\n```\n\n![image-20210320170900864](image-20210320170900864.png)\n\nThen, try to dispose the faked object. \n\n```c++\n @autoreleasepool {\n    dispose_helper(obj);\n  }\n```\nThe disposing of the fake object actually triggers `releasing` of those detectors if they are strongly referred by the fake object only. In FBBlockStrongRelationDetector, `release` message has been overridden and set `_strong` ivar to `YES` to mark the related strong reference in the `blockLiteral`\n\n```\nFBBlockStrongRelationDetector\n// set _strong as YES when received release message\n- (oneway void)release\n{\n  _strong = YES;\n}\n```\n\n![image-20210320172426371](image-20210320172426371.png)\n\nFinally get the index of the strong reference of current block by figuring out in which `FBBlockStrongRelationDetector`, `_strong` is `YES`.  \n\n```\n<NSMutableIndexSet: 0x7fc07b41f560>[number of indexes: 1 (in 1 ranges), indexes: (4)]\n```\n\n\n## Detect cycle\n\nTo detect the cycle of objects, it is doing DFS over graph of objects.[ code here](https://github.com/facebook/FBRetainCycleDetector/blob/1ff2adee84a6ee94a1ae82526104a188774eb90a/FBRetainCycleDetector/Detector/FBRetainCycleDetector.mm#L89).  \n\n![image-20201008115603415](image-20201008115603415.png)\n\n# Impact on memory footprint \n\n- **MLeaksFinder** is light-weight. It has **few** impact on memory footprint \n- **FBRetainCycleDetector has impact** on the memory footprint**.** The upside is that **MLeaksFinder** triggers **DFS in FBRetainCycleDetector** on when the user click `Retain Cycle` button in the alter. After the Alert is dismissed, most of the memory usage will be gone. \n\n\n# Summary:\n\n- **FBRetainCycleDetector** is quite powerful. It can even detect leaks related to Blocks. But it is a bit slow since it uses `DFS` algorithm to traverse the object tree. Besides, there is potential risks of data race in [associated manager](https://github.com/facebook/FBRetainCycleDetector/blob/1ff2adee84a6ee94a1ae82526104a188774eb90a/FBRetainCycleDetector/Associations/FBAssociationManager.mm#L136). \n- **MLeaksFinder** is simple but tricky. So once it detects the leaked object, it use **FBRetainCycleDetector to detect the retain cycle.** Then it shows the **alter.**\n- We can use `MLeaksFinder` to detect some seed objects. and provide **FBRetainCycleDetector**  with these candidate objects from which it will start detection.","categories":["iOS"]},{"title":"Crash - Pointer Authentication Failures or invalid memory accesses","url":"/2021/03/05/20210305-pointer-authentication-failed/","content":"\nRecently, a colleague came to me for a crash. It is quite tricky. So i took a note here. The exception section is as follow:\n\n```\nException Type:  EXC_BAD_ACCESS (SIGSEGV)\nException Subtype: KERN_INVALID_ADDRESS at 0x0000ec033bb40320 -> 0x000000033bb40320 (possible pointer authentication failure)\nVM Region Info: 0x33bb40320 is not in any region.  Bytes after previous region: 2612265761  Bytes before following region: 53759180000\n      REGION TYPE                 START - END      [ VSIZE] PRT/MAX SHRMOD  REGION DETAIL\n      MALLOC_NANO              283fb8000-2a0000000 [448.3M] rw-/rwx SM=ZER  \n--->  GAP OF 0xd20000000 BYTES\n      commpage (reserved)      fc0000000-1000000000 [  1.0G] ---/--- SM=NUL  ...(unallocated)\n\nTermination Signal: Segmentation fault: 11\nTermination Reason: Namespace SIGNAL, Code 0xb\nTerminating Process: exc handler [8919]\nTriggered by Thread:  14\n```\nFrom this exception type, we can see `KERN_INVALID_ADDRESS at 0x0000ec033bb40320 -> 0x000000033bb40320 (possible pointer authentication failure)` . You may wonder what it is. Well, according to Apple doc \n\n>  When pointer authentication fails, the system invalidates the failing pointer by setting a high-order bit. Subsequent use of the pointer results in a segmentation fault. The crash report contains a message that includes the value of the pointer both after and before invalidation:\n\nBut there is another much more common crash caused by this kind: \n\n> Be aware that other invalid memory accesses, where high-order bits are erroneously set, can also look like pointer authentication failures.\n\nIn exception section in the crash report, there are 3 messages matching \n\n- The exception type is `EXC_BAD_ACCESS (SIGSEGV) `,  it is a segment violation signal from system to kill your process\n- The `subtype` is  `KERN_INVALID_ADDRESS at 0x0000ec033bb40320 -> 0x000000033bb40320 (possible pointer authentication failure)`.  We can see here the failing pointer is `0x0000ec033bb40320`, after system invalidates the higher bits of this pointer, it becomes `0x000000033bb40320`.\n- The converted address `0x33bb40320` isn't in any valid memory region. \n\nNow we know the invalid address is `0x0000ec033bb40320`. Then we actually can see it is in `x0` register in the Thread State. `Thread State` in crash report actually records the state of thread's register when crash happened. \nSee more about thread state in [doc](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/identifying_the_cause_of_common_crashes/investigating_memory_access_crashes#3562197). In Objective-C , c or Swift, register 0 holds address for current object when function calling. \n\n```\nThread 14 crashed with ARM Thread State (64-bit):\n    x0: 0x0000ec033bb40320   x1: 0x000000016b692b58   x2: 0x000000016b692b50   x3: 0x000000016b692b30\n    x4: 0x0000000000008903   x5: 0x0000000000000020   x6: 0x0000000000000000   x7: 0x0000000000000000\n    x8: 0x003f4281a5942364   x9: 0x8ef94d448c3b009a  x10: 0x00000000000007c8  x11: 0x007f00013e1bd800\n   x12: 0x000000000000004d  x13: 0x000000013e1bdcc0  x14: 0x000000000000035f  x15: 0x00000001f3e4d8b8\n   x16: 0x00000001dc3bfbc0  x17: 0x00000001908b9474  x18: 0x0000000000000000  x19: 0x000000016b692b30\n   x20: 0x000000016b692b50  x21: 0x000000016b692b58  x22: 0x0000000280e10320  x23: 0x000000028392f600\n   x24: 0x0000000108367ae8  x25: 0x0000000000000000  x26: 0x000000016b6930e0  x27: 0x0000000000000114\n   x28: 0xffffffffffffffff   fp: 0x000000016b692b20   lr: 0x00000001076903ac\n    sp: 0x000000016b692ad0   pc: 0x00000001076900d0 cpsr: 0x20001000\n   esr: 0x92000004 (Data Abort) byte read Translation fault\n\n```\n\nSo we can switch gears and take a deeper look into the stacktrace in the crashed thread to find out the current instance. At the top of the stacktrace, it is `loadApplication` function from `Instance` class. Since the invalid address is in `x0`, which usually holds the pointer to current object. I suspect something goes wrong with `Instance`  instance. \n\n```c++\nThread 14 name:\nThread 14 Crashed:\n0   xxx                       \t0x00000001076900d0 facebook::react::Instance::loadApplication(std::__1::unique_ptr<facebook::react::RAMBundleRegistry, std::__1::default_delete<facebook::react::RAMBundleRegistry> >, std::__1::unique_ptr<facebook::re... + 40 (Instance.cpp:61)\n1   xxx                       \t0x00000001076903ac facebook::react::Instance::loadScriptFromString(std::__1::unique_ptr<facebook::react::JSBigString const, std::__1::default_delete<facebook::react::JSBigString const> >, std::__1::basic_string<char,... + 200 (Instance.cpp:95)\n2   xxx                       \t0x00000001076903ac facebook::react::Instance::loadScriptFromString(std::__1::unique_ptr<facebook::react::JSBigString const, std::__1::default_delete<facebook::react::JSBigString const> >, std::__1::basic_string<char,... + 200 (Instance.cpp:95)\n3   xxx                       \t0x0000000106434fb4 __51-[RCTCxxBridge executeApplicationScript:url:async:]_block_invoke + 668 (RCTCxxBridge.mm:1429)\n4   xxx                       \t0x0000000106439414 std::__1::__function::__value_func<void ()>::operator()() const + 20 (functional:1873)\n5   xxx                       \t0x0000000106439414 std::__1::function<void ()>::operator()() const + 20 (functional:2548)\n6   xxx                       \t0x0000000106439414 facebook::react::tryAndReturnError(std::__1::function<void ()> const&) + 40 (RCTCxxUtils.mm:72)\n7   xxx                       \t0x000000010642e5e8 -[RCTCxxBridge _tryAndHandleError:] + 100 (RCTCxxBridge.mm:276)\n8   xxx                       \t0x0000000106434cb0 -[RCTCxxBridge executeApplicationScript:url:async:] + 156 (RCTCxxBridge.mm:1412)\n9   xxx                       \t0x0000000106434aa4 -[RCTCxxBridge enqueueApplicationScript:url:onComplete:] + 112 (RCTCxxBridge.mm:1392)\n10  xxx                       \t0x0000000106432710 -[RCTCxxBridge executeSourceCode:sync:] + 228 (RCTCxxBridge.mm:1005)\n11  xxx                       \t0x000000010642f374 __21-[RCTCxxBridge start]_block_invoke_2 + 96 (RCTCxxBridge.mm:390)\n12  libdispatch.dylib             \t0x000000019050824c _dispatch_call_block_and_release + 32 (init.c:1454)\n13  libdispatch.dylib             \t0x0000000190509db0 _dispatch_client_callout + 20 (object.m:559)\n14  libdispatch.dylib             \t0x000000019051aa68 _dispatch_root_queue_drain + 656 (inline_internal.h:2548)\n15  libdispatch.dylib             \t0x000000019051b120 _dispatch_worker_thread2 + 116 (queue.c:6777)\n16  libsystem_pthread.dylib       \t0x00000001dc3c57d8 _pthread_wqthread + 216 (pthread.c:2227)\n17  libsystem_pthread.dylib       \t0x00000001dc3cc76c start_wqthread + 8\n```\n\nThen, i checked the backtrace again.  It actually happens in the phase of Bridge initialization.  `[RCTCxxBridge start]`. \n\n```c++\n- (void)start\n{\n  RCT_PROFILE_BEGIN_EVENT(RCTProfileTagAlways, @\"-[RCTCxxBridge start]\", nil);\n\n  [[NSNotificationCenter defaultCenter]\n    postNotificationName:RCTJavaScriptWillStartLoadingNotification\n    object:_parentBridge userInfo:@{@\"bridge\": self}];\n\n  // Set up the JS thread early\n  _jsThread = [[NSThread alloc] initWithTarget:[self class]\n                                      selector:@selector(runRunLoop)\n                                        object:nil];\n  _jsThread.name = RCTJSThreadName;\n  _jsThread.qualityOfService = NSOperationQualityOfServiceUserInteractive;\n#if RCT_DEBUG\n  _jsThread.stackSize *= 2;\n#endif\n  [_jsThread start];\n\n  dispatch_group_t prepareBridge = dispatch_group_create();\n\n  [_performanceLogger markStartForTag:RCTPLNativeModuleInit];\n\n  [self registerExtraModules];\n  // Initialize all native modules that cannot be loaded lazily\n  (void)[self _initializeModules:RCTGetModuleClasses() withDispatchGroup:prepareBridge lazilyDiscovered:NO];\n  [self registerExtraLazyModules];\n\n  [_performanceLogger markStopForTag:RCTPLNativeModuleInit];\n\n  // This doesn't really do anything.  The real work happens in initializeBridge.\n  _reactInstance.reset(new Instance);\n\n  __weak RCTCxxBridge *weakSelf = self;\n\n  // Prepare executor factory (shared_ptr for copy into block)\n  std::shared_ptr<JSExecutorFactory> executorFactory;\n  if (!self.executorClass) {\n    if ([self.delegate conformsToProtocol:@protocol(RCTCxxBridgeDelegate)]) {\n      id<RCTCxxBridgeDelegate> cxxDelegate = (id<RCTCxxBridgeDelegate>) self.delegate;\n      executorFactory = [cxxDelegate jsExecutorFactoryForBridge:self];\n    }\n    if (!executorFactory) {\n      executorFactory = std::make_shared<JSCExecutorFactory>(nullptr);\n    }\n  } else {\n    id<RCTJavaScriptExecutor> objcExecutor = [self moduleForClass:self.executorClass];\n    executorFactory.reset(new RCTObjcExecutorFactory(objcExecutor, ^(NSError *error) {\n      if (error) {\n        [weakSelf handleError:error];\n      }\n    }));\n  }\n\n  // Dispatch the instance initialization as soon as the initial module metadata has\n  // been collected (see initModules)\n  dispatch_group_enter(prepareBridge);\n  [self ensureOnJavaScriptThread:^{\n    [weakSelf _initializeBridge:executorFactory];\n    dispatch_group_leave(prepareBridge);\n  }];\n\n  // Load the source asynchronously, then store it for later execution.\n  dispatch_group_enter(prepareBridge);\n  __block NSData *sourceCode;\n  [self loadSource:^(NSError *error, RCTSource *source) {\n    if (error) {\n      [weakSelf handleError:error];\n    }\n\n    sourceCode = source.data;\n    dispatch_group_leave(prepareBridge);\n  } onProgress:^(RCTLoadingProgress *progressData) {\n#if RCT_DEV && __has_include(\"RCTDevLoadingView.h\")\n    // Note: RCTDevLoadingView should have been loaded at this point, so no need to allow lazy loading.\n    RCTDevLoadingView *loadingView = [weakSelf moduleForName:RCTBridgeModuleNameForClass([RCTDevLoadingView class])\n                                       lazilyLoadIfNecessary:NO];\n    [loadingView updateProgress:progressData];\n#endif\n  }];\n\n  // Wait for both the modules and source code to have finished loading\n  dispatch_group_notify(prepareBridge, dispatch_get_global_queue(QOS_CLASS_USER_INTERACTIVE, 0), ^{\n    RCTCxxBridge *strongSelf = weakSelf;\n    if (sourceCode && strongSelf.loading) {\n      [strongSelf executeSourceCode:sourceCode sync:NO];\n    }\n  });\n  RCT_PROFILE_END_EVENT(RCTProfileTagAlways, @\"\");\n}\n```\n\nThis snippet of code comes from `React Native 0.61` , what this function basically does is to \n\n1. Init JSThread and . If you are interested in `CFRunloop` as well, can take a look at my another [article](https://suelan.github.io/2021/02/13/20210213-dive-into-runloop-ios/)\n2. Initialize native modules. If you are interested, see more in [what is behind react native native module](https://suelan.github.io/2020/12/23/20201223-what-is-behind-react-native-module/)\n3. create instance of  `facebook::react::Instance` class, and initialization in `JSThread`\n\n```c++\n// In RCTCxxBridge\ndispatch_group_enter(prepareBridge);\n  [self ensureOnJavaScriptThread:^{\n    [weakSelf _initializeBridge:executorFactory];\n    dispatch_group_leave(prepareBridge);\n  }];\n\n// In Instance\nvoid Instance::initializeBridge(\n    std::unique_ptr<InstanceCallback> callback,\n    std::shared_ptr<JSExecutorFactory> jsef,\n    std::shared_ptr<MessageQueueThread> jsQueue,\n    std::shared_ptr<ModuleRegistry> moduleRegistry) {\n  callback_ = std::move(callback);\n  moduleRegistry_ = std::move(moduleRegistry);\n  jsQueue->runOnQueueSync([this, &jsef, jsQueue]() mutable {\n    nativeToJsBridge_ = folly::make_unique<NativeToJsBridge>(\n        jsef.get(), moduleRegistry_, jsQueue, callback_);\n\n    std::lock_guard<std::mutex> lock(m_syncMutex);\n    m_syncReady = true;\n    m_syncCV.notify_all();\n  });\n\n  CHECK(nativeToJsBridge_);\n}\n```\n\n4. Load JavaScript Bundle \n\n5. execute JavaScript source code in background thread, which is the crash thread. \n\n   \n\nObviously, there are potential risk of multi-thread write for `Instance` object. It would be accessed from \n\n- `com.facebook.react.JavaScript` thread. You can search `+[RCTCxxBridge runRunLoop]` in your crash report\n\n- Background thread created by `Dispatch`\n\n- The thread to setup JavaScript Bridge, where you call\n\n  `_bridge = [[RCTBridge alloc] initWithDelegate:self                               launchOptions:launchOptions];`\n\nAnd in my friend's case, they could init `RCTBridge`  for more than once, which could rise the possibility of this crash. I have a [video](https://www.youtube.com/watch?v=GPs3oPFSdo0) for this. \n\n\n### Ref\n- https://developer.apple.com/documentation/security/preparing_your_app_to_work_with_pointer_authentication\n- https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/analyzing_a_crash_report","categories":["iOS","React Native"]},{"title":"Crash - ate bad food (0x8badf00d)","url":"/2021/03/05/20210305-crash-ate-bad-food/","content":"\nRecently, my colleague came to me for a crash report. It is a case where system watch dog kills our app for blocking `main thread` for too long time. It seems many people encounter issues of this sorts from time to time. However, there are a few articles about it. I hope this article could help you. \n\n## Exception Type \n\nAs we know, a crash report records app's state when it crashed. It is a crucial and first-hand resource to help us figure out what was happening when a crash happened in user's device. When i to a crash report. I always try to extract as much information as I can. Apple actually has dedicated article about how to [analyze a crash report](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/analyzing_a_crash_report). \n\nIn this case, firstly, we can take a look at exception type, which is `EXC_CRASH (SIGKILL)`. `EXC_CRASH (SIGKILL)` indicates the operating system terminated the process. See more [here](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/understanding_the_exception_types_in_a_crash_report#3582412). \n\nThe crash report also contains a `Termination Reason` field with a code that explains the reason for the crash. Here, that code is `0xdead10cc`:\n\n- `0x8badf00d` (pronounced “ate bad food”). The operating system’s watchdog terminated the app. See [Addressing Watchdog Terminations](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/identifying_the_cause_of_common_crashes/addressing_watchdog_terminations).\n\n```\nException Type:  EXC_CRASH (SIGKILL)\nException Codes: 0x0000000000000000, 0x0000000000000000\nException Note:  EXC_CORPSE_NOTIFY\nTermination Reason: Namespace SPRINGBOARD, Code 0x8badf00d\nTermination Description: SPRINGBOARD, scene-update watchdog transgression: application<.......>:307 exhausted real (wall clock) time allowance of 10.00 seconds | ProcessVisibility: Background | ProcessState: Running | WatchdogEvent: scene-update | WatchdogVisibility: Background | WatchdogCPUStatistics: ( | \"Elapsed total CPU time (seconds): 39.500 (user 39.500, system 0.000), 39% CPU\", | \"Elapsed application CPU time (seconds): 21.283, 21% CPU\" | )\nTriggered by Thread:  0\n```\n\n\n\n### WatchDog\n\nAs we know, iOS has watchdog oto ensure application not drag down the system responsiveness. If your app has poor performance, watchdog will check then kill you app to make sure the shared resource well allocated.  It is dev's duty to maintain system responsiveness. The following table showing some cases for watchdog check, it comes from this [session](https://developer.apple.com/videos/play/wwdc2011/312/),\n\n<img src=\"image-20210305194510328.png\" alt=\"image-20210305194510328.png\" style=\"zoom:50%;\" />\n\nAs for scenarios, Slow launch will cause OS to abort your app. `20 sec`; resume and suspend is also very important `10sec`; smooth scrolling `6s` is also a key point. Besides, I also have seen `blocking main thread`  will cause watchdog kill an app, like this \n\n```\ntransgression: application<com.wangya.test2>:21021 exhausted real (wall clock) time allowance of 19.99 seconds \nTriggered by Thread:  0\n```\n\n\n\nThe `Termination Description`  in my crash report shows our app `exhausted real (wall clock) time allowance of 10.00 seconds`.  Besides, the `ProcessVisibility` shows it is `Background` and `ProcessState` is `Running`.  It seems the crashed happened when it tried to resumed from background. But what caused it? \n\n### Backtrace \n\nSo we have to go to the stack trace in the crashed report. Unfortunately, he gave me a partially symbolicated crash report with `CoreData` related method remaining hexadecimal memory address. From the frame in our app, i know operations related to `CoreData` happening in `main thread`. Then, I have to symbolicate the crash report. \n\n### Symbolicate \n\nApple actually has doc to [symbolicate the Crash Report in Xcode](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/adding_identifiable_symbol_names_to_a_crash_report#3403794)  or [symbolicate the crash report with the command line](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/adding_identifiable_symbol_names_to_a_crash_report#3403800). \n\n> To symbolicate in Xcode, click the Device Logs button in the [Devices and Simulators window](https://help.apple.com/xcode/mac/current/#/dev85c64ec79), then drag and drop the crash report file into the list of device logs. And, crash reports must have the `.crash` file extension. \n\n![img](https://help.apple.com/xcode/mac/current/en.lproj/Art/dw_view_crash_logs.png)\n\n As Apple's doc, [Acquire Device Symbol Information](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/adding_identifiable_symbol_names_to_a_crash_report#3403795) says, I have to collect symbols for system frameworks like `CoreData` from the device where crashed happened.\n\n> The symbols for system frameworks are specific to the operating system release and the CPU architecture of the device. For example, the symbols for an iPhone running iOS 13.1.0 aren’t the same as the symbols for the same iPhone running iOS 13.1.2. \n\nUnfortunately, I don't have  the device on hand to get the symbol information matching the operating system version recorded in the crash report. How to solve it? Well, I still have a way to work around. Let's start to do that.\n\n1. Check the os version and hardware model from the crash report. OS Version: `iPhone OS 13.3.1 (17D50); Hardware model: `Hardware Model:      iPhone11,8`\n\n2. download [IPSW](https://en.wikipedia.org/wiki/IPSW), iPod Software from  https://www.theiphonewiki.com/wiki/Firmware/iPhone/11.x or https://ipsw.me/; or can decrypte `ipsw` by yourself following this [guide](https://gist.github.com/tzmartin/812027b879f6ff4459af)\n\n3. `IPSW` file actually is `zip` file, we can change the file extension `ipsw` to `zip`. Then unzip it. You can see a big disk image there.\n\n   ![](image-20210305201936593.png)\n\n    Double click it. It will be mounted in filesystem. Then we can see it showing in the `Finder` \n\n   ![](image-20210305202238201.png)\n\n4. Then go to `/System/Library/Caches/com.apple.dyld` folder. Drag this file to `Hopper`\n\n   ![](image-20210305202347747.png)\n\n5. Since all executable dylib are shipped into this whole file, we have to filter out `CoreData` in the search bar. \n\n   ![](image-20210305202507076.png)\n\n6. Get `offset` from frame in the backtrace in the crash report.  Using `go to file offset`  in Hopper, `option + g` to jump to that line of assembly code. I actually have a [talk](https://www.youtube.com/watch?v=GPs3oPFSdo0) about how to use exception info, thread state, offset in backtrace in crash report  to analyze crash report. \n\n   ![](image-20210305204358148.png)\n\n   take `line 29` as an example, it goes to a `bl` instruction. As we know, in Objective-C, `x1` stores the sector. So we can quickly figure out the selector is \n\n   [executeRequest:withContext:error:](https://developer.apple.com/documentation/coredata/nspersistentstorecoordinator/1468872-executerequest?language=objc)\n\n   ![](image-20210305204545965.png)\n\n   Hmm, although it is a little bit tedious, we finanly get more info about what is happening here. \n\n   Basically, when resuming from background, our app triggers a data request operation in `CoreData`. It is executed in `main thread` and make the main thread wait this transaction finished. While,  it is a bit of slow to execute this SQL-related transaction here and blocks `main thread` for extended period of time. Then when watchdog come to check, it terminates our app in order to maintain the system responsiveness. \n\n![](image-20210305210726254.png)\n\nAs apple suggests, the watchdog terminates apps that block the main thread for a significant time.  There are some cases of this sort, like \n\n- Synchronous networking\n- Processing large amouts of data, such as large JSON files or 3D models\n- Triggering lightweight migration for a large [Core Data](https://developer.apple.com/documentation/coredata) store synchronously\n- Analysis requests with [Vision](https://developer.apple.com/documentation/vision)\n\nThis time, we ate bad food. \n\n### See More\n\n- [Addressing Watchdog Terminations](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/identifying_the_cause_of_common_crashes/addressing_watchdog_terminations)\n\n- [Investigating Memory Access Crashes](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/identifying_the_cause_of_common_crashes/investigating_memory_access_crashes)\n\n- [Analyzing a Crash Report](https://developer.apple.com/documentation/xcode/diagnosing_issues_using_crash_reports_and_device_logs/analyzing_a_crash_report)\n- [0x8badf00d in main thread](https://stackoverflow.com/questions/59827727/ios-frequently-getting-exhausted-real-wall-clock-time-allowance-of-10-00-seco)\n\n","categories":["iOS"]},{"title":"Ensure Null-Terminated JS Bundle in React Native","url":"/2021/02/13/20210213-ensure-null-terminated-string/","content":"\n## Description\n\nThere is an expensive copy operation for data buffer when loading and parsing JS Bundle in React Native.  In my case, I have a `4.8` MB JS bundle. Xcode instrument profiler shows it takes up 15.81 MB trying to copy a `NSData` object in  `ensureNullTerminated` function in `NSDataBigString` class.\n\n![image](instrument-profile.png)\n\nThis is the brief process for `RCTBridge` loading JS bundle\n![image](image-load.png)\n\nIn Objc, `NSData` is a static byte buffer that bridges to Data, which is a byte buffer in a contiguous region of memory. Here, `NSDataBigString` class holds `NSData` object constructed from JS bundle. \n\n![image](nsdata.png)\n\nInside react-native framework, it has to treat this data buffer in a contiguous region of memory as a [null-terminated byte string (NTBS)](https://en.cppreference.com/w/c/string/byte#:~:text=A%20null%2Dterminated%20byte%20string,(the%20terminating%20null%20character).&text=For%20example%2C%20the%20character%20array,%22cat%22%20in%20ASCII%20encoding.) . \n\n> A null-terminated byte string (NTBS) is a sequence of nonzero bytes followed by a byte with value zero (the terminating null character). Each byte in a byte string encodes one character of some character set. For example, the character array {'\\x63','\\x61','\\x74','\\0'} is an NTBS holding the string \"cat\" in ASCII encoding.\n\nWhile, this data buffer doesn't end with `\\0` character. Besides, In Objective-C, `NSData` is an immutable object. In order to add the `Null` byte, `\\0` character, firstly, it has to copy the original immutable `NSData` object and construct a mutable object; then append `\\0` to the data buffer.\n\n\n## React Native version:\nRun `react-native info` in your terminal and copy the results here.\nreact-native: v0.63.3\ndevice: iPhone 5s \nOS version: 12.4.8 \n\n## Steps To Reproduce\nProvide a detailed list of steps that reproduce the issue.\n\n1. open `RNTester` in `react-native` repo. `react-native/packages/rn-tester`\n2. find `ensureNullTerminated`  and set a breakpoint there \n3. run the `RNTester` \n\n## Snack, code example, screenshot, or link to a repository:\n\n![image](code-snippet.png)\n\n## Solution \n\n- Add `\\0` character ahead of time when building JS bundle. By doing this, you can avoid this copy operation during bundle loading in App launching phase. \n\n## Ref \n\n- https://github.com/facebook/react-native/issues/30145\n\n","tags":["Dive into React Native"],"categories":["React Native"]},{"title":"Dive into CFRunLoop","url":"/2021/02/13/20210213-dive-into-runloop-ios/","content":"## Background \n\nSometimes, you may want to collect on-device performance metrics in main thread to know how our App performs and help you find more clues to  analyse performance issue. [MetricKit](MetricKit) is a useful utility framework to achieve that. It starts accumulating reports for your app after being called for the first time and delivers reports at most once per day. The reports contain the metrics from the past 24 hours and any previously undelivered daily reports. Then, you can go to `Xcode->Organizer->Metric` panel to check these info. However, you may want your in-house App Performance Monitoring framework to gain more controls on when to collect metrics, or how to upload it, or collect what you want. Earlier days, `Tencent` launched a [iOS framework called matrix](https://github.com/Tencent/matrix) to monitor App performance metrics. When I explored this library, I saw they use `CFRunLoop` to detect hitch in the thread, like main thread. This intrigued me. So I investigated `CFRunLoop` to learn more. \n\n\n## What is RunLoop in iOS? \n\nBefore talking about RunLoop in iOS, we may have to know something about event loop and thread.  In [OS/360 Multiprogramming with a Variable Number of Tasks](https://en.wikipedia.org/wiki/OS/360_and_successors#MVT) (MVT) in 1967, threads made an early appearance under the name of \"tasks\". A **thread** in computer science  is short for a *thread of execution*. Once the tasks in one Thread is all done, the thread finishes its job and exits. Sometimes, we need a way to keep it alive and handling events.  Then,  comes the event loop. The psudo code for event loop is like this:\n\n```js\nfunction loop\n    initialize()\n    while message != quit\n        message := get_next_message()\n        process_message(message)\n    end while\nend function\n```\n\nIn Wikipedia, event loop is a programming construct or [design pattern](https://en.wikipedia.org/wiki/Software_design_pattern) that waits for and dispatches [events](https://en.wikipedia.org/wiki/Event-driven_programming) or [messages](https://en.wikipedia.org/wiki/Message_Passing_Interface) in a [program](https://en.wikipedia.org/wiki/Computer_program).  In this event loop, it keeps `waiting events -> receive events -> handle events` until the exit condition is met. \n\n> Run loops are part of the fundamental infrastructure associated with threads. A *run loop* is an event processing loop that you use to schedule work and coordinate the receipt of incoming events. The purpose of a run loop is to keep your thread busy when there is work to do and put your thread to sleep when there is none.\n\n> A CFRunLoop object monitors sources of input to a task and dispatches control when they become ready for processing.  \n\nA run loop receives events from two different types of sources. `Input sources` deliver asynchronous events, usually messages from another thread or from a different application. `Timer sources` deliver synchronous events, occurring at a scheduled time or repeating interval.  \n\nIt can handle \n\n- user input devices\n\n- port objects \n\n- network connections\n\n- periodic or time-delayed events\n\n- asynchronous callbacks\n\n  ![image-20210128230441389](image-20210128230441389.png)\n\nIn Apple's doc,  this kind of event loop is implemented by `CFRunLoop` in low-level. In cocoa, the object is an instance of `NSRunLoop` There is exactly one run loop per thread. \n\nApple provides two APIs to get runloop object \n\n- `CFRunLoopGetMain()` // the main CFRunLoop object\n- `CFRunLoopGetCurrent()` // CFRunLoop object for the current thread\n\n## RunLoop Mode \n\n> A *run loop mode* is a collection of input sources and timers to be monitored and a collection of run loop observers to be notified. Each time you run your run loop, you specify (either explicitly or implicitly) a particular “mode” in which to run.During that pass of the run loop, only sources associated with that mode are monitored and allowed to deliver their events.   --- [doc](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-SW23)\n\nA run loop mode contains a set of `CFRunLoopSource`, a list of `CFRunLoopTimer` and `CFRunLoopObservers`. They are all inputs for runloop. \n\n![image-20210128223829153](image-20210128223829153.png)\n\n## Inputs\n\nThree kinds of inputs can be monitored by a run loop \n\n- CFRunLoopSource \n- CFRunLoopTimer\n- CFRunLoopObservers\n\n### Input Source  - CFRunLoopSource\n\n[CFRunLoopSource](https://developer.apple.com/documentation/corefoundation/cfrunloopsource-rhr)\n\n> A CFRunLoopSource object is an abstraction of an input source that can be put into a run loop. Input sources typically generate asynchronous events, such as messages arriving on a network port or actions performed by the user.\n\n```c++\nstruct __CFRunLoopSource {\n    CFRuntimeBase _base;\n    uint32_t _bits;\n    pthread_mutex_t _lock;\n    CFIndex _order;\t\t\t/* immutable */\n    CFMutableBagRef _runLoops;\n    union {\n\t      CFRunLoopSourceContext version0;\t/* immutable, except invalidation */\n        CFRunLoopSourceContext1 version1;\t/* immutable, except invalidation */\n    } _context;\n};\n```\n\n`_context` is a `union` type. A union looks like a structure, but  it will use the memory space for just one of the fields in its definition. So the `_context` is either an `CFRunLoopSourceContext`    structure or `CFRunLoopSourceContext1` structure.\n\n#### Two categories of Input Source\n\nAs it is mentioned in this [doc](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-SW23), we mainly care about two categories, `port-base` input sources, source1,  and `non-port-based` input sources, source0, also called custom sources. \n\n- Version 0 sources, so named because the `version` field of their context structure is 0, are managed manually by the `application`.\n  - When a source is ready to fire, some part of the `application`, perhaps code on a separate` thread` waiting for an event, must call [`CFRunLoopSourceSignal(_:)`](https://developer.apple.com/documentation/corefoundation/1543700-cfrunloopsourcesignal) to tell the run loop that the source is ready to fire. \n  - custom input source that allows you to perform a selector on any thread. Like `performSelectorOnMainThread:withObject:waitUntilDone:` , `performSelector:withObject:afterDelay:`. see more\n  - [Defining a Custom Input Source](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-SW3)\n- Version 1 sources are managed by the run loop and kernel. \n  - These sources use `Mach ports` to signal when the sources are ready to fire. \n  - A source is automatically `signaled by the kernel` when a message arrives on the source’s Mach port.\n  - see [Configuring a Port-Based Input Source](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-131281)\n![image-20210125183432020](image-20210125183432020.png)\n\n\n\n#### `bits` field\n\nIt seems that `bits` field is used to mark the status of the `CFRunLoopSouceRef` .  \n\n```c++\nCF_INLINE Boolean __CFRunLoopSourceIsSignaled(CFRunLoopSourceRef rls) {\n    return (Boolean)__CFBitfieldGetValue(rls->_bits, 1, 1);\n}\n\nCF_INLINE void __CFRunLoopSourceSetSignaled(CFRunLoopSourceRef rls) {\n    __CFBitfieldSetValue(rls->_bits, 1, 1, 1);\n}\n\nCF_INLINE void __CFRunLoopSourceUnsetSignaled(CFRunLoopSourceRef rls) {\n    __CFBitfieldSetValue(rls->_bits, 1, 1, 0);\n}\n```\n\n[CFRunLoopSourceSignal](https://developer.apple.com/documentation/corefoundation/1543700-cfrunloopsourcesignal) is used to signals a `version 0 source` , marking it as ready to fire. It actually updated the `bits` in the  `CFRunLoopSouceRef` structure. \n\n```c++\nvoid CFRunLoopSourceSignal(CFRunLoopSourceRef rls) {\n    CHECK_FOR_FORK();\n    __CFRunLoopSourceLock(rls);\n    if (__CFIsValid(rls)) {\n\t__CFRunLoopSourceSetSignaled(rls);\n    }\n    __CFRunLoopSourceUnlock(rls);\n}\n```\n\n### CFRunLoopTimer \n\nBesides `CFRunLoopSource`, there is another input for runloop. Timer Source, `CFRunLoopTimer`, which represents a specialized run loop source that fires at a preset time in the future.  see [doc for CFRunLoopTimer](https://developer.apple.com/documentation/corefoundation/cfrunlooptimer-rhk)\n\n\nThere are two conditions for a timer to be fired: \n\n- one of the run loop modes to which the timer has been added is running \n- the timer's firing time has passed\n\n#### a timer is not a real-time mechanism\n\n1. Like input sources, timers are associated with specific modes of your run loop. If a timer is not in the mode currently being monitored by the run loop, it does not fire until you run the run loop in one of the timer’s supported modes. \n2. If a timer fires when the run loop is in the middle of executing a handler routine, the timer waits until the next time through the run loop to invoke its handler routine. \n3. If the run loop is not running at all, the timer never fires.\n\n\nIn Cocoa, you can create and schedule a timer all at once using either of these class methods:\n\n```\nscheduledTimerWithTimeInterval:target:selector:userInfo:repeats:\nscheduledTimerWithTimeInterval:invocation:repeats:\n```\nYou can also create your `NSTimer` object and then add it to the run loop using the `addTimer:forMode:` method of `NSRunLoop`. \nsee [how to configure timer source here](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-SW6)\n\n### RunLoopObserver\n\n#### How to use observer \n\n1. We can use these two APIs to create RunLoopObserver and associated it with handlers. \n\n- CFRunLoopObserverCreate(_:_:_:_:_:_:)\n- CFRunLoopObserverCreateWithHandler(_:_:_:_:_:)\n\n2. add the observer into the runloop \n\n   ```objective-c\n     \n       CFRunLoopObserverRef runloopObserver = CFRunLoopObserverCreateWithHandler(kCFAllocatorDefault, kCFRunLoopBeforeWaiting, YES, 0, ^(CFRunLoopObserverRef observer, CFRunLoopActivity activity) {   \n        // handler code here  \n     });\n   \n       CFRunLoopAddObserver(CFRunLoopGetMain(), runloopObserver, kCFRunLoopDefaultMode);\n   ```\n\n3. Observe specific RunLoop Activity \n\n## RunLoop Activity \n\n> The run loop stages in which an observer is scheduled are selected when the observer is created with [`CFRunLoopObserverCreate`](https://developer.apple.com/documentation/corefoundation/1541546-cfrunloopobservercreate?language=objc).       -[doc](https://developer.apple.com/documentation/corefoundation/cfrunloopactivity?language=objc)\n\nThere are several kinds of RunLoop Activity for CFRunLoop. You can associate run loop observers with these RunLoopActivity\n\n```c\n/* Run Loop Observer Activities */\ntypedef CF_OPTIONS(CFOptionFlags, CFRunLoopActivity) {\n    kCFRunLoopEntry = (1UL << 0), // The entrance of the run loop, before entering the event processing loop. This activity occurs once for each call to CFRunLoopRun() and CFRunLoopRunInMode(_:_:_:).\n    kCFRunLoopBeforeTimers = (1UL << 1), // Inside the event processing loop before any timers are processed.\n    kCFRunLoopBeforeSources = (1UL << 2), // Inside the event processing loop before any sources are processed.\n    kCFRunLoopBeforeWaiting = (1UL << 5), \n    kCFRunLoopAfterWaiting = (1UL << 6),  // Inside the event processing loop after the run loop wakes up, but before processing the event that woke it up. This activity occurs only if the run loop did in fact go to sleep during the current loop.\n    kCFRunLoopExit = (1UL << 7), // The exit of the run loop, after exiting the event processing loop. This activity occurs once for each call to CFRunLoopRun() and CFRunLoopRunInMode(_:_:_:).\n    kCFRunLoopAllActivities = 0x0FFFFFFFU \n};\n```\n\nhttps://developer.apple.com/documentation/corefoundation/cfrunloopactivity \n\n### Run Loop Sequence of Events\n\nAccording to [apple doc](https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-SW1),  when runloop running  in a thread, it processes pending events and generates notifications for attached observers.  Briefly, it works as the follow diagram shows. \n\n![image-20210209142244931](image-20210209142244931.png)\n\nThe implementation is in `CFRunLoopRunSpecific` and `__CFRunLoopRun` in `CFRunloop.c` . \n\n## Use case \n\n### Detect hitch block in main thread \n\n In [Tencent matrix](https://github.com/Tencent/matrix), it leverages the Run Loop notifications to record timestamp when these notifications sent. \n\n1. create and add RunLoopObserver to current RunLoop [CFRunLoopAddObserver](https://github.com/Tencent/matrix/blob/c7fd99237af189fb060f90d1272350db19182dbf/matrix/matrix-iOS/Matrix/WCCrashBlockMonitor/CrashBlockPlugin/Main/BlockMonitor/WCBlockMonitorMgr.mm#L831)\n\n2. [record timestamp](https://github.com/Tencent/matrix/blob/c7fd99237af189fb060f90d1272350db19182dbf/matrix/matrix-iOS/Matrix/WCCrashBlockMonitor/CrashBlockPlugin/Main/BlockMonitor/WCBlockMonitorMgr.mm#L858) in callback function invoked when the observer runs\n3. start a [monitor thread](https://github.com/Tencent/matrix/blob/c7fd99237af189fb060f90d1272350db19182dbf/matrix/matrix-iOS/Matrix/WCCrashBlockMonitor/CrashBlockPlugin/Main/BlockMonitor/WCBlockMonitorMgr.mm#L478), then [check periodically](https://github.com/Tencent/matrix/blob/c7fd99237af189fb060f90d1272350db19182dbf/matrix/matrix-iOS/Matrix/WCCrashBlockMonitor/CrashBlockPlugin/Main/BlockMonitor/WCBlockMonitorMgr.mm#L498)\n4. get the[timestamp diff](https://github.com/Tencent/matrix/blob/c7fd99237af189fb060f90d1272350db19182dbf/matrix/matrix-iOS/Matrix/WCCrashBlockMonitor/CrashBlockPlugin/Main/BlockMonitor/WCBlockMonitorMgr.mm#L612) to see if it is greater than threshold, [g_RunLoopTimeOut](https://github.com/Tencent/matrix/blob/c7fd99237af189fb060f90d1272350db19182dbf/matrix/matrix-iOS/Matrix/WCCrashBlockMonitor/CrashBlockPlugin/Main/BlockMonitor/WCBlockMonitorMgr.mm#L630)\n\nI did a small experiment to better understand it. I added a RunLoop Observer to the runloop in main thread. Then calculate the time gap between `kCFRunLoopBeforeTimers` notification in two continuous loop. \n\n```c++\n// 1. create runloop observer \nCFRunLoopObserverRef beginObserver = CFRunLoopObserverCreate(kCFAllocatorDefault, kCFRunLoopAllActivities, YES, LONG_MIN, &myRunLoopCallback, &context);\n// 2.  add observer to runloop in the main thread\nCFRunLoopAddObserver([[NSRunLoop mainRunLoop] getCFRunLoop], beginObserver, kCFRunLoopCommonModes);\n```\n\n```c++\n// 3. implemented callback for RunLoop observer \nstatic void myRunLoopCallback(CFRunLoopObserverRef observer, CFRunLoopActivity activity, void *info)\n{\n     switch (activity) {\n        case kCFRunLoopEntry:\n             self.isRunloopRunning = YES;\n             break;       \n        case kCFRunLoopBeforeTimers:\n             NSLog(@\"[RY]kCFRunLoopBeforeTimers called %@\", @(getCurrentMilliTimestamp() - monitor.runloopMilliTimestamp));\n             self.runloopMilliTimestamp = getCurrentMilliTimestamp();\n             self.isRunloopRunning = YES;\n             break;\n        case kCFRunLoopBeforeSources:\n             self.isRunloopRunning = YES;\n             break;\n        case kCFRunLoopBeforeWaiting:\n             self.isRunloopRunning = NO;\n             break;\n        case kCFRunLoopAfterWaiting:\n             self.isRunloopRunning = YES;\n             break;\n        case kCFRunLoopExit:\n             self.isRunloopRunning = NO;\n             break;b\n        default:\n            break;\n    }\n}\n```\n\nTheoretically,  the time diff between  two continuous `kCFRunLoopBeforeTimers` notification should be within `16.67ms` to achieve smooth user experience in main thread, which means `RunLoop` runs 60 times per second. In the following log, one frame takes about `72ms` to executed. \nHowever, since I put the logger in `kCFRunLoopBeforeTimers`, this may not be a hitch. It could be caused thread was sleeping while there is no event come. \n\n```\n [RY]kCFRunLoopBeforeTimers called 3.628173828125\n [RY]kCFRunLoopBeforeTimers called 17.784912109375\n [RY]kCFRunLoopBeforeTimers called 0.041015625\n [RY]kCFRunLoopBeforeTimers called 1.23388671875\n [RY]kCFRunLoopBeforeTimers called 72.05419921875\n [RY]kCFRunLoopBeforeTimers called 5.138916015625\n [RY]kCFRunLoopBeforeTimers called 0.072021484375\ners called 1.296875\n [RY]kCFRunLoopBeforeTimers called 0.070068359375\n [RY]kCFRunLoopBeforeTimers called 0.035888671875\n [RY]kCFRunLoopBeforeTimers called 0.051025390625\n [RY]kCFRunLoopBeforeTimers called 0.057861328125\n [RY]kCFRunLoopBeforeTimers called 0.01806640625\n [RY]kCFRunLoopBeforeTimers called 0.260009765625\n [RY]kCFRunLoopBeforeTimers called 0.03515625\n [RY]kCFRunLoopBeforeTimers called 0.43212890625\n\n```\n\n### Runloop in React Native \n\n#### make JSThread long-lived\n\n- [create the JSThread](https://github.com/facebook/react-native/blob/1bc06f18c613f9a85d5b631493a09682524016f2/React/CxxBridge/RCTCxxBridge.mm#L407), called `com.facebook.react.JavaScript`. In react native, this is a secondary thread besides main thread where JavaScript code runs, function calls to native implementation are made etc... \n- [run the runloop explicitly in JSThread](https://github.com/facebook/react-native/blob/1bc06f18c613f9a85d5b631493a09682524016f2/React/CxxBridge/RCTCxxBridge.mm#L326) to make it long-lived \n\n#### enqueue a block object on a given runloop\n\n- [use `CFRunLoopPerformBlock` to enqueue a block to `kCFRunLoopCommonModes` mode in current runloop](https://github.com/facebook/react-native/blob/1bc06f18c613f9a85d5b631493a09682524016f2/React/CxxBridge/RCTMessageThread.mm#L41). This function is similar to [Cocoa’s performSelector:onThread:withObject:waitUntilDone:](https://developer.apple.com/documentation/objectivec/nsobject/1414476-performselector?language=objc)\n- [wake up runloop. The block will be executed when the runloop runs in `kCFRunLoopCommonModes` mode ](https://github.com/facebook/react-native/blob/1bc06f18c613f9a85d5b631493a09682524016f2/React/CxxBridge/RCTMessageThread.mm#L48)\n\n## See More \n\n- https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/RunLoopManagement/RunLoopManagement.html#//apple_ref/doc/uid/10000057i-CH16-SW1\n- https://blog.ibireme.com/2015/05/18/runloop/\n- https://opensource.apple.com/tarballs/CF/\n- https://developer.apple.com/documentation/corefoundation\n- https://github.com/apple/swift-corelibs-foundation/","tags":["Popular Article"],"categories":["iOS"]},{"title":"How Image Loader and Cache work in React Native","url":"/2020/12/24/20201224-How-Image-Loader-and-Cache-work-in-React-Native/","content":"\n In react native, it is so intuitive to display different types of images. The [Image Component](https://reactnative.dev/docs/image) can display network images, static resources, temporary local images, and images from local disk. \n\n```jsx\n<Image style={styles.footerLastestImage} source={{ uri: latestImage }} />\n```\n\nHowever, there are actually lots of stories behind this simple line of code.\nToday, I would like to explore image loader and image cache in react native, and talk something about how they work under the hood. After reading this, you will find some limits in the image component shipped from react-native and may want to use other tech solutions for better image display. \n\n## Overview of React/Image module\n\nLet me begin with an activity diagram about **React/Image** module.\n\n![](ActivityReactNative.jpg)\n\nThere are several classes playing important roles in image render and cache in react native. **RCTImageView** is the iOS native implementation for **Image component**. It inherits `RCTView` and hold a `UIImageView` to render the image. `RCTImageView` is created by `RCTUIManager`. The `UIImageView` size comes from the style prop in `Image` component in JavaScript side or calculated by `Yoga`. When setting property for Image component in RN or other events triggering the image loading, `RCTImageView` calls `RCTImageLoader` to get the cached image or download image. `RCTImageLoader` is the controller for the workflow of image downloading, decoding. It depends on `RCTNetwork` to fetch the image remotely.  Before trying to download an image, `RCTImageLoader` will try to check [if there is cached image](https://github.com/facebook/react-native/blob/1ee406b9ccbecc52dff3e77d65c6d9b4837e6dab/Libraries/Image/RCTImageLoader.mm#L606) and to reuse the cached image. So here comes `RCTImageCache`, which is for Image Cache in react native iOS. \n\n## **RCTImageCache**\n\nFirst of all, keep in mind that **RCTImageCache** uses [NSCache](https://developer.apple.com/documentation/foundation/nscache) to cache images. `NSCache` object used `RCTImageCache` has only [20MB](https://github.com/facebook/react-native/blob/00456211e591930f28a08356141fc8bec52fe3e5/Libraries/Image/RCTImageCache.m#L41) cache capacity in React Native iOS.\n\n### How images added into NSCache? \n\n#### 1. expiration time \n\nAfter successfully downloading the images, **RCTImageLoader** decodes the image using [decodeImageData:size:scale:clipped:resizeMode:completionBlock](https://github.com/facebook/react-native/blob/9500eb8867d25896b1611903a64fac8d81984bf6/Libraries/Image/RCTImageLoader.mm#L935), then it [adds the decoded image to cache](https://github.com/facebook/react-native/blob/00456211e591930f28a08356141fc8bec52fe3e5/Libraries/Image/RCTImageLoader.mm#L806). In this step, it extracts the **expiration time** from the Http Response header. See more in the diagram to see how it get the expire time. The **max-age** is the top priority to decide expiration time for an image here. \n\n<img src=\"stale_time.png\" style=\"zoom:50%;\" />\n\n#### 2. The cost of image in NSCache\n\nAnother key point is that **RCTImageCache** uses [`setObject:forKey:cost:` API](https://developer.apple.com/documentation/foundation/nscache/1416399-setobject?language=objc). \n\n> The `cost` value is used to compute a sum encompassing the costs of all the objects in the cache. When memory is limited or when the total cost of the cache eclipses the maximum allowed total cost, the cache could begin an eviction process to remove some of its elements.\n\n#### 3. using Bitmap size as cost\n\n```c++\n\nstatic const NSUInteger RCTMaxCachableDecodedImageSizeInBytes = 2097152; // 2 MB\n\n- (void)addImageToCache:(UIImage *)image\n                 forKey:(NSString *)cacheKey\n{\n  if (!image) {\n    return;\n  }\n  // calculate the bitmap size \n  NSInteger bytes = image.reactDecodedImageBytes;\n  // checks if the size of the decoded image bigger than 2MB. Any decoded image occupying more than 2MB memory won't be added into **NSCache**.  \n  if (bytes <= RCTMaxCachableDecodedImageSizeInBytes) {\n    [self->_decodedImageCache setObject:image\n                                 forKey:cacheKey\n                                   cost:bytes];\n  }\n}\n```\n\n\nBefore adding an image into the **NSCache**. **RCTImageCache** firstly calculate the bitmap size using the following formula\n\n```c++\nstatic NSInteger RCTImageBytesForImage(UIImage *image)\n{\n  NSInteger singleImageBytes = image.size.width * image.size.height * image.scale * image.scale * 4;\n  return image.images ? image.images.count * singleImageBytes : singleImageBytes;\n}\n```\n\nFor a `RGBA` format image, each pixel needs 4 bytes to represent the RGBA value, which contains 4 channels. We know that the value for each channel varies from 0 to 255.  So we need 8 bits, or 1 bytes to store it.\n\n```\nA   R   G   B   A   R   G   B   A   R   G   B  \n| pixel 0       | pixel 1       | pixel 2  \n0  233  2  100  4  155 255  7   8   9   10  11\n```\n\nBeside, Image.scale is the scale factor. Multiplying the logical size of the image (stored in the size property) by value, you get the dimensions of the image in pixels. So for the `310*165` `UIImage` object, it totally uses `310*scale*165*scale*4` pixels. \n\nAn important point here is that the **reactDecodedImageBytes** isn't always equal to the true bitmap size in memory after decoding images. Because **RCTImageLoader** will take the size and the resize mode of the **UIImageView** into consideration. [Source code here.](https://github.com/facebook/react-native/blob/00456211e591930f28a08356141fc8bec52fe3e5/Libraries/Image/RCTImageUtils.m#L256). When decoding, it downscale the downloaded image and display the downsized image to fit the image view size. This means `reactDecodedImageBytes` used as image cost in NSCache could be bigger than the actual size of finally displaying image. \n\nSo briefly speaking, for each image added into the `NSCache`, its cost is the bitmap size instead of the file size. `JPG` or `PNG` is kind of compressed format, which has much smaller size. Remember `NSCache` has `20MB` **totalCostLimit** in react native. In addition, bitmap size is much bigger than file size. It is so easy to exceed the totalCostLimit for `NSCache`, and then to trigger the eviction process to remove some of the images. \n\n#### 4. The unknown storage and eviction policy in NSCache \n\nIn the official doc  [NSCache](https://developer.apple.com/documentation/foundation/nscache) , it says `NSCache` is to temporarily store transient key-value pairs, and doesn't mention whether it uses `disk cache` or not. I added a log to see if it get `image` from the `NSCache` when launching my App without `network`. It does get a few cached images. So far, I think we can say that `NSCache` does have `disk cache` , but the proportion of disk cache is so small that we got a few cached images and the hit rate doesn't improve a lot even when I improve the `totalCostLimit` of NSCache. \n\nSo if your react native app is kind of image-heavy app. Sometimes, when you are in the scroll view full of displaying images. When you scroll down, then scroll back, you can see it fetching and decoding images, even if some of them were rendered just now but moved out of the screen later. Because in this case, the `NSCache` uses up its cache capacity and keep evicting images. Moreover, this eviction process isn't in a guaranteed order. Seems it doesn't simply apply `LRU` policy here. \n\n\n### How to get images from cache\n\nThe method to get images from `NSCache` looks relatively simple. [ imageForUrl:size:scale:resizeMode](https://github.com/facebook/react-native/blob/00456211e591930f28a08356141fc8bec52fe3e5/Libraries/Image/RCTImageCache.m#L79). \n\n1. get the key for cached image by using **url, size, scale, resizeMode.** As long as these 4 factors not changed next time, the key for the cached image won't be changed, and you can reuse this image\n2. check if the cached image is expired. If it is, remove the image from the cache. \n\n### How to replace RCTImageCache with your own cache implementation\n\nLet your own cache implementation conform `RCTImageCache` protocol. And then `setImageCache` in `RCTImageLoader`.\n\n```c++\n/**\n * Allows developers to set their own caching implementation for\n * decoded images as long as it conforms to the RCTImageCache\n * protocol. This method should be called in bridgeDidInitializeModule.\n */\n- (void)setImageCache:(id<RCTImageCache>)cache;\n```\n\n\n## Concurrent Loading and Decoding Tasks \n\n`RCTImageLoader` maintains queues to schedule image loading and decoding tasks.  The following property controls the number of concurrent tasks for image loading and decoding. \n\n```c++\n/**\n * The maximum number of concurrent image loading tasks. Loading and decoding\n * images can consume a lot of memory, so setting this to a higher value may\n * cause memory to spike. If you are seeing out-of-memory crashes, try reducing\n * this value.\n */\n@property (nonatomic, assign) NSUInteger maxConcurrentLoadingTasks;\n\n/**\n * The maximum number of concurrent image decoding tasks. Decoding large\n * images can be especially CPU and memory intensive, so if your are decoding a\n * lot of large images in your app, you may wish to adjust this value.\n */\n@property (nonatomic, assign) NSUInteger maxConcurrentDecodingTasks;\n\n/**\n * Decoding large images can use a lot of memory, and potentially cause the app\n * to crash. This value allows you to throttle the amount of memory used by the\n * decoder independently of the number of concurrent threads. This means you can\n * still decode a lot of small images in parallel, without allowing the decoder\n * to try to decompress multiple huge images at once. Note that this value is\n * only a hint, and not an indicator of the total memory used by the app.\n */\n@property (nonatomic, assign) NSUInteger maxConcurrentDecodingBytes;\n```\n\n\n","tags":["Popular Article","Dive into React Native"],"categories":["iOS","React Native"]},{"title":"Dive into react native module","url":"/2020/12/23/20201223-what-is-behind-react-native-module/","content":"\n[Native Modules](https://reactnative.dev/docs/native-modules-ios) is one of the key part of React Native which enables JavasScript to call methods in iOS or Android native implementation.\n\n It is quite interesting to explore the source code about native modules in react native repo. In this article, I would like to talk something about how React Native register, initialize native modules and what is behind the method calling from JavaScript side to iOS Objective-C modules. \n\nFirst of all, let's take look at [RCTBridgeModule`](https://github.com/facebook/react-native/blob/23717e48aff3d7fdaea30c9b8dcdd6cfbb7802d5/React/Base/RCTBridgeModule.h#L63) , which is a protocol provides interface needed to register a bridge module.   \n\n```objective-c\n#define RCT_EXPORT_MODULE(js_name)  \n#define RCT_EXPORT_METHOD(method)\n+ (NSString *)moduleName;\n\n@optional\n+ (BOOL)requiresMainQueueSetup;\n```\n\n## Export and Register Modules\n\n`RCT_EXPORT_MODULE` is in `RCTBridgeModule` protocol, You can use this macro to export your iOS module. \n\n> Place this macro in your class implementation to automatically register your module with the bridge when it loads. The optional js_name argument. It will be used as the JS module name. If omitted, the JS module name will match the Objective-C class name.\n\nFor example, `RCT_EXPORT_MODULE` is used in [RNCAsyncStorage.m#L404, react-native-async-storage](https://github.com/react-native-async-storage/async-storage/blob/bfd76c7508bcc35d88f6b6c8d2fd525466f77ba0/ios/RNCAsyncStorage.m#L404).\n\nThis macro will be replaced by the following code in the preprocessor phase when you are compiling a source file. \n\n```objective-c\nRCT_EXTERN void RCTRegisterModule(Class); \n+ (NSString *)moduleName { return @#js_name; } \n+ (void)load { RCTRegisterModule(self); }\n```\n\nIn Objc world, `load` method is invoked whenever a class is added to the Objective-C runtime at the very beginning of app launch. At this time, it invokes `RCTRegisterModule` function to add the class object into the  `RCTModuleClasses` array. `RCTModuleClasses` is an array containing a list of registered classes.\n\n```objective-c\nvoid RCTRegisterModule(Class moduleClass)\n{\n  static dispatch_once_t onceToken;\n  dispatch_once(&onceToken, ^{\n    RCTModuleClasses = [NSMutableArray new];\n    RCTModuleClassesSyncQueue =\n        dispatch_queue_create(\"com.facebook.react.ModuleClassesSyncQueue\", DISPATCH_QUEUE_CONCURRENT);\n  });\n\n  RCTAssert(\n      [moduleClass conformsToProtocol:@protocol(RCTBridgeModule)],\n      @\"%@ does not conform to the RCTBridgeModule protocol\",\n      moduleClass);\n\n  // Register module\n  dispatch_barrier_async(RCTModuleClassesSyncQueue, ^{\n    [RCTModuleClasses addObject:moduleClass];\n  });\n}\n```\n\nWhen adding current module class into `RCTModuleClasses` array,  it uses `dispatch_barrier_async`  to dispatch this task to a concurrent queue, `RCTModuleClassesSyncQueue`. Using  `dispatch_barrier_async` makes sure that \none async block executing at a time in `RCTModuleClassesSyncQueue`. \n\nAs we mentioned just now,  `RCTModuleClasses` is a global array containing a list of registered classes.\n\n```\nPrinting description of RCTModuleClasses:\n<__NSArrayM 0x7fe4dc5d6bb0>(\n....\nRNSVGTSpanManager,\nRNSVGUseManager,\nRCTBaseTextViewManager,\nRCTTextViewManager,\nRNLinearTextGradientViewManager,\nRCTVirtualTextViewManager,\nRNVirtualLinearTextGradientViewManager,\nRCTAccessibilityManager,\nRCTActionSheetManager,\nRCTActivityIndicatorViewManager,\nRCTAlertManager,\n.....\n)\n```\n\n## Register and Initialize Modules \n\n1. **Modules in `RCTModuleClasses` are registered and initialized in [start](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L364)  phase in `RCTCxxBridge.mm`**.  In [initializeModules:withDispatchGroup:lazilyDiscovered](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L854), react native firstly registers all these `automatically-exported` modules.[code here](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L854); then store them  into array `_moduleClassesByID`, a bunch of pointers to `Class` objects, and `_moduleDataByID` referring to a bunch of `RCTModuleData` object. [code here](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L727). The back trace for module registering is as follow: \n\n  ![image-20201001142132537](image-20201001142132537.png)\n\n2. **If the module needs to be set up in `main` thread. It will be guaranteed running in Main thread**. [code here](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L877) and [here](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L935).  It makes sense that [react native doc](https://reactnative.dev/docs/native-modules-ios#implementing--requiresmainqueuesetup) suggests us return `NO` in the `requiresMainQueueSetup` method.\n  \n> If your module does not require access to UIKit, then you should respond to `+ requiresMainQueueSetup` with `NO`.\n\n3. When the `RNBridge` is initialized. It inits the `RCTCxxBridge` and `starts` it as current bridge.`RNBridge` in Objc realm basically is a wrapper of `RCTCxxBridge.mm`. At that time, RN [registers extra modules](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L738). \n\nJust as what  [*Lorenzo S.*](https://medium.com/u/b25eae7ad28?source=post_page-----9bb82659792c--------------------------------) shared in this  [talk](https://www.youtube.com/watch?v=7gm0owyO8HU) . The initialization of all modules in `RCTCxxBridge` start phase slows down its launch time. The more native module you have, the longer time it takes to initialize these modules even you won't use them on the first page. \n\n\n## Store modules\n\nIn the registration phase, in [`[RCTCXXBridge  _registerModulesForClasses:lazilyDiscovered:]`](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L681) , react native stores a list of registered classes into  a dictionary `_moduleDataByName`. The key is the `moduleName`, the value is the `RCTModuleData`. \n\n```\n  NSMutableDictionary<NSString *, RCTModuleData *> *_moduleDataByName;\n```\n\nRemember, in registering phase, The classes of modules ` are stored in `_moduleClassesByID`. While, `_moduleDataByID` stores `RCTModuleData`.\n\n```\n  // Native modules\n  NSMutableArray<RCTModuleData *> *_moduleDataByID;\n  NSMutableArray<Class> *_moduleClassesByID;\n```\n\n### RCTModuleData\n\nNow, you may wondering what is `RCTModuleData`? While, it is just the data structure to hold data for react native module. \n\n![image-20201215174307790](image-20201215174307790.png)\n\n`RCTBridgeModuleProvider` in `RCTModuleData` is for initializing an `instance` of `RCTBridgeModule`. Then, `RCTModuleData` retain this `instance`.  In initialization phase, `RCTModuleData`  creates an instance for the `module class`  by `RCTBridgeModuleProvider` . What `RCTBridgeModuleProvider` does is to provide an instance using`[moduleClass new]`.  [Code ref](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/Base/RCTModuleData.mm#L104).\n\n\n```objective-c\n- (instancetype)initWithModuleClass:(Class)moduleClass\n                             bridge:(RCTBridge *)bridge\n{\n  return [self initWithModuleClass:moduleClass\n                    moduleProvider:^id<RCTBridgeModule>{ return [moduleClass new]; }\n                            bridge:bridge];\n}\n```\n\n### Get Module by name or class \n\n`RCTBridge` bridge is a simple wrapper for the `RCTCxxBridge` , to make the methods in `RCTCxxBridge.mm` available for other Objective-C objects.  You can access to these two methods to get the module from Objective-C objects. \n\n```objc\n// RCTBridge \n- (id)moduleForName:(NSString *)moduleName\n- (id)moduleForClass:(Class)moduleClass\n```\n\nThey will look up the `_moduleDataByName` dictionary to find out the target  `RCTModuleData` and get its `instance`. [Source code here](https://github.com/facebook/react-native/blob/e125f12c01262c11d70c1015139d5f72c5576042/React/CxxBridge/RCTCxxBridge.mm#L529)\n\n## Module-related Class\n\nYou might be interested in the relationship between these classes.  \n\n![](module_diagram.png)\n\n## [RCTNativeModule](https://github.com/facebook/react-native/blob/master/React/CxxModule/RCTNativeModule.mm) and ModuleRegistry\n\nIn `RCTNativeModule.mm`, `RCTNativeModule`, this c++ class inherits from the base class, `NativeModule`, which holds the info for modules.\nThe constructor method in `RCTNativeModule` takes in two parameters, `RCTBridge` object and `RCTModuleData` object. \n\n### Invoke method in RCTNativeModule\n\nThe `invoke` method in `RCTNativeModule` \n\n1. firstly get the `methodName` by `methodId`\n\n2. get the execution queue for current module \n\n3. construct a block, which calls [`invokeInner`](https://github.com/facebook/react-native/blob/306a8adade432ae5c12f0a13130c4e599d64c642/React/CxxModule/RCTNativeModule.mm#L135). `invokeInner` [calls](https://github.com/facebook/react-native/blob/306a8adade432ae5c12f0a13130c4e599d64c642/React/CxxModule/RCTNativeModule.mm#L181)  [`invokeWithBridge:module:arguments:`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/Base/RCTModuleMethod.mm#L519) in the `RCTModuleMethod.mm`.\n\n   ```c++\n     invokeInner(weakBridge, weakModuleData, methodId, std::move(params), callId, isSyncModule ? Sync : Async);\n   ```\n\n![image-20201029152216662](image-20201029152216662.png)\n\n4. if current module is executed in `JSThread`, then block for invoking the method is executed synchronously. But if methods in current module should be executed in other threads, react native will dispatch the previous block into the related queue. \n\n ```c++\n   dispatch_queue_t queue = m_moduleData.methodQueue;\n   const bool isSyncModule = queue == RCTJSThread;\n   if (isSyncModule) {\n     block();\n     BridgeNativeModulePerfLogger::syncMethodCallReturnConversionEnd(moduleName, methodName);\n   } else if (queue) {\n     BridgeNativeModulePerfLogger::asyncMethodCallDispatch(moduleName, methodName);\n     dispatch_async(queue, block);\n   }\n ```\n\n### NativeModuleProxy \n\n- In the Runtime initialization phase, `RCTxxBridge.start->Instance.initializeBridge->NativeToJSBridge.initializeRuntime->JSIExecutor.initializeRuntime`,\n\n an `NativeModuleProxy` object is created and set as `nativeModuleProxy` property to the `global` object in JavaScript runtime context. \n\n```c++\nvoid JSIExecutor::initializeRuntime() {\n ...\n  runtime_->global().setProperty(\n      *runtime_,\n      \"nativeModuleProxy\",\n      Object::createFromHostObject(\n          *runtime_, std::make_shared<NativeModuleProxy>(nativeModules_)));\n ...\n }\n```\n\n- In `NativeModule.js`, JavaScript side can get a bunch of `native modules` from this `nativeModuleProxy` property from `global` object. \n\n```js\nlet NativeModules: {[moduleName: string]: $FlowFixMe, ...} = {};\nif (global.nativeModuleProxy) {\n  NativeModules = global.nativeModuleProxy;\n```\n\n- In the iOS side, the `NativeModuleProxy` class holds a weak pointer for `JSINativeModules` , which actually holds a list of registered native modules. \n\n```c++\n  std::weak_ptr<JSINativeModules> weakNativeModules_; \n```\n\n![image-20201217183117953](image-20201217183117953.png)\n\n## Export Method \n\nThe `RCT_EXPORT_METHOD` macro is used to export method in Objective realm, and will be replaced by the following code\n\n```objective-c\n#define RCT_REMAP_METHOD(js_name, method)       \\\n  _RCT_EXTERN_REMAP_METHOD(js_name, method, NO) \\\n  \n+(const RCTMethodInfo *)RCT_CONCAT(__rct_export__, RCT_CONCAT(js_name, RCT_CONCAT(__LINE__, __COUNTER__))) \n  {                                                                                                          \n    static RCTMethodInfo config = {#js_name, #method, is_blocking_synchronous_method};                       \n    return &config;                                                                                          \n  }\n```\n\nBasically, what it does is to construct a `RCTMethodInfo` structure.  \n\n```objective-c\ntypedef struct RCTMethodInfo {\n  const char *const jsName;\n  const char *const objcName;\n  const BOOL isSync;\n} RCTMethodInfo;\n```\n\nThe  [calculateMethods](https://github.com/facebook/react-native/blob/23717e48aff3d7fdaea30c9b8dcdd6cfbb7802d5/React/Base/RCTModuleData.mm#L294)  extracts exported methods and get the `IMP` of these methods.  `IMP` actually is a c function which takes in `class` and `selector` as its parameters. And then, `RCTMethodInfo` and `moduleClass` are used to construct `RCTModuleMethod`, which confirms to `RCTBridgeMethod`.\n\n### RCTBridgeMethod \n\nThe `RCTModuleData` also contains information about exported methods.\n\n```objective-c\n/**\n * Returns the module methods. Note that this will gather the methods the first\n * time it is called and then memoize the results.\n */\n@property (nonatomic, copy, readonly) NSArray<id<RCTBridgeMethod>> *methods;\n\n/**\n * Returns a map of the module methods. Note that this will gather the methods the first\n * time it is called and then memoize the results.\n */\n@property (nonatomic, copy, readonly) NSDictionary<NSString *, id<RCTBridgeMethod>> *methodsByName;\n```\n\nThe [getter methods](https://github.com/facebook/react-native/blob/23717e48aff3d7fdaea30c9b8dcdd6cfbb7802d5/React/Base/RCTModuleData.mm#L373) for these two will generate a list of `RCTBridgeMethod` objects. `RCTBridgeMethod` is a protocol. Any class confirms to this protocol has to implement `JSMethodName`,  `functionType` and `invokeWithBridge: module:arguments:` function. \n\n```objective-c\n@protocol RCTBridgeMethod <NSObject>\n\n@property (nonatomic, readonly) const char *JSMethodName;\n@property (nonatomic, readonly) RCTFunctionType functionType;\n\n- (id)invokeWithBridge:(RCTBridge *)bridge module:(id)module arguments:(NSArray *)arguments;\n\n@end\n```\n\nSo when react native triggers these two getter method? Well, in the `RCTUIManager`\n\n```\nRCT_EXPORT_METHOD(dispatchViewManagerCommand\n                  : (nonnull NSNumber *)reactTag commandID\n                  : (id /*(NSString or NSNumber) */)commandID commandArgs\n                  : (NSArray<id> *)commandArgs)\n```\n\nBeside, `RCTModuleData` also sets up and holds the thread `methodQueue` for the native module.  This `dispatch_queue_t` object is also retained in [RCTBridgeModule.h](https://github.com/facebook/react-native/blob/e54ead6556f813fc622fd5e1f27ab2b41fa4f213/React/Base/RCTBridgeModule.h#L155), which is used to call all exported methods.\n\n```objc\n- (void)setUpMethodQueue\n{\n  if (_instance && !_methodQueue && _bridge.valid) {\n    RCT_PROFILE_BEGIN_EVENT(RCTProfileTagAlways, @\"[RCTModuleData setUpMethodQueue]\", nil);\n    BOOL implementsMethodQueue = [_instance respondsToSelector:@selector(methodQueue)];\n    if (implementsMethodQueue && _bridge.valid) {\n      _methodQueue = _instance.methodQueue;\n    }\n    if (!_methodQueue && _bridge.valid) {\n      // Create new queue (store queueName, as it isn't retained by dispatch_queue)\n      _queueName = [NSString stringWithFormat:@\"com.facebook.react.%@Queue\", self.name];\n      _methodQueue = dispatch_queue_create(_queueName.UTF8String, DISPATCH_QUEUE_SERIAL);\n\n      // assign it to the module\n      if (implementsMethodQueue) {\n        @try {\n          [(id)_instance setValue:_methodQueue forKey:@\"methodQueue\"];\n        } @catch (NSException *exception) {\n          RCTLogError(\n              @\"%@ is returning nil for its methodQueue, which is not \"\n               \"permitted. You must either return a pre-initialized \"\n               \"queue, or @synthesize the methodQueue to let the bridge \"\n               \"create a queue for you.\",\n              self.name);\n        }\n      }\n    }\n    RCT_PROFILE_END_EVENT(RCTProfileTagAlways, @\"\");\n  }\n}\n```\n\n## How does JS invoke a method in Native?\n\nI set a breakpoint at   [`[RCTModuleMethod invokeWithBridge:module:arguments:]`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/Base/RCTModuleMethod.mm#L519).\n\n![image-20201217171417579](image-20201217171417579.png)\n\n1. in initialization phase, `nativeFlushQueueImmediate` property is set in the global object of the JavaScript execution context.. [code reference here](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/jsiexecutor/jsireact/JSIExecutor.cpp#L90). `    global.nativeFlushQueueImmediate(queue)` is called in `enqueueNativeCall` from the Javascript side. [code ref.](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/Libraries/BatchedBridge/MessageQueue.js#L318)  Before calling, it makes sure the last Flush is 5 milliseconds ago;  then `nativeFlushQueueImmediate` is triggered.  \n\n```js\n if (\n      global.nativeFlushQueueImmediate &&\n      now - this._lastFlush >= MIN_TIME_BETWEEN_FLUSHES_MS\n    ) {\n      const queue = this._queue;\n      this._queue = [[], [], [], this._callID];\n      this._lastFlush = now;\n      // 🌟\n      global.nativeFlushQueueImmediate(queue);\n    }\n```\n\n2. [`call` function in JSCRuntime](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/jsi/JSCRuntime.cpp#L1151) is invoked when there is a method call from JavaScrip side, then the `host function` is triggered. In this case, the host function is `nativeFlushQueueImmediate` in the C++ realm.\n\n```js\nJSValueRef call(\n        JSContextRef ctx,\n        JSObjectRef function,\n        JSObjectRef thisObject,\n        size_t argumentCount,\n        const JSValueRef arguments[],\n        JSValueRef *exception) {\n  HostFunctionMetadata *metadata =\n          static_cast<HostFunctionMetadata *>(JSObjectGetPrivate(function));\n  JSCRuntime &rt = *(metadata->runtime);\n  ...\n     // 🌟🌟\n     metadata->hostFunction_(rt, thisVal, args, argumentCount));\n  ...\n}\n```\n\n3. See the following C++ lambda is used to create the host function `nativeFlushQueueImmediate`. In side this  C++ lambda,  we can see it calls [callNativeModules](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/jsiexecutor/jsireact/JSIExecutor.cpp#L106).\n\n```c++\n runtime_->global().setProperty(\n      *runtime_,\n      \"nativeFlushQueueImmediate\",\n      Function::createFromHostFunction(\n          *runtime_,\n          PropNameID::forAscii(*runtime_, \"nativeFlushQueueImmediate\"),\n          1,\n          [this](\n              jsi::Runtime &,\n              const jsi::Value &,\n              const jsi::Value *args,\n              size_t count) {\n            if (count != 1) {\n              throw std::invalid_argument(\n                  \"nativeFlushQueueImmediate arg count must be 1\");\n            }\n            callNativeModules(args[0], false);\n            return Value::undefined();\n          }\n      )\n  );\n```\n\nThen [ `callNativeModules` in `JSToNativeBridge`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/jsiexecutor/jsireact/JSIExecutor.cpp#L390) is invoked.\n\n4. The [callNativeModules in `JSToNativeBridge`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/cxxreact/NativeToJsBridge.cpp#L54) firstly parses the `JSON` data to get the `moduleIds`, `methodIds` and `params`, etc.  [source code here](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/cxxreact/MethodCall.cpp#L38).  After constructing `MethodCall` structure, which holds `moduleId`, `methodId`, `arguments`, `callId`, [`callNativeModules` in `ModuleRegistry.cpp`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/ReactCommon/cxxreact/ModuleRegistry.cpp#L220)  is called.\n   \n```c++\n   // This is always populated\n  std::vector<std::unique_ptr<NativeModule>> modules_;\n\n  void ModuleRegistry::callNativeMethod(\n    unsigned int moduleId,\n    unsigned int methodId,\n    folly::dynamic &&params,\n    int callId) {\n  if (moduleId >= modules_.size()) {\n    throw std::runtime_error(folly::to<std::string>(\n        \"moduleId \", moduleId, \" out of range [0..\", modules_.size(), \")\"));\n  }\n  modules_[moduleId]->invoke(methodId, std::move(params), callId);\n  }\n```\n\n`moduleId` is used to look up the `NativeModule` object in a list of modules.  `NativeModule` list is set up in `CxxBridge` initialization phases, which basically is a vector holding module information in C++ realm, transformed from `_moduleDataByID` array in Objc realm. As we know `_moduleDataByID` is a list of  `RCTModuleData` holding registered `RCTBridgeModule` and its instance. \n\n5. It goes to `invoke` in the [`RCTNativeModule.mm`]( https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/CxxModule/RCTNativeModule.mm#L106), which has module info in its private variable `RCTModuleData` object. \n\n6. The[`invoke`](https://github.com/facebook/react-native/blob/306a8adade432ae5c12f0a13130c4e599d64c642/React/CxxModule/RCTNativeModule.mm#L74) function in the [`RCTNativeModule.mm`]( https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/CxxModule/RCTNativeModule.mm#L106) calls [`invokeInner`](https://github.com/facebook/react-native/blob/306a8adade432ae5c12f0a13130c4e599d64c642/React/CxxModule/RCTNativeModule.mm#L135). Inside ` invokeInner`, it get the `RCTBridgeMethod` object from `RCTModuleData` object using `methodId` . [code](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/CxxModule/RCTNativeModule.mm#L155)\n\n\n```objective-c\n  id<RCTBridgeMethod> method = moduleData.methods[methodId]\n```\n\nThen, it [calls](https://github.com/facebook/react-native/blob/306a8adade432ae5c12f0a13130c4e599d64c642/React/CxxModule/RCTNativeModule.mm#L181)  [`invokeWithBridge:module:arguments:`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/Base/RCTModuleMethod.mm#L519) in the `RCTModuleMethod.mm`. \n\n![image-20201029152216662](image-20201029152216662.png)\n\n\n```c++\nid result = [method invokeWithBridge:bridge module:moduleData.instance arguments:objcParams];\n```\n\n[code ref](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/CxxModule/RCTNativeModule.mm#L181)\n\n<img src=\"image-20201029162107074.png\" alt=\"image-20201029162107074\" style=\"zoom:50%;\" />\n\n\n\n7. The  [`invokeWithBridge:module:arguments:`](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/Base/RCTModuleMethod.mm#L519)  uses [ NSInvocation ](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/Base/RCTModuleMethod.mm#L566) to send message to the related `module` object. \n\n>  An `NSInvocation` object contains all the elements of an Objective-C message: a target, a selector, arguments, and the return value.\n\n​\n7.1.  [parse MethodSignature](https://github.com/facebook/react-native/blob/17a8737ecb68f61a14f54bf0e2efeb618f97d326/React/Base/RCTModuleMethod.mm#L204) to init `NSInvocation`.\n\n```objective-c\n_selector = NSSelectorFromString(RCTParseMethodSignature(_methodInfo->objcName, &arguments));\n....  \nNSInvocation *invocation = [NSInvocation invocationWithMethodSignature:methodSignature];\n...\n// set  selector  \ninvocation.selector = _selector;  \n```\n\n7.2, trigger the method in the module  \n\n```objective-c\n [_invocation invokeWithTarget:module];\n```\n\nIn a nutshell,  when JavaScript side calls a method in a specific native module, the indices of the module and method are passed to Objc through JSCRuntime. These information is serialized as JSON object. By looking up the table which holds the information about registered modules and methods, React Native can invoke the specific method in a specific module in the Objective-C realm.  There are some [restrictions](https://github.com/react-native-community/discussions-and-proposals/blob/master/proposals/0002-Turbo-Modules.md#motivation) in this workflow. \n\n![image-20201001143632128](image-20201001143632128.png)\n\n> 1. Native Modules are specified in [a package](https://github.com/facebook/react-native/blob/1e8f3b11027fe0a7514b4fc97d0798d3c64bc895/local-cli/link/__fixtures__/android/0.20/MainActivity.java#L37) and are eagerly initialized. The startup time of React Native increases with the number of Native Modules, even if some of those Native Modules are never used. \n> 2. There is no simple way to check if the Native Modules that JavaScript calls are actually included in the native app. With over the air updates, there is no easy way to check if a newer version of JavaScript calls the right method with the correct set of arguments in Native Module.\n> 3. Native Modules are always singleton and their lifecycle is typically tied to the lifetime of the bridge. This issue is compounded in brownfield apps where the React Native bridge may start and shut down multiple times.\n> 4. During the startup process, Native Modules are typically specified in [multiple packages](https://github.com/facebook/react-native/blob/b938cd524a20c239a5d67e4a1150cd19e00e45ba/ReactAndroid/src/main/java/com/facebook/react/CompositeReactPackage.java). We then [iterate](https://github.com/facebook/react-native/blob/407e033b34b6afa0ea96ed72f16cd164d572e911/ReactAndroid/src/main/java/com/facebook/react/ReactInstanceManager.java#L1132) over the list [multiple times](https://github.com/facebook/react-native/blob/617e25d9b5cb10cfc6842eca62ff22d39eefcf7b/ReactAndroid/src/main/java/com/facebook/react/bridge/NativeModuleRegistry.java#L46) before we finally give the bridge a [list of Native Modules](https://github.com/facebook/react-native/blob/master/ReactAndroid/src/main/java/com/facebook/react/bridge/CatalystInstanceImpl.java#L124). This does not need to happen at runtime.\n> 5. The actual methods and constants of a Native Module are [computed during runtime](https://github.com/facebook/react-native/blob/master/ReactCommon/cxxreact/ModuleRegistry.cpp#L81) using [reflection](https://github.com/facebook/react-native/blob/master/ReactAndroid/src/main/java/com/facebook/react/bridge/JavaModuleWrapper.java#L75). \n\n","tags":["Dive into React Native"],"categories":["iOS","React Native"]},{"title":"iOS main in Assembly","url":"/2020/08/18/20200817-ios-main-in-assembly/","content":"\n### How to see Assemble code in Xcode \n\n`debug` -> `Product -> Action`->  `Assemble`  \"main.m\"\n\n```objective-c\n12 int main(int argc, char * argv[]) {\n13    NSString * appDelegateClassName;\n14    @autoreleasepool {\n15        // Setup code that might create autoreleased objects goes here.\n16        appDelegateClassName = NSStringFromClass([AppDelegate class]);\n17    }\n18    return UIApplicationMain(argc, argv, nil, appDelegateClassName);\n19 }\n```\n\nIt produces a file with 541 lines of code with lots of assembler directives for debugger.  \n\n###  Assembler directives \n\n```assembly\n\t.section\t__TEXT,__text,regular,pure_instructions\n\t.ios_version_min 11, 0\tsdk_version 13, 6\n\t.file\t1 \"/Users/rongyan.zheng/Downloads/AssemblyMain\" \"AssemblyMain/main.m\"\n\t.globl\t_main                   ; -- Begin function main\n\t.p2align\t2\n```\n\nThese are assembler directives, not assembly code. The `.section` directive specifies into which section the following will go.  \n\nNext, the `.globl` directive specifies that `_main` is an external symbol.`.p2align\t2` aligns  the current location in the file to a specified boundary, here it is 2^2, 4 bytes.  \n\n\n\nThen, here comes our `main`  assemble label. \n\n```assembly\n_main:                                  ; @main\nLfunc_begin0:\n\t.loc\t1 12 0                  ; AssemblyMain/main.m:12:0\n\t.cfi_startproc\n; %bb.0:\n\n```\n\n\n\n> The `.cfi_startproc` directive is used at the beginning of most functions. CFI is short for Call Frame Information. A *frame* corresponds loosely to a function. When you use the debugger and *step in* or *step out*, you’re actually stepping in/out of call frames. In C code, functions have their own call frames, but other things can too. The `.cfi_startproc` directive gives the function an entry into `.eh_frame`, which contains unwind information – this is how exception can unwind the call frame stack. The directive will also emit architecture-dependent instructions for CFI. It’s matched by a corresponding `.cfi_endproc` further down in the output to mark the end of our `main()` function.  -- https://www.objc.io/issues/6-build-tools/mach-o-executables/ \n\n\n\n### SP and stack\n\n```assembly\n\tsub\tsp, sp, #48             ; =48\n```\n\nIt sets up a call frame on the stack. Here `sp` refers to the register for stack-pointer. In AArch64 the stack-pointer must be 128-bit aligned; here is 48*8-bit.\n\n![image-20200807093341883](image-20200807093341883.png)\n\n#### Registers \n\n> Processor operations mostly involve processing data. This data can be stored in memory and accessed from thereon. However, reading data from and storing data into memory slows down the processor, as it involves complicated processes of sending the data request across the control bus and into `the memory storage unit` and getting the data through the same channel. To speed up the processor operations, the processor includes some `internal memory storage locations`, called **registers**.\n>\n> The registers store data elements for processing without having to access the memory. A limited number of registers are built into the processor chip. -- https://www.tutorialspoint.com/assembly_programming/assembly_registers.htm \n\nIn ARM 64, the following graph shows the registers' roles.\n\n![image-20200805000244292](image-20200805000244292.png)\n\n- The first eight registers, r0-r7, are used to pass argument values into a subroutine and to return result values from a function. \n- The frame record for the innermost frame (belonging to the most recent routine invocation) shall be pointed to by the `Frame Pointer register` (FP). The lowest addressed double-word shall point to the `previous frame record` and the highest addressed double-word shall contain the value passed in LR on entry to the current function. \n\n#### Stack Structure\n\n> The stack is a `contiguous area of memory` that may be used for storage of local variables and for passing additional arguments to subroutines when there are insufficient argument registers available.The stack implementation is *full-descending*, with `the current extent of the stack` held in the special-purpose register `SP`.   --[Procedure Call Standard for the ARM 64-bit Architecture (AArch64)- AArch64 ABI release 1.0](https://developer.arm.com/documentation/ihi0055/b/)\n\nThe ARM environment uses a stack that—at the point of function calls—is grows downward, and contains local variables and a function’s parameters. The stack is  aligned at the point of function calls.  Figure 1 shows the stack before and during a subroutine call. \n\n![img](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/art/arm_stack.jpg)\n\n Stack frames contain the following areas:\n\n- *The parameter area* stores the arguments the caller passes to the called function or stores space for them, depending on the type of each argument and the availability of registers. This area resides in the caller’s stack frame.\n- *The linkage area* contains the address of the caller’s next instruction.\n- *The saved frame pointer* (optional) contains the base address of the caller’s stack frame.\n- The *local storage area* contains the subroutine’s local variables and the values of the registers that must be restored before the called function returns. See [Register Preservation](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW4) for details.\n- The *saved registers area* contains the values of the registers that must be restored before the called function returns. See [Register Preservation](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW4) for details.\n\nIn this environment, the stack frame size is not fixed.\n\nAnother stack frame layout graph comes from [Procedure Call Standard for the ARM 64-bit Architecture (AArch64)- AArch64 ABI release 1.0](https://developer.arm.com/documentation/ihi0055/b/)\n\n![image-20200805222941420](image-20200805222941420.png)\n\nAbout stack and stack pointer, see more in. \n- [Using the Stack in AArch32 and AArch64](https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/using-the-stack-in-aarch32-and-aarch64)\n- [Using the Stack in AArch64: Implementing Push and Pop](https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/using-the-stack-in-aarch64-implementing-push-and-pop)\n\n### Addressing Mode\n\nAs a beginner, I want to know how the addresses are calculated from the figures within the square brackets\n\nHere, we have to know something about  `addressing modes`. There are several addressing modes that define how the address is formed according to [document s about ARMv8 instructions set](https://developer.arm.com/architectures/learn-the-architecture/armv8-a-instruction-set-architecture/loads-and-stores-addressing)  \n\n- **Base register** - The simplest form of addressing is a single register. Base register is an X register that contains the full, or absolute, virtual address of the data being accessed, as you can see in this figure:\n\n  <img src=\"image-20200807150953454.png\" alt=\"image-20200807150953454\"  />\n\n- **Offset addressing modes** - An offset can be applied optionally to the base address, as you can see in this figure:\n\n  <img src=\"image-20200807151043180.png\" alt=\"image-20200807151043180\"/>\n\n  In the preceding figure, X1 contains the base address and `#12` is a byte offset from that address. This means that the accessed address is` X1+12`. The offset can be either a constant or another register. This type of addressing might be used for structs, for example. The compiler maintains a pointer to the base of struct using the offset to select different members.\n\n- **Pre-index addressing modes** - In the instruction syntax, pre-index is shown by adding an exclamation mark `!` After the square brackets, as this figure shows: \n\n  ![image-20200807151621841](image-20200807151621841.png)\n\n  Pre-indexed addressing is like offset addressing,` except that the base pointer is updated as a result of the instruction`. In the preceding figure, `X1` would have the value X1+12 after the instruction has completed.\n\n- **Post-index addressing modes** - With post-index addressing, the value is loaded from the address in the base pointer, and then the pointer is updated, as this figure shows: \n\n  ![image-20200807151851210](image-20200807151851210.png)\n\n  Post-index addressing is useful for popping off the stack. The instruction loads the value from the location pointed at by the stack pointer, and then moves the stack pointer on to the next full location in the stack.\n\nSo, here comes the next instruction in our `main` function: \n\n```assembly\nstp\tx29, x30, [sp, #32] \n```\n\n`stp` pushes X29 and X30 onto the stack, which means this instruction will store values from `x29` and `x30` to memory where the address is `sp+32`. And in ARMv8, `X29` is for frame pointer, `X30` is used as the Link Register and can be referred to as LR.\n\n![image-20200807103821841](image-20200807103821841.png)\n\n### Store parameters on the Stack\n\n```assembly\nadd\tx29, sp, #32            ; =32\n```\n\nset the value of `x29` as `sp` + `#32`\n\n```assembly\nstur\twzr, [x29, #-4]\nstur\tw0, [x29, #-8]\nstr\tx1, [sp, #16]\n```\n\nstore value from `wzr` to `x29 + #-4`, which means write `x29 + #-4` using 0; \n\n>  The zero registers, ZXR and WZR, always read as 0 and ignore writes.\n\nstore value  from `w0` to `x29 + #-8;`\n\nstore value from `x1` to `sp + #16`.\n\n![image-20200807103920889](image-20200807103920889.png)\n\nMost A64 instructions operate on registers. The architecture provides 31 general purpose registers. Each register can be used as a 64-bit X register (X0..X30), or as a 32-bit W register (W0..W30).   W0 is the bottom 32 bits of X0.\n\n<img src=\"image-20200807155505092.png\" alt=\"image-20200807155505092\" style=\"zoom:50%;\" />\n\nThe choice of X or W determines the size of the operation. Using X registers will result in 64-bit calculations, and using W registers will result in 32-bit calculations. \n\n#### Registers for parameters \n\nThe Arm architecture has some restrictions on how general purpose registers are used.  \n\n`X0-X7` is the parameter/result registers.  x0-x7, are used to pass argument values into a subroutine and to return result values from a function.  The first argument is passed into `X0`, the second argument is in `X1`.  \n\nIn our case, `main` function takes two arguments, so `w0` and `X` are used. \n\n#### Registers for return \n\nWhich register is used for return result is determined by the type of that result:\n\n- If the type, T, of the result of a function is such that\n\n  `void func(T arg)`,  the result is returned in the same registers used as passing arguments. For exmaple\n\n![image-20200807175855759](image-20200807175855759.png)\n\n- Otherwise,  the caller shall reserve a block of memory of sufficient size and alignment to hold the result. The address of the memory block shall be passed as an additional argument to the function in X8.`XR` |`X8`.\n\n  \n\n```assembly\nLtmp0:\n\t.loc\t1 13 16 prologue_end    ; AssemblyMain/main.m:13:16\n\tmov\tx8, #0                    ; copy #0 to x8\n\tstr\tx8, [sp, #8]              ; \n\t.loc\t1 14 22                 ; AssemblyMain/main.m:14:22\n```\n\nThen,  store value from `x8` to `sp + #8`.  \n\n![image-20200807154518025](image-20200807154518025.png)\n\n### Branch instructions and Function calls \n\nSo let's see the next instruction. \n\n```assembly\nbl\t_objc_autoreleasePoolPush\n```\n\n> Ordinarily, a processor executes instructions in program order. This means that a processor executes instructions in the same order that they are set in memory. One way to change this order is to use branch instructions. Branch instructions change the program flow and are used for loops, decisions and function calls.\n>\n> The A64 instruction set also has some conditional branch instructions. These are instructions that change the way they execute, based on the results of previous instructions.       --  https://developer.arm.com/architectures/learn-the-architecture/armv8-a-instruction-set-architecture/program-flow\n\n#### Unconditional branch instructions \n\n> There are two types of unconditional branch instructions; `B` which means Branch and `BR` which means Branch with Register. \n\nThe unconditional branch instruction `B <label`> performs a direct, PC-relative, branch to <label>.\n\nIn our case, the `labe` is  `_objc_autoreleasePoolPush`; `bl\t_objc_autoreleasePoolPush` means we will jump to `_objc_autoreleasePoolPush` routine. \n\n#### Conditional branch instructions \n\nThe conditional branch instruction B.<cond> <label> is the conditional version of the B instruction. The branch is only taken if the condition <cond> is true. The range is limited to +/- 1MB.\n\n#### [Labels for PC-relative addresses](https://www.keil.com/support/man/docs/armasm/armasm_dom1359731174549.htm)\n\n> A label can represent the PC value plus or minus the offset from the PC to the label. Use these labels as targets for branch instructions, or to access small items of data embedded in code sections.\n\n\n\n```assembly\n\tadrp\tx8, _OBJC_SELECTOR_REFERENCES_@PAGE\n\tadd\tx8, x8, _OBJC_SELECTOR_REFERENCES_@PAGEOFF        ;@selector(class)\n\tadrp\tx9, _OBJC_CLASSLIST_REFERENCES_$_@PAGE \n\tadd\tx9, x9, _OBJC_CLASSLIST_REFERENCES_$_@PAGEOFF     ; objc_cls_ref_AppDelegate\n```\n\n- `adrp` is to Address of 4KB page at a PC-relative offset\n\n  I drag the final executable into `hopper`,   the address for `_OBJC_SELECTOR_REFERENCES_@PAGE` is `#0x100009000   `\n\n  ```assembly\n  000000010000621c         adrp       x8, #0x100009000                            ; 0x1000093e0@PAGE\n  0000000100006220         add        x8, x8, #0x3e0                              ; 0x1000093e0@PAGEOFF, &@selector(class)\n  0000000100006224         adrp       x9, #0x100009000                            ; 0x1000093f0@PAGE\n  0000000100006228         add        x9, x9, #0x3f0                              ; 0x1000093f0@PAGEOFF, objc_cls_ref_AppDelegate\n  000000010000622c         ldr        x9, [x9]                                    ; objc_cls_ref_AppDelegate,_OBJC_CLASS_$_AppDelegate\n  0000000100006230         ldr        x1, [x8]                                    ; \"class\",@selector(class)\n  ```\n\n  \n\n```assembly\n\tldr\tx9, [x9]                ; load data into x9 from the value in x9.\n\tldr\tx1, [x8]                ; load data into x1 from the value in x8, which is the address of @selector(class)\n\tstr\tx0, [sp]                ; 8-byte Folded Spill\n\tmov\tx0, x9                  ; move the addreess in x9 into x0, which is the address of objc_cls_ref_AppDelegate\n\tbl\t_objc_msgSend           ; call msgSend, [AppDelegate class]\n\tbl\t_NSStringFromClass      ; call NSStringFromClass \n```\n\n#### The return value and auto release \n\n```assembly\n  mov\tx29, x29\t; marker for objc_retainAutoreleaseReturnValue\n\tbl\t_objc_retainAutoreleasedReturnValue\n  ldr\tx8, [sp, #8]            ; load data into x8 from memory [sp, #8] \n\tstr\tx0, [sp, #8]            ; store data from x0 into [sp, #8], which is the result of _NSStringFromClass\n\tmov\tx0, x8                  ; move data from x8 to x0\n\tbl\t_objc_release\n\tldr\tx0, [sp]                ; 8-byte Folded Reload\n\tbl\t_objc_autoreleasePoolPop\n```\n\n\n\n`str\tx0, [sp, #8] ` means store data from x0 into [sp, #8]. As we mentioned before, for functions with this type `NSString *NSStringFromClass(Class aClass)`, the `x0` is used to store the return result. \n\n### Pass parameters\n\n```assembly\n\tldur\tw0, [x29, #-8]      ; load data into w0 from [x29, #-8]; which is int argc\n\tldr\tx1, [sp, #16]         ; load data into x1 from [sp, #16], where argv is stroed\n\tldr\tx3, [sp, #8]          ; laod data into x3 from [sp, #8], which is the result of  the result of _NSStringFromClass\n```\n\n```assembly\n\tmov\tx8, #0\n\tmov\tx2, x8                ; nil\n```\n\n\n\n```assembly\n\tbl\t_UIApplicationMain    ; call _UIApplicationMain\n\tstur\tw0, [x29, #-4]      \n\tadd\tx8, sp, #8              ; =8\n\tmov\tx0, x8\n\tmov\tx8, #0\n\tmov\tx1, x8\n\tbl\t_objc_storeStrong\n\tldur\tw0, [x29, #-4]\n\tldp\tx29, x30, [sp, #32]     ; 16-byte Folded Reload, reset \n\tadd\tsp, sp, #48             ; =48, reset \n\tret\n```\n\n\n\n`ldp\tx29, x30, [sp, #32]`  this is for reset the `fp` and linker regiseter \n\n`add\tsp, sp, #48 ` means, the call frame for this function is gone. \n\n\n\n![image-20200810095955537](image-20200810095955537.png)","tags":["Popular Article","Debug"],"categories":["iOS"]},{"title":"Address Sanitizer","url":"/2020/08/18/20200817-address-sanitizer/","content":"Memory corruption is hard to debug because it is `hard to consistently reproduce` and `the source of error is often far from its manifestation`. But with powful `Address Sanitizer` tool,  we  could achieve it.  `Addresss Sanitizer` is a LLVM-based debug tool to finds memory corruption at run time with `less overhead` at running time. And it works on OS X, iOS (simulator and device). \n\n### Different kinds of memory corruption \n\n- use after free \n- heap buffer overflow \n- Stack buffer overflow \n- global variable overflow \n- overflows in C++ containers \n- Use after return \n- Use after scope\n\n### How to enable Address Sanitizer\n\n- Edit Scheme \n\n- turn on the `Address Sanitizer` \n\n  ![image-20200816172927364](image-20200816172927364.png)\n\n- re-compile the App \n\nThis can be used together with `Malloc Scribble`.\n\n### Xcode Debuger UI \n\n1. showing errors \n\n   ![image-20200816210717157](image-20200816210717157.png)\n\n2. stacktrace \n\n   <img src=\"image-20200816210812044.png\" alt=\"image-20200816210812044\" style=\"zoom:50%;\" />\n\n3. memory allocation \n\n   ![image-20200816210745829](image-20200816210745829.png)\n\n4. Heap object \n\n   1. faulty addresss \n\n5. Expand Memory View. It shows the allocation and deallocation backtrace of the memory. Also we can see the bytes of the object in the memory \n   1. the black bytes : valid memory \n   2. the grey bytes: invalid memory \n\n![image-20200816213933801](image-20200816213933801.png)\n\nWe can also see the bytes of the memory  by `view Memory of xxx`\n\n![image-20200816213627715](image-20200816213627715.png)\n\nBesides, in the `LLDB`, we can run `memory history` to get the backtrace of the allocation and deallocation. \n\n![image-20200816214150578](image-20200816214150578.png)\n\n## Use Cases \n\n### Heap buffer overflow \n\n![image-20200816211332451](image-20200816211332451.png)\n\ncase from here https://www.youtube.com/watch?v=rJFoMq-RI7c\n\n### Use out of scope stack memory \n\n![image-20200816211144445](image-20200816211144445.png)\n\n`value` is a variable that inside the `if` scope. If you assign its address to `integer_pointer` and  access its memory outside the scope by using  `*integer_pointer` , it triggers `use of out of scope stack memory` \n\n### Use stack memory after return \n\n![image-20200816211204763](image-20200816211204763.png)\n\nIn the c function, `return_address_of_stack` it return `&a`, the address of `a` variable. While `a` is a stack variable in this function, the function returns, the stack frame will be released.  At. that time, if we try to use  `a` again, it triggers `use of stack memory after return`. \n\nUse of deallocated memory \n\n![image-20200816213422013](image-20200816213422013.png)\n\n\n\n## When to Use Address Sanitizer\n\n- You project is mixed with C languages and Swift\n- Memory corruptions and crashes, which are hard to reproduce and find out the root cause\n- General debugging\n\n## Integrated with Test and CI \n\nBecause it is less overhead than other tools and detects bugs at the run time,  we can integrate it with XCode test scheme and CI. \n\n#### In Xcode\n\n- Edit Scheme – Test – Diagnostics tab\n- “Enable Address Sanitizer” checkbox\n- Build and Test\n\n#### Command Line\n\n```\n$ xcodebuild -scheme \"Jogr\" test -enableAddressSanitizer YES\n```\n\n## Under the Hood \n\n### How Address Sanitizer works\n\nWhen we enable the address sanitizer and compile a executable, Xcode pass a flag to Clang when compiling. \n\n```\n-fsanitize=address\n```\n\nAfter building, the instrumented executable will contain memory checks. Besides, at runtime, this binary links with `Asan` runtime dylib that contains more checks and the dylib is required by the instrumentation. \n\n##### How this memory check works? \n\nIt will check the allocations in our process. In the following graph, the blue region is the memory we allocted.  In the right side, it is the `Shadow memory` maintained by `Address saninitzer` , which tracks the real memory in the left side, telling whether the real memory is address-accessible or not.   The `Redzones` are the poisoned memory. \n\n![image-20200816120042864](image-20200816120042864.png)\n\nIf the executable is compiled by enabling the Address sanitizer, every time before it access to memory, there is prefix instruction to check if this memory is`poisoned`.  If it was, the Address Sanitizer will generate a diagnostics report shown above. \n\n![image-20200816120700174](image-20200816120700174.png)\n\nThe following graph shows the process is trying to access to a poisoned memory and it trigger `Crash` and genrate a diagnostic report. \n\n![image-20200816120921377](image-20200816120921377.png)\n\n#### How the lookup table works \n\nIn address sanitizer, the loop up in the shadow memory should be very fast so that it will be less overhead. To achieve that, they main a look up table where every 8 bytes real memory in user process are tracked by 1 byte in the shadow memory. Even so, the loop up table is large. So they don't allocate memory region for the lookup table. Instead, they reserve the  memory region for shadow usage.  \n\n<img src=\"image-20200816121732422.png\" alt=\"image-20200816121732422\" style=\"zoom:50%;\" />\n\nSupposed the address of the real memory usage in the process is `Addr`. The address of the related shadow memory is `Add >> 3 + Offset`. If the value in the bytes in the shadow memory isn't `0`,  we know the real memory is poisoned. \n\n![image-20200816121722926](image-20200816121722926.png)\n\n### The heap object allocation \n\nThe default Malloc implementation layout out objects in memory one after another for optimizing memory consumption.  But address sanitizer replace default Malloc implementation by using it is own allocate implementation, which lays out objects further apart from each other. \n\n![image-20200816123141896](image-20200816123141896.png)\n\nAll the unused memory between objects are marked as poisoned, marked as `red` in the shadow memory.  Once  a object is free, the related shadow memory is marked as `red`, poisoned too.  Also, address sanitizer will delay reuse of free memory. So it can catch the heap buffer overflow, double-free errors, user-free etc. \n\n### Stack variables \n\n![image-20200816150456865](image-20200816150456865.png)\n\nWhen enabling the Address sanitizer and compiling the executable, some red zone will be inserted between two stack variables, so stack red zones are poisoned at the runtime. \n\n### Global variables\n\n![image-20200816151834767](image-20200816151834767.png)\n\nThey do the similar things during the compiling time for the global variables, \n\n## Overhead\n\n- CPU slowdown usually between 2x–5x\n  - In normal case, CPU slowdown 2x-3x. In some edge case, they have seen the slowdown 5x. \n\n- Memory overhead 2x–3x\n- AddressSanitizer uses more real memory than a native run. Exact overhead depends on the allocations sizes. The smaller the allocations you make the bigger the overhead is.\n- AddressSanitizer uses more stack memory. We have seen up to 3x increase.\n\nStill, this overhead is smaller than other tools that can do the same job. \n\n## The difference in Assembly code  \n\nLet's write a simple Objective-c function, and build a executable. \n\n```objective-c\n- (void)testAllocation\n{\n    NSString *f = @\"RY\";\n    NSArray *a = @[@1];\n    NSLog(@\"%@, %@\", f, a);\n}\n```\n\nThe left side is the Assembly code for normal code; the right side is the Assembly code after enabling the Address Sanitizer. \n\n![image-20200816171459459](image-20200816171459459.png)\n\nThe one with Address Sanitizer enabled adds checks. The following is the shadow memory check. If the value in `w3` , the value from the shadow memory is zero. It goes the `loc100004894` label, continue to run. But if not, it will call `imp___stubs____asan_report_store8` to generate the Address sanitizer report. \n\n![image-20200816172007233](image-20200816172007233.png)\n\n\n\n- [Avoiding Buffer Overflows and Underflows](https://developer.apple.com/library/archive/documentation/Security/Conceptual/SecureCodingGuide/Articles/BufferOverflows.html)\n\n- https://developer.apple.com/videos/play/wwdc2015/413\n- https://developer.apple.com/videos/play/wwdc2017/406\n\n- [AddressSanitizer in LLVM doc](https://clang.llvm.org/docs/AddressSanitizer.html)\n- https://www.youtube.com/watch?v=rJFoMq-RI7c","tags":["Debug"],"categories":["iOS"]},{"title":"Tail Call Elimination in iOS","url":"/2020/08/05/20200805-tail-call-elimination/","content":"\n> Tail call optimization, callee reusing the stack of the caller, is currently supported on x86/x86-64, PowerPC, and WebAssembly. It is performed on x86/x86-64 and PowerPC - [lldb](http://llvm.org/docs/CodeGenerator.html#tail-call-optimization)\n\n\n## Basic Knowledge \n\n### Registers \n\n> Processor operations mostly involve processing data. This data can be stored in memory and accessed from thereon. However, reading data from and storing data into memory slows down the processor, as it involves complicated processes of sending the data request across the control bus and into `the memory storage unit` and getting the data through the same channel. To speed up the processor operations, the processor includes some `internal memory storage locations`, called **registers**.\n>\n> The registers store data elements for processing without having to access the memory. A limited number of registers are built into the processor chip. -- https://www.tutorialspoint.com/assembly_programming/assembly_registers.htm \n\nIn ARM 64, the following graph shows the registers' roles.\n\n![image-20200805000244292](image-20200805000244292.png)\n\n- The first eight registers, r0-r7, are used to pass argument values into a subroutine and to return result values from a function. \n- The frame record for the innermost frame (belonging to the most recent routine invocation) shall be pointed to by the `Frame Pointer register` (FP). The lowest addressed double-word shall point to the `previous frame record` and the highest addressed double-word shall contain the value passed in LR on entry to the current function. \n\n### Stack Structure\n\n> The stack is a `contiguous area of memory` that may be used for storage of local variables and for passing additional arguments to subroutines when there are insufficient argument registers available.The stack implementation is *full-descending*, with `the current extent of the stack` held in the special-purpose register `SP`.   --[Procedure Call Standard for the ARM 64-bit Architecture (AArch64)- AArch64 ABI release 1.0](https://developer.arm.com/documentation/ihi0055/b/)\n\nThe ARM environment uses a stack that—at the point of function calls—is grows downward, and contains local variables and a function’s parameters. The stack is  aligned at the point of function calls.  Figure 1 shows the stack before and during a subroutine call. \n\n![img](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/art/arm_stack.jpg)\n\n Stack frames contain the following areas:\n\n- *The parameter area* stores the arguments the caller passes to the called function or stores space for them, depending on the type of each argument and the availability of registers. This area resides in the caller’s stack frame.\n- *The linkage area* contains the address of the caller’s next instruction.\n- *The saved frame pointer* (optional) contains the base address of the caller’s stack frame.\n- The *local storage area* contains the subroutine’s local variables and the values of the registers that must be restored before the called function returns. See [Register Preservation](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW4) for details.\n- The *saved registers area* contains the values of the registers that must be restored before the called function returns. See [Register Preservation](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW4) for details.\n\nIn this environment, the stack frame size is not fixed.\n\nAnother stack frame layout graph comes from [Procedure Call Standard for the ARM 64-bit Architecture (AArch64)- AArch64 ABI release 1.0](https://developer.arm.com/documentation/ihi0055/b/)\n\n![image-20200805222941420](image-20200805222941420.png)\n\n### Passing Arguments\n\n> When functions (routines) call other functions (subroutines), they may need to pass arguments to them. The called subroutines access these arguments as *parameters*. Conversely, some subroutines pass a *result* or return value to their callers. In the ARMv6 environment, arguments may be passed on the runtime stack or in registers; in addition, some vector arguments are also passed passed in registers. Results are returned in registers or in memory. To efficiently pass values between callers and callees, GCC follows strict rules when it generates a program’s object code. - [ARMv6](https://developer.apple.com/library/archive/documentation/Xcode/Conceptual/iPhoneOSABIReference/Articles/ARMv6FunctionCallingConventions.html#//apple_ref/doc/uid/TP40009021-SW8)\n\nThe base standard provides for passing arguments in general-purpose registers (r0-r7)\n\n### Returning Results\n\nThe manner in which a result is returned from a function is determined by the type of that result:\n\n- If the type, `T,` of the result of a function is such that\n\n  `void func(T arg)`\n   would require that `arg` be passed as a value in a register, then the result is returned in the same registers as would be used for such an argument.\n\n- Otherwise, `the caller shall reserve a block of memory of sufficient size and alignment to hold the result`. The address of the memory block shall be passed as an additional argument to the function in `x8`. `The callee may modify the result memory block` at any point during the execution of the subroutine (there is no requirement for the callee to preserve the value stored in x8).\n\n## Tail call Elimination  \n\n### Normal Case \n\nLet's say we have a method `drawRect`, which calls ` CGContextDrawPath`\n\n```objective-c\n- (void) drawRect: (NSRect) rect {\n  // draw stuff\n  ...\n  CGContextDrawPath(_path, kCGStroke);\n}\n```\n\n<img src=\"./image-20200804224933284.png\" alt=\"image-20200804224933284\" style=\"zoom:50%;\" />\n\nThe above picture is the stack right before UIKit calls the `drawRect` method. This graph comes from [WWDC](https://developer.apple.com/videos/play/wwdc2015/412/?time=729). \n\nHere, `fp`  is the[ frame pointer]( https://chortle.ccsu.edu/assemblytutorial/Chapter-28/ass28_4.html)  .`lr` is the `link register`, which holds the next instruction to execute in the caller function( routines) that called the current function(subroutines). So the current function, `subroutines` know how to return to its caller. \n\nWhen UIKit calls `drawRect`, firstly,  `drawRect` will establish its call frame by pushing the `return` address from the link registe(`lr` )and `previous value `of the frame pointer ( `frame Ptr`), on the stack. As we said before,  there are registers store these two data. \n\n```assembly\n+0x00 push {r4, r5, r6, fp, lr}\n```\n\n the frame poniter, `fp` , will store a new address,  the value in `sp`  + 12. Then, `fp` will be set up on a new base just as the following graph shows. \n\n```assembly\n+0x02 add fp, sp, #12\n```\n\n<img src=\"./image-20200805094701153.png\" alt=\"image-20200805094701153\" style=\"zoom:50%;\" />\n\n\n\nThen, `drawRect` makes room for storing local variables,  and has its call frame on the stack. \n\n```assembly\n+0x04 sub sp, #180\n```\n\n<img src=\"./image-20200805094754924.png\" alt=\"image-20200805094754924\" style=\"zoom:50%;\" />\n\nNext, `drawRect` calls `CGContextDrawPath`,  which will also set up its call frame on the stack. \n\n<img src=\"./image-20200805094818787.png\" alt=\"image-20200805094818787\" style=\"zoom:50%;\" />\n\n> [The way time profiler works, it uses a service in the kernel ](https://developer.apple.com/videos/play/wwdc2015-412/?time=700)[that will sample what the CPUs are doing ](https://developer.apple.com/videos/play/wwdc2015-412/?time=703)[at about 1000x per second.](https://developer.apple.com/videos/play/wwdc2015-412/?time=705)In this case, if we take a sample, we see that we're running inside of context draw path.\n>\n> [Then the kernal looks at the frame Pointer register to see ](https://developer.apple.com/videos/play/wwdc2015-412/?time=714)[where the base of that function's frame is ](https://developer.apple.com/videos/play/wwdc2015-412/?time=718)[and find the return address of who called it.](https://developer.apple.com/videos/play/wwdc2015-412/?time=721) \n\n### Backtrace \n\nSo, what is Backtrace? Well,  by using frame pointer that was pushed on the stack,  we know the the base address of the caller’s stack frame. Since every call frame of the method has store the base address  of its caller's stack frame, we can use this to go through the chain of the call frames in this stack.  \n\n<img src=\"/image-20200805094837070.png\" alt=\"image-20200805094837070\" style=\"zoom:50%;\" />\n\n### Optimized case \n\nIn `drawRect`, after calling `CGContextDrawPath` , it is going to  `return`, which means actually it will `pop stack frame`, `restore fp`, and then `jump back to caller` . \n\n<img src=\"image-20200805231739717.png\" alt=\"image-20200805231739717\" style=\"zoom:50%;\" />\n\nSince `CGContextDrawPath` needs nothing from `drawRect`, the params it needs arn't from the call frame of `drawRect` , the compiler does an optimization here.  It rearranges the code as follow. I `pops stack frame` of `drawRect` firstly, `restores fp`,  then calls  `CGContextDrawPath` . So it doesn't have to `jump back to caller`  , the address stored in the `lr` register. \n\nFigure 1. it is going to  `pops stack frame`\n\n![image-20200805232447437](image-20200805232447437.png)\n\nFigure 2. after  poping stack frame of `drawRect`, the call frame of drawRect doesn't exist on the Stack any more.  Then `sp` moves.\n\n![image-20200805232642308](image-20200805232642308.png)\n\nFigure 3. after restoring `fp` to the base address of its caller's frame pointer, the `return address` and `frame ptr` of `drawRect` don't exist on the Stack any more.  Then `sp` moves.\n\n![image-20200805232724011](image-20200805232724011.png)\n\nFinally, it calls `CGContextDrawPath`, which establish its own call frame on the Stack. So, the stack is like this now. \n\n```assembly\n+0x76 b.w \"CGContextDrawPath$shim\"\n```\n\n<img src=\"image-20200805234014273.png\" alt=\"image-20200805234014273\" style=\"zoom:50%;\" />\n\n### The difference in the Call Tree \n\nThe left side is the normal case, the right side is the optimized case where then call frame of `drawRect` will be removed from the stack in the optimized case. It looks like `CGContextDrawPath` is directedly called from `drawLayout:inContext` .\n\n![image-20200805234610955](image-20200805234610955.png)\n\n### The benifit of Tail call Elimination \n\n- Saves stack memory \n- Keeps caches hot, and reuses the memory\n- Best for recursive function tail calls, especially `tail call recursive code`, where a function or method calls itself as the last line of code and then returns.  With Tail call Elimination, the stack won't grow so much that we can get hight performances.\n\n### Disabling\n\nset this compiler flag when building,  you can get better call tree in the Time Profiler when profiling app. \n\n- CFLAGS=“-fno-optimize-sibling-calls\"\n\n### Call Semantics\n\nThere is a useful trick to indentify if this is a Tail call Elimination case. That is to\n\n`look at the disaeembly and call sight of the last call`\n\n![image-20200806092252238](image-20200806092252238.png)\n\n- In normal call, it uses `a Branch and Link family of instructions` (bl)\n\n  - Sets `lr` to  next address and jumps to the caller\n\n    ```assembly\n    Caller: +0x174 blx \"CGContextDrawPath $shim”\n    ```\n\n- In optimized call, Tail Calls use `simple branches` (b) , directedly jump into the function\n\n  ```assembly\n  Caller: +0x174 b.w \"CGContextDrawPath $shim”\n  ```\n\n  ","tags":["Debug","LLDB"],"categories":["iOS"]},{"title":"Behind the Scenes of the Xcode Build Process","url":"/2020/07/05/20200705Behind-the-Scenes-of-the-•Xcode-Build-Process/","content":"\n> Most contents come from https://developer.apple.com/videos/play/wwdc2018/415 \n\nThe new building system introduced in Xcode 10 is written by Swift from scratch, and brings lots of improved performance and reliability.  So what happens when we press `CMD + B` in Xcode? \n\nIn general, Xcode has to do tasks like preprocess source files and compile them by compiler,  link source code by linker, copy and process resources like headers, asset catalogues and storyboards, And finally code sign and maybe even do some custom work in a shell script or a make file like building API documentation for your framework or running code linting and validation tools.\n\n![image-20200705224132928](image-20200705224132928.png)\n\n## Build Task dependency and execution order \n\nBuilding tasks are executed in a particular order. \n\n<img src=\"image-20200705170528761.png\" alt=\"image-20200705170528761\" style=\"zoom:50%;\" />\n\nThe building system use the dependency information to determine which tasks should be run and what task can be run in parallel.  This is called `dependency order`.  \n\n We know that a compiler can produce `.o` files from `.m` files. Then a linker consumes a number of object files and produces executable or library output. The following graphic shows the dependency info between compilation and linking tasks.  \n\n![image-20200705170723485](image-20200705170723485.png)\n\n### Build tasks are executed in dependency order \n\n1. The  building system will process the project and represented building tasks as a Directed Graph \n\n> What happens when you press build? So the first step is for the build system to take the build description, your Xcode project file.Parse it, take into account all the files in your project, your targets and the dependency relationships.Your build settings, and turn it into a tree-like structure called a directed graph.\n>  And this represents all the dependencies between the input and output files in your project and the tasks that will be executed to process them.\n\n![image-20200705172316201](image-20200705172316201.png)\n\n2. Then the low-level execution engine get the dependency specifications from the above graph and figures out which tasks to execute.\n\n   <img src=\"image-20200705225725510.png\" alt=\"image-20200705225725510\" style=\"zoom:80%;\" />\n\n### Discovered Dependencies \n\nWhen clang compile `PetController.m` source file into object file, `PetController.d` file  is also generated, which contains a listing of information about which header files were included by that source file. Next time you build, if you change any of the header files that `PetController.d` includes, the building system will recompile `PetController.m`. \n\n<img src=\"image-20200705225819662.png\" alt=\"image-20200705225819662\" style=\"zoom:50%;\" />\n\n\n\n### Incremental builds\n\nHaving accurate dependency information is very important in order for incremental builds to work correctly and efficiently, in this case,  the build system only execute a subset of the tasks on the building tasks graph\n\n**how does the build system actually detect changes?**\n\n1. Each time in the building graph has a signature, which computed from stat info of inputs and other task metadata. \n2. Building system tracks signatures of current and previous build, and compared them to determine whether a task should be run. \n\nFor example, in the following picture, building system only has to run these 3 highlight tasks when only `PetViewVontroler.m` changed\n\n![image-20200705231435967](image-20200705231435967.png)\n\n## How can we help the build system? \n\nThe answer is to handle the dependency properly so that the build system can order tasks correctly and build in parallel to save time. \n\n#### Where do dependencies come from? \n\n- Built in. The build system ships with rules for the compiler, the linker, the asset catalogue and story board processors and so on.\n   And these rules define what kind of files are accepted as inputs as well as what outputs are produced.\n\n- Target dependencies, which roughly determine the order in which targets are built.\n\n  <img src=\"image-20200705232141133.png\" alt=\"image-20200705232141133\" style=\"zoom:50%;\" />\n\n- Implicit dependencies \n\n  <img src=\"image-20200705232159289.png\" alt=\"image-20200705232159289\" style=\"zoom:50%;\" />\n\n- Build phase dependencies.  The tasks associated with each of these phrases are usually running groups according to the order in which the phases are listed. But the build system might ignore that order if it knows better.\n\n  <img src=\"image-20200705232220121.png\" alt=\"image-20200705232220121\" style=\"zoom:50%;\" />\n\n- Scheme order dependencies. \n\n  If you have the parallelize build check box enabled in your scheme settings, you get better build performance and the order of your targets in your scheme doesn't matter.  However, if you turn parallelize build off, Xcode will attempt to build their, your targets in the order you listed them in the build action of the scheme one by one.\n  <img src=\"image-20200705232238281.png\" alt=\"image-20200705232238281\" style=\"zoom:50%;\" />\n\n#### What we can do? \n\n- Declare inputs and outputs to help the build system avoid rerunning the script tasks unnecessarily\n\n  <img src=\"image-20200705232718754.png\" alt=\"image-20200705232718754\" style=\"zoom:50%;\" />\n\n- Avoid Auto-link for project dependencies.  \n\n  > This setting allows the compiler to automatically link to the frameworks corresponding to any modules you import without having to explicitly link them in your link library's build phase. However, it's important to note that auto-link does not establish dependency on that framework at the build system level. So it won't guarantee that the target you depend on is actually built before you try to link against it.\n\n  <img src=\"image-20200705232921705.png\" alt=\"image-20200705232921705\" style=\"zoom:50%;\" />\n\n- Add explicit dependencies \n-  You might also need to create project references by dragging and dropping another Xcode project into your project's file navigator in order to reveal the targets of other projects you depend on.\n\n## [Clang compiler](https://clang.llvm.org/)\n\n### Header map \n\n> `Header map` is used by the Xcode build system to know where the header files are.\n\nIn Objective-C, a header file is a promise, saying that the implementation exists somewhere else. If you only update the `header` file, adding a new function A,  without implementation of the function in `m` file, you broke your promise. Then you use function A in class B.   This doesn't break during compile time, because compiler trusts the promise, saying that there is a function A symbol exists, but during link,  we usually got `symbol undefined` error. \n\n### 1. How does Clang find your header files? \n\nWe can copy the arguments from the Xcode building log when Clang compiles a single `.m` file, then using command line to see more details. \n\n<img src=\"image-20200705234147883.png\" alt=\"image-20200705234147883\" style=\"zoom:50%;\" />\n\n```\n clang <list of arguments> -c Cat.mm -o Cat.o -v\n```\n\n\n\nFirst, Clang will start searching the header in header map files. \n\n<img src=\"image-20200705234506914.png\" alt=\"image-20200705234506914\" style=\"zoom:50%;\" />\n\n<img src=\"image-20200705234528306.png\" alt=\"image-20200705234528306\" style=\"zoom:50%;\" />\n\n#### What are header maps \n\n<img src=\"image-20200705234700573.png\" alt=\"image-20200705234700573\" style=\"zoom:50%;\" />\n\n\n\nIn the header map, for the first two keys `PetKit.h` and `Cat.h` , it just simply append the framework name, make them as `PetKit/PetKit.h` and `PetKit/Cat.h`. This keep existing projects working when you use `import <Cat.h>` or `import Cat.h`,  but there might be issues down the road with Clang modules.  So it is recommended that you always `specify the framework name` when you include a public or private header file from your own framework. \n\n#### Suggestion for importing headers explicitly in your source code to help Clang find the header:  \n\n- Always explicit a framework name when you introduce a public and private header \n- always add the header to the project \n- Always use unique name for header avoid shadowing other headers \n\n### 2. How does Clang find system header files? \n\n`Headermap` is only for developers' code. So, in the case of finding system header files, Clang focus on two directories. \n\n```\n$(SDKROOT)/usr/include \n$(SDKROOT)/System/Library/Frameworks.(framework directory).\n```\n\nTake `import <Foundation/Foundatoin.h>` as an example, Clang appends `Foundation/Foundation.h` to the `(SDKROOT)/usr/includ`, and search the header in this path.\n\n```\n$(SDKROOT)/usr/include/Foundation/Foundation.h\n```\n\nIf it doesn't find the header under `$(SDKROOT)/usr/include ` ,  it continues to find header file in framework directory. \n\n```\n$SDKROOT/System/Library/Frameworks/Foundation.framework/Headers/Foundation.h\n```\n\n### Process your file \n\nXcode -> Product ->. Perform Action -> Preprocess \"\". This is the action to create preprocessed file for us, where the `import ...`  statement is substituted with the contents of that file.\n\n```\n#import <Foundation/Foundation.h>\n```\n\nClang has to find and process over 800 header files for this single include statement. That's over 9 megabyte of source code that has to be parsed and verified.\n\nAfter preprocessing: \n\n![image-20200706000118839](image-20200706000118839.png)\n\nHow does Clang do to avoid these redundant and heavy job?  \n\n### Clang module  \n\nTo speed up the building,  by using module, Clang can parse the header only once and store the information `in the disk`, then `reuse the cache` next time. \n\n In order to achieve this, Clang module should have  properties. \n\n- Context-free \n\n  ignore the context-related statement. Like, macro definitions\n\n  ![image-20200706091410725](image-20200706091410725.png)\n\n- Self-contained \n\n  have to specify all the dependencies.\n\n#### Module Map \n\n> A Module Map describes how a certain set of header files translate onto your module.\n\nThis is the `module map` file for Foundation.framework. \n\n<img src=\"image-20200706092447210.png\" alt=\"image-20200706092447210\" style=\"zoom: 50%;\" />\n\n- It obviously describes what is the name of the module which is, Foundation.\n\n- it also specifies what headers are part of this module.  `Foundation.h` is a umbrella header.  If you want to find `NSString` header, you have to look into `Foundation.h` file. \n\n  <img src=\"image-20200706091927374.png\" alt=\"image-20200706091927374\" style=\"zoom:50%;\" />\n\n#### Build Module \n\nWhile building the foundation module, we have to build its dependency too. \n\n<img src=\"image-20200706095037818.png\" alt=\"image-20200706095037818\" style=\"zoom:50%;\" />\n\n#### Module Cache\n\n```\n$ clang -fmodules —DENABLE_CHINCHILLA=1 ...\n```\n\nThe command line arguments for building a module can affect the content of your module. Clang will hash all those arguments and store the modules we created for this particular compiler invocation in a directory matching that hash.\n\n<img src=\"image-20200706095441247.png\" alt=\"image-20200706095441247\" style=\"zoom:50%;\" />\n\n## How about Swift \n\nWhen compiling Objective-C files,  the compiler compiles each file separately and in parallel, by process the `import` statement, and then compiling the file. As we know, unlike Objective-C, Swift doesn't have headers. So First, the compiler has to find declarations both within the Swift target and also coming from Objective-C.  Further, it has to generate interfaces describing the contents of the file. \n\n### Finding declarations \n\n- Within a Swift target \n\n  In the following example, the compiler will check the type in the `PetView`'s initializer ', firstly, it parses the `PetView` and knows the declaration of the initializer is well formed. And then, it checks the call inside the \tPetViewController`. \n\n![image-20200709093711492](image-20200709093711492.png)\n\n​\tSo, actually, when compiling one Swift file, the compiler will parse all the other Swift files in the target. When compiling files separately and in parallel, it causes repeated parsing all files to find declarations.\n\n#### ![image-20200709095907259](image-20200709095907259.png)\n\n In order to improve performance, Xcode 10 combines the files into groups to reuse parsing within a group, and only repeat parsing across groups.\n\n![image-20200709095800665](image-20200709095800665.png)\n\n- Find declarations from Objective-C \n\n  In fact, `Swiftc` compiler embeds `clang`, so   we can can import clang frameworks directly\n\n  > 1. In any target, when you import an Objective-C framework, the importer finds declarations in the headers exposing Clang's module map for that framework.\n  > 2. Within a framework that mixes Swift and Objective-C code, the importer finds declarations in the umbrella header.\n  > 3. Within applications and unit test bundles,  you can find declaration from the target's bridging header.\n\n### Generating interface \n\n- How your Objective-C header will be imported into Swift\n\n  In this `PetViewController.h`, you use the button in the top-left corner of the source editor, see `generated interface`. \n\n  ![image-20200710110626097](image-20200710110626097.png)\n\n- To use Swift in Objective-C \n\n  ![image-20200710112907949](image-20200710112907949.png)\n\n  - For classes extending NSObject and methods/properties marked `@objc`\n  - Apps and unit tests: both public and internal declarations\n  - Frameworks: Only `public declarations`\n  - Compiler ties Objective-C class to mangled Swift class name. The Objective-C name includes the module name `PetWall` . This is to prevent conflict when two modules define class with same name\n  - You can also use `@objc(Name`) to provide custom name — but must not conflict!\n\n- To use Swift in other Swift targets\n\n  - Must firstly import other modules to see their declarations, because in Swift, a module is a distributable unit of declarations.\n\n  - Can import Objective-C modules. \n\n  - In Xcode each `Swift target` produces `a separate module`, so your app target does.\n\n### swfitmodule vs header\n  `swfitmodule` file is serialized, binary representation of module’s declarations, which will be deserialised by compiler  to check the types when you use them. So this `swfitmodule` is a bit like `like a generated Objective-C header`. But instead of text, it's a binary representation. Besides, it does include the names and types of `private declarations` so that we can refer to them in the debugger. In addition, it includes the `bodies of inlineable`functions`,  like `static inline function`s in Objective-C  header\n\n    ![image-20200710113202143](image-20200710113202143.png) \n\n  ![image-20200709100603559](image-20200709100603559.png)\n\n   For incremental builds, the compiler produces partial Swift module files and then `merges` them into a single `swift module` file, and  a single Objective-C header. \n\n### In summary:\n\n- Swift uses Objective-C declarations by Bridging header.\n- Objective-C uses Swift declarations by Generated header.\n- In Objective-C Clang find where the header file is by header map files.  \n- In Swift, `swfitmodule` is a bit like like a generated Objective-C header\n\n![](generated_header.png)\n\n## Linker \n\n### What is Linker? \n\nLinking is the final task in building an executable Mach-O. What it does it to combine the output of all compiler invocations into a executable. \n\nTake two kinds of input files \n\n- Object files (`.o`)\n- Libraries (`.dylib`, `tbd`, `.a`)\n\n###  Symbols \n\n> A symbol is a name for a fragment of code or data, which may reference other symbols. \n\n- Symbols can have attributes on them that alter the linker’s behavior, like `Weak symbols`. \n\n- Languages often encode data into a symbol `mangling` the symbol\n\nweak symbols \n\n### Object Files \n\nObject file, `.o` file is the output of individual compiler actions. A non-executable Mach-O file containing code and data fragments. \n\n- Each fragment is represented by a symbol. \n- Fragment may reference `undefined` symbol. \n\n### Libraries\n\n>  Libraries define symbols that are not built as part of your target\n\n- Dylibs: Dynamic libraries\n\n  - Mach-O file that exposes code and data fragments for executables to use. Those are distributed as part of the system,  and a number of you also use your own frameworks\n\n- TBDs: Text Based Dylib Stubs\n\n  - Only contains symbols. \n\n    1. a stub dylib  where we delete the bodies of all of the symbols and we just have the names.\n    2. a textual representation of them that are easier for us to use\n\n    ```\n    ---\n    archs:           [ armv7, armv7s, arm64 ]\n    platform:        ios\n    install-name:    /usr/lib/libsqlite3.dylib\n    current-version: 216.4\n    compatibility-version: 9.0\n    exports:         \n      - archs:           [ armv7, armv7s, arm64 ]\n        symbols:         [ __sqlite3_lockstate, __sqlite3_purgeEligiblePagerCacheMemory, \n                           __sqlite3_system_busy_handler, __sqlite_auto_profile, \n                           __sqlite_auto_profile_syslog, __sqlite_auto_trace, \n                           __sqlite_auto_trace_syslog, _sqlite3OsShmHasMultipleLinks, \n                           _sqlite3OsShmRenamedWhileOpen, _sqlite3OsShmWasTruncated, \n                           _sqlite3OsShmWasUnlinkedWhileOpen, _sqlite3VersionNumber, \n    ```\n\n    from [stackoverflow](https://stackoverflow.com/questions/31450690/why-xcode-7-shows-tbd-instead-of-dylib)\n\n- Static archives\n\n  - An archive of multiple `.o` files built with the archive tool. `ar` tool. [ar](https://linux.die.net/man/1/ar)\n  - It ends with `.a` suffix, and is something like ZIP or TAR archive.\n  - Only the `.o` files with symbols you reference are included in your app\n\n  see more  [here](https://www.vadimbulavin.com/static-dynamic-frameworks-and-libraries/)\n\n### Example \n\nThe left side is the source, the right side is the object file.  \n\nFirstly, let's look at the `purrFile` variable, it is `static`  , and  `nonexported` name.  So it doesn't appear in the object file.  \n\n<img src=\"image-20200710150601150.png\" alt=\"image-20200710150601150\" style=\"zoom:50%;\" />\n\nThen, here comes  an actual symbol `-[Cat purr]`. \n\n![image-20200710150636666](image-20200710150636666.png)\n\nThen, we see two instructions to pass the variable `purrFile` into `playSound` function. It is because,  we don't have concrete address for  `purrFile` and we don't know where this string is going to end up in the final executable.  But in  `ARM64`, it could take at most two instructions.  \n\n-  [adrp](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/ADRP) \n\nSo the compiler leaves the symbolic values `PAGE` and `PAGEOFF` that the linker will come in and fix up later.\n Finally,  we've loaded that string into register  `x0` . \n\n![image-20200710150648959](image-20200710150648959.png)\n\n`__Z9playSoundPKc`  is a C++ `demangle symbol`  \n\n![image-20200710150707825](image-20200710150707825.png)\n\n\n\n![image-20200710154006829](image-20200710154006829.png)\n\nWhen linking, linker takes a number of object files as input, and create a file to put them in.  In the `__TEXT` segment, it copies the executable code from the object file.  Then, in another segment, it copy the string. Now, the linker knows the absolute addresses of the string symbol, it will rewrite the instruction using a specific address. Meanwhile, the second instruction just went away, it replaced it with a null instruction `that does nothing`. [nop](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/NOP?lang=en)\n\n\n\n![image-20200710154246392](image-20200710154246392.png)\n\n Then the linker has to resolve the `undefined symbol`, `__Z9playSoundKc`.  \n\n<img src=\"image-20200710155242689.png\" alt=\"image-20200710155242689\" style=\"zoom:50%;\" />\n\nWe start looking through the `.o` file in the `.a` archive file, and found out matching symbol for `playSound`. Then, linker put this symbol into the `PetKit`.   While copying code, it rewrite`_open` symbol as `_open$stub`. Why? because `_open` is in the lib system TBD file, which means it is in the system library. The linker needs to put more information in the Application executable file to make it call this function properly. \n\nSo, it makes a fake function, `_open$stub`  , where it actually loads from the`$open` pointer and jumps to it. \n\n- [bl](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/BL?lang=en)\n- `ldr` (load register) loads data from a memory location into a register. \n- [br](https://developer.arm.com/documentation/dui0802/b/A64-General-Instructions/BR?lang=en)\n\n![image-20200710160920246](image-20200710160920246.png)\n\n![image-20200710161911500](image-20200710161911500.png)\n\n- [Building faster in Xcode](https://developer.apple.com/videos/play/wwdc2018/408)\n- [build time optimization](https://www.onswiftwings.com/posts/build-time-optimization-part1/)\n- [The build process](https://www.objc.io/issues/6-build-tools/build-process/)\n- [The compiler](https://www.objc.io/issues/6-build-tools/compiler)\n- [swift-llbuild](https://github.com/apple/swift-llbuild)\n- [Understanding Xcode Build System](https://www.vadimbulavin.com/xcode-build-system/)\n- [iOS Assembly Tutorial](https://www.raywenderlich.com/2705-ios-assembly-tutorial-understanding-arm#toc-anchor-001)\n","tags":["LLDB","Building"],"categories":["iOS"]},{"title":"Advanced debug in Xcode and LLDB","url":"/2020/06/07/20200607-Advanced-debug-in-Xcode-and-LLDB/","content":"\n# Advanced debug in Xcode and LLDB \n\nhttps://developer.apple.com/videos/play/wwdc2018/412 \n\nThis session is awesome! \n\n## Configure behaviors to dedicate a tab for debugging\n\nIn `Prefernece` -> `Behaviors` ,  we can custom the debugging tab for ourselves. For example, choose `Show tab named` , fill in the name and choose `active window` . We will have a independent debug tab. \n\n![image-20200601222857985](412/image-20200601222857985.png)\n\n\n\n<img src=\"media/15902152252875/image-20200607112605302.png\" alt=\"image-20200607112605302\" style=\"zoom:50%;\" />\n\n## LLDB expressions can modify program state\n\nBy using  auto-continuing breakpoints with debugger commands to inject code live, you can inject expression, change state or logic without compiling the project.  \n\n**How to do it? **\n\n- Click `Edit BreakPoint...`\n\n- Click `add action` ; the default option is `Debugger Command`  we can write some `LLDB` command here\n\n- Choose the `Automatically continue`, it will not pause when trigger this breakpoint. \n\n  \n\n  <img src=\"media/15902152252875/image-20200607111532596.png\" alt=\"image-20200607111532596\" style=\"zoom:50%;\" />\n\n\n\n<img src=\"media/15902152252875/image-20200601224246210.png\" alt=\"image-20200601224246210\" style=\"zoom:50%;\" />\n\n\n\n## Symbolic Breakpoint \n\n`Symbolic Breakpoint` is one of my favorite tools to debug issues caused by others' framework.\n\nIn the  `Breakpoint navigator` , choose `Symbolic Breakpoint` .  \n\n<img src=\"412/image-20200607113135963.png\" style=\"zoom:50%;\" />\n\nFill in any signature of the `Objective-c` method you want. \n\n<img src=\"412/image-20200607113105829.png\" style=\"zoom:50%;\" />\n\n## “po $arg1” ($arg2, etc) in assembly frames to print function arguments\n\n<img src=\"412/image-20200601224622911.png\" style=\"zoom:50%;\" />\n\nIn this case,  we use `Symbolic Breakpoint` to hit the `setText:` in `UILabe`, but we don't have the source code of `UIKit`. When the method is hit, we are in an assembly frame, we can use `$arg` to inspect the parameters.  `$arg1` is `self` pointer. `$arg2` is the  `selector` of the method. Others are  arguements to the method. [doc for objc_msgSend](https://developer.apple.com/documentation/objectivec/1456712-objc_msgsend#parameters)\n\n<img src=\"media/15902152252875/image-20200601224723843.png\" style=\"zoom: 50%;\" />\n\n\n\n**Noted**:  we have to do typecast for the `$arg2` , which is a `Slector` . \n\n<img src=\"media/15902152252875/image-20200601224918951.png\" alt=\"image-20200601224918951\" style=\"zoom:50%;\" />\n\n## Create dependent breakpoints using “breakpoint set --one-shot true”\n\nIf a Breakpoint is frequently hit, Like the above breakpoint `[UILabel setText:]`,  usually we will edit `conditions` for this breakpoint. And then, this `Breakppint` will be hit only when the expression for the condition is true.  However, when we don't a property to make the `condition expression`.   There is another way.  We can add action `one-shot symbolic breakpoint` in `a specific breakpoint`, where it will be hit only once in the proper time. \n\n>  The one shot breakpoint is a temporary breakpoint that only exists until it's triggered and then it's automatically deleted.\n\n\n\n<img src=\"media/15902152252875/image-20200607115734569.png\" alt=\"image-20200607115734569\" style=\"zoom:67%;\" />\n\n- Set  a break point in line 96, where we might don't want a break, but we can `configure this breakpoint` to actually set the `symbolic breakpoint` in UI label set text . \n- choose `automatically continue` \n\n- Then add action , `breakpoint set --one-shot true --name \"[UILabel setText:]\"`.  This `one-shot symbolic breakpoint` is activated only after this breakpoint in line 96 is hit.  \n\n\n\nHow magical the dependent breakpoints are!\n\n\n\n## Skip lines of code \n\nBy `dragging` Instruction Pointer, the green handler in the following picture,  we can skip lines of code. It means, these lines of  code will not be executed. \n\n![image-20200607123358909](media/15902152252875/image-20200607123358909.png)\n\n\n\nOr we can use `action` int the breakpoint to skip this line of code for us. \n\n<img src=\"media/15902152252875/image-20200607123639829.png\" alt=\"image-20200607123639829\" style=\"zoom:50%;\" />\n\n\n\nAfter doing that, we can add `expression` to add new expressions, like calling other functions. \n\n<img src=\"media/15902152252875/image-20200607123845152.png\" alt=\"image-20200607123845152\" style=\"zoom:50%;\" />\n\n\n\n## Pause when variables are modified by using watchpoints\n\n\n\n- filter the variable we want using `fitler` \n- click `Watch attempts` \n\n<img src=\"412/image-20200607124534515.png\" style=\"zoom:50%;\" />\n\nThen, we create a `Watchpoint` , which can be seen in the `breakpoint navigator`\n\n<img src=\"412/image-20200607124622132.png\" style=\"zoom:50%;\" />\n\n## Evaluate Obj-C code in Swift frames with `expression -l objc -O -- <expr>`\n\nIn swift frames, we can't use `pointers` or private func as we do in  obj-c frames. So here comes ``expression -l objc -O -- <expr>`.  This can help use them as we do in obj-c frames.  \n\n```\n// In swift\nexpression -l objc -O -- [`self.view`  recursiveDescription]\n\n// In Obj-c \n[self.view  recursiveDescription]\n```\n\nBy using the  `command alis` , we can short cut it. \n\n```\ncommand alis poc expression -l -objc -O --\n```\n\n![image-20200607141219843](media/15902152252875/image-20200607141219843.png)\n\n\n\n## Flush view changes to the screen using “expression CATransaction.flush()”\n\n#### unsafeBitCast\n\nWe can use `unsafeBitCast`  in Swift.  To do the type cast, we have to provide the correct type. \n\nPrint its property or change its property: \n\n![image-20200607142019406](media/15902152252875/image-20200607142019406.png)\n\nUse `CATransaction.flush` to apply the view module changes to the screen's frame buffer. \n\n## Add custom LLDB commands using aliases and scripts. Alias examples:\n\n- download nudge LLDB script provided by the Apple. https://developer.apple.com/videos/play/wwdc2018/412/ \n- Add to `~/.lldbinit`\n- Add  custom alias in the lldbinit\n\n![image-20200607143100209](media/15902152252875/image-20200607143100209.png)\n\n```\ncommand alias poc expression -l objc -O --\ncommand alias flush expression -l objc -- (void)[CATransaction flush]\n```\n\n## Customizing Data Formatters\n\nhttps://developer.apple.com/videos/play/wwdc2019/429","tags":["Debug","LLDB"],"categories":["iOS"]},{"title":"Beyond \"po\"","url":"/2020/06/07/20200607-beyond-po/","content":"\n> https://developer.apple.com/videos/play/wwdc2019/429 \n\n## po command\n\nWe usually use `po` to print object description, which does the same job as `expression --object-description`. \n\n### Alias the command  \n\nWe can also use `command alias` to custom it. like \n\n`command alias my_po expression --object-description` ![img](15902187135968.jpg)\n\n### Custom the output  \n\nWe can add `debugDescription` to custom the output when using `po`\n\n![image-20200607171902758](image-20200607171902758.png)\n\n### Others jobs po can do \n\n![image-20200607172607792](image-20200607172607792.png)\n\n\n### What LLDB does behind the `Po` command\n\n![img](15902307367967.jpg?lastModify=1591521218)\n\n## p command\n\n```\np is a alias of `expression\n```\n\n![-w398](15902310620901.jpg?lastModify=1591521218)\n\nThe result of LLDB is given a increasing name, such as `$R1` and `$R2` \n\n![-w509](15902311269458.jpg?lastModify=1591521218)\n\n## Dynamic type resolution\n\n![img](15902347284185.jpg?lastModify=1591521218)\n\n> In Swift, the static representation of a type in the source code and the dynamic type at the runtime, aren't necessarily the same. For example, a variable might be declared using a protocol of this type. In this example, the static type of `cruise` is `Activity`. But at runtime, the variable will have an instance of type `Trip` which is the dynamic time. If we print the value of `cruise`, we get back an object of type `Trip` because LLDB retell results metadata to display the most accurate type for a given variable at a given program point. This is what we call `dynamic type resolution`.\n\nWith the p-command, dynamic type resolution is `only` performed on the result of the `expression`.\n\nThis happens because if you remember, LLDB compiles code where running p and the only type it sees is the one in your source code, the static one. It's the same thing as typing the expression `cruise.name` in your source code. The static compiler will reject it with an error.  ![-w1104](15902348043124.jpg?lastModify=1591521218)\n\nIf you want to evaluate the expression without errors, you need to first cast the object explicitly to its dynamic type and then access the field on the result. This is true both for the debugger and your source code.\n\n![img](15902348340793.jpg?lastModify=1591521218)\n\n### “p” Under the Hood\n\n![img](15902348740856.jpg?lastModify=1591521218)\n\n### Formatter \n\nAfter it performed `dynamic type resolution` on the result, LLDB passes the resulting object to the `formatter subsystem` which is the part of LLDB responsible for printing a human readable description of objects.\n\n![-w850](15902349355474.jpg?lastModify=1591521218)\n\n## v Command\n\n- The output of `v` is exactly the same as `p` as it also relies on the formatter we just described.\n- `v` is just an alias we introduced in Xcode 10.2 for the `frame` variable command\n- The v-command doesn't compile and execute code at all which makes it very fast.\n\n![img](15902351819724.jpg?lastModify=1591521218)\n\n### v under the hood \n\n![img](15902354049114.jpg?lastModify=1591521218)\n\n### frame command\n\n![-w799](15902352051371.jpg?lastModify=1591521218)\n\n## po vs p vs v\n\n![-w1306](15902354519154.jpg?lastModify=1591521218)\n\n","tags":["Debug","LLDB"],"categories":["iOS"]},{"title":"Anchor point for 3D Transform in React Native","url":"/2020/05/15/20200515-react-native-anchor-point/","content":"\nIn react-native, sometimes, you may want to rotate a view basing one a specific point instead of the center of the view. Like the cube animation in the instagram stories. Some people think you need a extra `transformZ` property to achieve that. But, actually, you don't need that. What you need is `Anchor Point`. \n\n## What is Anchor Point \n\nWeb developers may be familiar with `transform-origin` in css. While in iOS, there is something similar called `anchor point`. \n\n`Anchor point` in a view is a point in the unit coordinate space, about which all geometric manipulations to the view occur. \n\n> Defines the anchor point of the layer's bounds rectangle. Animatable. \n> You specify the value for this property using the unit coordinate space. The default value of this property is (0.5, 0.5), which represents the center of the layer’s bounds rectangle. `All geometric manipulations to the view occur about the specified point`. For example, applying a rotation transform to a layer with the default anchor point causes the layer to rotate around its center. Changing the anchor point to a different location would cause the layer to rotate around that new point.                -- [Apple dev](https://developer.apple.com/documentation/quartzcore/calayer/1410817-anchorpoint)\n\nBy default, the anchor point for the rotation is the center of the view. That means the rotation of a view is based on its center. Inspired by this [article](https://commitocracy.com/implementing-foldview-in-react-native-e970011f98b8#.k95f793qe), which teaches us how to rotate a view based from the origin point, I got an important clue to implement the anchor point.  \n\n### Why do we need anchor point in react-native\n\n1. Currently, there is no public API in react-native providing the ability to set `transform-origin` or `anchor-point`. So you will find it is difficult to do some fancy 3D transform animations. For example, [cube animation](https://www.npmjs.com/package/react-native-cube-transition) has some flaws: \n    - There is a gap between the views when translating views in Android \n    - The angle is not correct, less than 90 degrees, make the animation wired. It is not a cube, if you try to adjust the angle, you will break all the things. \n    - part of the view is clipped, not rendering on the screen. \n![image2020-5-27_17-17-21](https://user-images.githubusercontent.com/7471672/84166299-4c06dd00-aaa7-11ea-8c48-4e401c756767.png)\n\nActually, I use this function to solve all these issues. But it is code for company, I can't make it public. The key thing is to set anchor point as (1, 0.5) for the left view and (0, 0.5) for the right view. \n![image](https://user-images.githubusercontent.com/7471672/84166384-63de6100-aaa7-11ea-8102-9de5bee4cf18.png)\n\n2. Beside, for this foldview animation [foldview-in-react-native](https://commitocracy.com/implementing-foldview-in-react-native-e970011f98b8), one of the most import things is to use [`transformOrigin`](https://github.com/jmurzy/react-native-foldview/blob/892f89569cd851867602ce7412852515dccc7e5f/src/transformUtil.js#L3). But, this function works with `transform matrix`, and isn't easy to use. So, I made `react-native-anchor-point`. It looks simple and tricky, but actually very powerful. With it, you can use the transform API in react-native to achieve many fancy animations.\n\n\n### transformOrigin in react-native-foldview\n\n> “Since the transform origin of a view is at its horizontal and vertical center by default, to rotate it in x-space along the bottom, we need to first shift our view’s origin on the y-axis by 50% of the view’s height, then apply rotation, then shift it back to the original center.” — [@jmurzy](https://commitocracy.com/implementing-foldview-in-react-native-e970011f98b8)\n\nSo @jmurze implemented a [function]\n(https://gist.github.com/jmurzy/0d62c0b5ea88ca806c16b5e8a16deb6a#file-foldview-transformutil-transformorigin-js)\n\n```js\nfunction transformOrigin(matrix, origin) {\n  const { x, y, z } = origin;\n\n  const translate = MatrixMath.createIdentityMatrix();\n  MatrixMath.reuseTranslate3dCommand(translate, x, y, z);\n  MatrixMath.multiplyInto(matrix, translate, matrix);\n\n  const untranslate = MatrixMath.createIdentityMatrix();\n  MatrixMath.reuseTranslate3dCommand(untranslate, -x, -y, -z);\n  MatrixMath.multiplyInto(matrix, matrix, untranslate);\n}\n```\nHere\n-  `reuseTranslate3dCommand` in the [react-native source code](https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/Utilities/MatrixMath.js#L95), is to replace the 12th, 13th, 14th element in the matrix by parameters, z, y, z to achieve `translation` effect. \n- `reuseTranslate3dCommand` is called in [processTransform.js#L79](https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/StyleSheet/processTransform.js#L79), in which, RN generates a transform matrix based on `transform object` we provide. \n[https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/StyleSheet/processTransform.js#L43]\n\n### What `transformOrigin` does is to\n\n```\n1. translate the view by x, y, z on the x-axis, y-axis, z-axis \n2. apply rotation\n3. translate the view back by -x, -y, -z on the x-axis, y-axis, z-axis \n```\n\n\n### Plain Code\n\nAfter understanding the above things, we know we can can use `transform` style to set the anchor point. For example, the following code sets the anchor point of the view as (0, 0.5). This will make the rotate base on the left side of the view. \n\n```javascript\n   const transform = {\n      transform: [\n          {translateX: -w / 2}, \n          rotateY, \n          {translateX: w / 2}\n      ]\n    }\n    return (   \n        <Animated.View style={transform}></Animated.View>\n    )\n  }\n\n```\n![](./d32bef61.png)\n\nRemember that RN generates only one single transform matrix, based on `transform object` we provide, [here](https://github.com/facebook/react-native/blob/a1ac2518a364ebcd3cc024a22229cadc1791e1c4/Libraries/StyleSheet/processTransform.js#L43). So, finally, the above code will be converted into a transform matrix, with which the rendering system can render a view with a given layout and shape.  There are some transform matrix knowledge involved. [ref: tutorial-3-matrices](http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/)\n\n\n## react-native-anchor-point\n\nIn this [package](https://github.com/sueLan/react-native-anchor-point), I provides a function `withAnchorPoint`, to inject the above code into your `transform` object. It works well with the original way you use transform and. So, you don't have to use `ref` to set the `transformOrigin` any more. This would make the `3d transform` in React Native easier to implement. \n\n![](./rotateZ.gif)\n![](./rotateXY.gif)\n![](./rotate.gif)\n\nAnd it works well with the react-native `transform` API \n\n```\nimport { withAnchorPoint } from 'react-native-anchor-point';\n\ngetTransform = () => {\n    let transform = {\n        transform: [{ perspective: 400 }, { rotateX: rotateValue }],\n    };\n    // inject the anchor point here\n    return withAnchorPoint(transform, { x: 0.5, y: 0 }, { width: CARD_WIDTH, height: CARD_HEIGHT });\n};\n    \n<Animated.View style={[styles.blockBlue, this.getTransform()]} />\n```\n\n## Ref\n\n- [Matrices](http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/)\n- [react-native-foldview](https://github.com/jmurzy/react-native-foldview)\n- [RN How to set the anchor point of a view.](https://stackoverflow.com/a/60632809/4026902)\n- https://pages.mtu.edu/~shene/COURSES/cs3621/NOTES/geometry/geo-tran.html\n","tags":["Popular Article","Animation"],"categories":["React Native"]},{"title":"Work with Wider Color","url":"/2020/05/09/20190509-Work-with-Wider-Color/","content":"\n\n# Work with Wider Color \nhttps://developer.apple.com/videos/play/wwdc2016/712\n\n## Basic concepts about color\n\n### What is Color Space \n\n> A color space is a specific organization of colors. In combination with physical device profiling, it allows for reproducible representations of color, in both analog and digital representations.            --- Wiki\n\n![](media/15884935782947/15884941050187.jpg)\n\nThis is the standard RGB space, which is the default color space in iOS. \n\n#### Color Primaries\n> Color primaries generally fall at the most intense value that you can get with that particular color channel.\n\nLike, in sRGB space, the color primaries are \n> RGB {0.0, 0.0, 0.0} = Black \nRGB {1.0, 1.0, 1.0} = White \nRGB {1.0, 0.0, 0.0} = Red\n\n#### Color gamut \n  All of the colors that can be defined as a combination of those individual color channels. \n\n\n## Display P3 \n\n\n![](media/15884935782947/15885097554778.jpg)\n\nIn the above image, the colored region represents the outer limits of perception in a human's color vision. \n\nThe inner black triangle represents sRGB's limits of presentation.\nIn contrast, the DCI-P3 standard, and the Wide Color implementation, has a larger area underneath the triangle, representing the greater array of displayable color possible.\n\n- 16bit per color channel for P3 and beyond \n\n### Extended Range sRGB \n\n- Display P3\n    - {1.0, 0.0, 0.0}\n- Extended Range sRGB\n    - {1.358, -0.074, -0.012}\n## Wider Color \n                        \n                        \n> Wide color displays support a P3 color space, which can produce richer, more saturated colors than sRGB. As a result, photos and videos that use wide color are more lifelike, and visual data and status indicators that use wide color are more impactful.\n\n\n## Color Management \n\nApplication Content Types\n- Static image resources\n- Document and network image resources\n- Advanced Media\n- GPU Textures\n\nFraming the Color Problem\n- App Content can come in a broad range of color richness from many sources Devices and \n- Displays come in a broad range of color capabilities\n\n### How do we bridge the differences?\n\nThe answer is color management. \n\n> The job of color management is to ensure that an image looks the same on any output device no matter what color space it is encoded in.\n\n### How does it work?\n\n- Every image has an associated color space (color profile)\n- Color matching maps image colors to output device\n    - ![](media/15884935782947/15885122964828.jpg)\n\n- Not for free: Every pixel needs to be color matched\n- Potentially lossy: Color fidelity is lost when output has smaller gamut. For example, going down from P3 color space to sRGB color space. \n\nOpti in System: \n\n- Color matching operations are easily hardware accelerated\n\n- Color matching operations are easily hardware accelerated\n- Properly tagged content requires no code to display properly\n\n## Design Considerations for Wide Gamut \n\n- Use wide gamut content where it makes sense\n- Use where vivid colors enhance the user experience\n- No need to change all content to P3\n- Toolchain support makes gradual opt-in of wide gamut content possible\n\n## Upgrading Content to Wide Color\n\nBe careful when promoting an existing design file to wide color! \n- Don’t “assign” P3 profile. It just remaps the existing color information into new color space. The colors are stretched, and the design file will be inevitably altered. \n- Convert to P3 instead\n\n\n## Tools \n ![](media/15884935782947/15885134344507.jpg)\n\n## Color Specification \n\nWhen communicating with designers, Be specific about color space!\n\n- Use Display P3 instead of sRGB when working with wide gamut designs\n\n- Use floating point for more precision\n> P3 (255, 128, 191) \n> P3 (1.0, 0.5, 0.75)\n\n## Drawing colors \n\n### Constructing Wide Gamut Colors \n\n```swift\nNSColor(displayP3Red: 1.0, green: 0.0, blue: 0.0, alpha: 1.0)  \nUIColor(displayP3Red: 1.0, green: 0.0, blue: 0.0, alpha: 1.0)\n\n```\n### Constructing Extended Range sRGB Colors\n```swift \nNSColor(red: 1.1, green: -.25, blue: 0.0, alpha: 1.0)  \nUIColor(red: 1.1, green: -.25, blue: 0.0, alpha: 1.0)\n\n```\n\n\n### Rendering \nOptimizing your app’s drawing for wide gamut displays\n\n❌ Don't use `UIGraphicsBeginImageContext`. It doesn't support wider color. \n\n> The format for the bitmap is a ARGB 32-bit\n>  integer pixel format using host-byte order\n\n`UIGraphicsBeginImageContext` not only cannot create contexts with more than 8 bits per color channel, but also cannot represent colors in extended range sRGB. Sadlly, existing interface has no ability to create a context in non-sRGB color space. \n\nSo, they introduce `UIGraphicsImageRenderer(size: CGSize)` \n\n```swift \n\nlet renderer = UIGraphicsImageRenderer(size: CGSize(width: 250, height: 250))\nlet image =  renderer.image { rendererContext in\n    let bounds = rendererContext.format.bounds\n    let rects = bounds.divided(atDistance: bounds.size.width/2, from: .minXEdge)\n    \n    UIColor(displayP3Red: 1.0, green: 0.0, blue: 1.0, alpha: 1.0).set()\n    rendererContext.fill(rects.slice)\n    \n    UIColor(red: 1.0, green: 0.0, blue: 1.0, alpha: 1.0).set()\n    rendererContext.fill(rects.slice)\n}\n```\n\n- Fully color managed by default\n- Supports extended range sRGB color space\n- Manages CGContext lifetime\n\n\n### Draw \n\n`UIView`, `UIImageView`, Color managed since iOS 9.3 \n```swift \ndraw(_ rect: CGRect) // called in the extended sRGB color space\n```\n\nFor `UIView`, use the view’s layer’s `contentsFormat` property\n\nValid CALayer contents formats:\n- kCAContentsFormatRGBA8Uint\n- kCAContentsFormatRGBA16Float\n- kCAContentsFormatGray8Uint","tags":["WWDC","Image"]},{"title":"iOS images in memory","url":"/2020/05/03/iOS-images-in-memory/","content":"\n> Notes for [wwdc2018/219](https://developer.apple.com/videos/play/wwdc2018/219) and [wwdc2018/416](https://developer.apple.com/videos/play/wwdc2018/416/)\n\n## Why memory and CPU matter? \n![](media/15884695669510/15888626848016.jpg)\n\n\n- It is obvious that too much usage of `CPU` has negative impact on `battery life` and `responsiveness`.  \n- But, if you application consumes too much memory, that causes more `CPU utilization`, which have negative effects on `battery life` and `performance`.\n\n## Basic Concepts \n\n### Buffers \n> Buffer is contiguous region of memory. \nIt is often viewed as sequence of elements of the same sizes, usually of the same internal construction. \n\n![-w354](media/15884695669510/15888596565806.jpg)\n\n\n\n#### Image Buffers \n\n> One kind of the important buffers is the `Image Buffer`, which holds the `in-memory representation of some image`. \n\nEach element in image buffers describes the color and the transparency of single pixel in our image. Constantly, the buffer size is proportional to image size. For example, in the image with sRBG format, each 32 bits describes the color and transparency of a single pixel. `The buffer size =  4 byte  x image_width x image_height`\n\n\n\n![-w452](media/15884695669510/15888600604360.jpg)\n\n#### Frame buffer \n\n> The frame buffer is what holds the actual rendered output of your application.  \n\nAs your application updates its view hierarchy UIKit will render the application's `window` and all of its `subviews` into the `frame buffer`. And that frame buffer provides per pixel color information that the `display hardware` will read in order to illuminate the pixels on the display.\n\n[Related resource: The View Drawing Cycle](https://developer.apple.com/library/archive/documentation/WindowsViews/Conceptual/ViewPG_iPhoneOS/WindowsandViews/WindowsandViews.html#//apple_ref/doc/uid/TP40009503-CH2-SW10)\n\nThe pipeline is like this: \n\n![](image_graphic.gif)\n\n#### Data Buffer\n\n> a data buffer is just a buffer that contains a sequence of bytes. \n\nIf we've downloaded images from the network or we've `loaded` them from disk. A data buffer that contains an image file, typically, begins with some metadata describing the size of the image that's stored in that data buffer.\n\n![-w397](media/15884695669510/15888655020412.jpg)\n\n- Store contents of an `image file` in memory. The `size` is the same as that in the image file in the disk. \n- Metadata describing dimensions of image\n- Image itself `encoded` as JPEG, PNG, or other (usually compressed) form\n- Bytes `do not `directly describe pixels\n\n\n### The Pipeline in Action \n\n![-w834](media/15884695669510/15890026431784.jpg)\n\n\n## Consequences of Excessive Memory Usage \n\n- Increased fragmentation. \n    - `fragment` : The large allocation that is in your application's address space could force other related content apart from content that it wants to reference.\n- Poor locality of reference\n- System starts `compressing` memory Process termination\n    - Eventually, if your application starts accumulating a lot of memory usage the operating system will step in and start transparently `compressing` the content of physical memory. Now, the CPU needs to be involved in this operation so in addition to any CPU usage in your own application. You could be `increasing global CPU usage` that you have no control over. Eventually, your application could start consuming so much physical memory that the OS needs to start `terminating processes`. And it'll start with background processes of low priority.\n\n- You app may be terminated by the system\n- Cause `CPU peak`, and then has negative impact on battery life and responsiveness.\n\n## Decoding \n\n> Decoding is an operation that will convert the JPEG or PNG or other encoded image data into per pixel image information. \n\n- CPU-intensive process\n\n- The memory used for the image buffer is proportional to original image size, not view size. \n- There are persistent large memory allocation in decoding.\n- The image buffer is retained for repeat rendering by UIImage. \n\nAfter decoding, UIImage will hang onto that image buffer, so that it only does that work once. Consequently, your application, for every image that gets decoded, could have a persistent and large memory allocation hanging out.\n\n## The memory use of an image using sRGB space\n\n> Memory use is related to the dimensions of the images, not the file size.\n\nTake the following image as an instance, its file size is 590KB, with dimension 2048 x 1536 pixel.\n![83dca9cf.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/83dca9cf.png)\n\n\n### 4 byetes for each pixel in RGBA \n\nBy this [article](https://www.objc.io/issues/3-views/moving-pixels-onto-the-screen/), each pixel in sRGB image needs 32bit, 4 bytes, in memory when it's decoded. Because in sRGB, there are Red, Green, Blue 3 channels and Alpha. The range of each channel value is from 0 to 255, which needs 8 bits to represent the value. \n\n```\n  A   R   G   B   A   R   G   B   A   R   G   B  \n | pixel 0       | pixel 1       | pixel 2   \n  0  233  2  100  4  155 255  7   8   9   10  11 \n```\n  \n\n### More memory usage when decoding a image \n\nA image have load -> decode -> render these 3 phases.  \n\n![64aaa3cd.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/ed4e1c96.png)\n\n\n\nWe only need 590KB to load a image, while we need \n`2048 pixels x 1536 pixels x 4 bytes per pixel` = 10MB when decoding \n  \n\n\n##  Image Rendering Pipeline \n\n- `UIImage` is responsible for loading image content. Usually, it is bigger than the ImageView that is going to display it. \n- `UIImageView` is responsible for displaying the image. The image which it is going to display will be shrink down to fit its size. \n ![](media/15884695669510/15889026761062.jpg)\n\n\n## Downsampling\nSo, we can use technique, called Downsampling, to `downsample` the images to `the size that they're going to be displayed`. Rather than having these large allocations hanging around, we're reducing our memory usage.\n\n![-w1333](media/15884695669510/15889088392417.jpg)\n\n```swift \n// Downsampling large images for display at smaller size\nfunc downsample(imageAt imageURL: URL, to pointSize: CGSize, scale: CGFloat) -> UIImage {\n    // ShouldCache flag tells Core Graphics framework that we're just creating an object to\n    // represent the infomation stored in the file at this URL\n    let imageSourceOptions = [kCGImageSourceShouldCache: false] as CFDictionary\n    let imageSource = CGImageSourceCreateWithURL(imageURL as CFURL, imageSourceOptions)!\n    let maxDimensionInPixels = max(pointSize.width, pointSize.height) * scale\n    let downsampleOptions =\n        // Ask the Core Graphics to create the decoded image buffer for me when calling it to create the thumbnail\n        [kCGImageSourceCreateThumbnailFromImageAlways: true,\n        kCGImageSourceShouldCacheImmediately: true,\n        // Should include kCGImageSourceCreateThumbnailWithTransform: true in the options dictionary. Otherwise, the image result will appear rotated when an image is taken from camera in the portrait orientation.\n        kCGImageSourceCreateThumbnailWithTransform: true,\n        kCGImageSourceThumbnailMaxPixelSize: maxDimensionInPixels] as CFDictionary\n    let downsampledImage =\n        CGImageSourceCreateThumbnailAtIndex(imageSource, 0, downsampleOptions)!\n    return UIImage(cgImage: downsampledImage)\n}\n```\n\n## Decoding in ScrollViews \n### The cause of the ScrollView hitch \n\n![-w1178](media/15884695669510/15889147842616.jpg)\n\n\n> When beginning scrolling, we're about to display another row of images. And we're about to ask Core Graphics to `decode` those images before we hand the cells back to UICollectionView.\nAnd that could take `a lot of CPU time`. So much so, that we `don't` get around to `re-rendering the frame buffer`. But the `display hardware` is operating on a `fixed interval`. So, from the user's perspective the application has just `stuttered`. Now, we're done decoding these images, we're able to provide those cells back to UICollectionView. And animation continues on, as before. Just saw a `visual hitch`, \n\n## Two techniques to smooth out CPU usage \n\n1. prefetching \n2. performing work in the background\n\n### Thread Explosion \nIt is caused by \n- More images to decode than available CPUs \n- GCD continues creating threads as new work is enqueued\n- Each thread gets less time to actually decode images\n\n\n> Now, to avoid deadlock when we dispatch asynchronously to a global queue, GCD is going to create new threads to capture the work we're asking it to do. And then, the CPUs are going to spend a lot of time moving between those threads to try and make incremental progress on all of the work we asked the operating system to do for us. And switching between those threads, actually, has a pretty significant overhead.\n\n\nwe're going to serialize some work.\n\nSo, rather than simply dispatching work to one of the global asynchronous queues, we're going to create a serial queue. And inside of our implementation of the prefetch method we're going to asynchronously dispatch to that queue.\n\n![-w1516](media/15884695669510/15889150745604.jpg)\n\n## Image Sources \n\nImages may come from \n- Image assets in asset catalog\n- Files in application/framework bundle\n- Files in Documents and Caches directories \n- Data downloaded from network\n\nThis session suggests us to use image assets for the following reasons: \n\n- Optimized name- and trait-based lookup\n   - It's `faster` to `look up` an image asset in the asset catalog, than it is to search for files on disk that have a certain naming scheme. \n\n- Smarter buffer caching\n    - The asset catalog runtime has, also, got some really good smarts in it for managing `buffer sizes`.\n\n- Per-device thinning\n   - your application only downloads image resources that are relevant to the device that it's going to run on and vector artwork. The \n\n- Vector artwork\n\n## Vector artwork\n\n- Since iOS 11, image assets support  “Preserve Vector Data”\n- Avoids blurriness and aliasing when drawn larger or smaller than natural size\n\n\n\n## Image Rendering Format \n\n### SRGB\n- 4 bytes per pixel \n- full color images \n- most common used \n![a1bf604b.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/a1bf604b.png)\n\n### Wide format \n\n- 8 bytes per pixel \n- super accurate colors. Because they use 8bytes, 16 bits, for each channel. In the meantime, double the image size.  \n- Only useful with wide color display. We don't want to use it when we don't need to. \n- Wide color capture cameras since iPhone 7\n  \n\n![75a1a01e.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/75a1a01e.png)\n\n### Luminance and alpha 8 format\n\nThis image only holds grayscale value. And the image size is smaller. \n\n- 2 bytes per pixel \n- Single-color iamges and alpha\n- Most used in Metal shaders, not very common. \n![6383b177.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/6383b177.png)\n### Alpha 8 Format \n\n- 1 byte per pixel \n- Userful for monochrome images because it uses less memory. \n  - masks \n  - Emoji-free text \n- 75% smaller than SRGB\n\n![753920b5.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/753920b5.png)\nWe can also change `image.tintColor` in this image without changing its format.  \n\n## How do I pick the right format?\n\n`UIGraphicsBeginImageContextWithOptions` always uses SRGB rendering-format, which use 4 bytes per pixel. \n\nwhile `UIGraphicsImageRenderer`, which introduced in iOS 10 will automatically pick the best graphic format in iOS12. It means, you will save 75% of memory by replacing `UIGraphicsBeginImageContextWithOptions` with  `UIGraphicsImageRenderer`\n\n\n**Do** ✅\n\n![2f0229d3.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/2f0229d3.png)\n## Use ImageIO to downsample images\n\n`UIImage` is expensive for sizing and to resizing\n- Will decompress original image into memory \n- Internal coordinate space transforms are expensive\n\n**Don't** ❌\n\n \n![c25d45de.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/c25d45de.png)\n\nUse ImageIO\n- ImageIO can read image sizes and metadata information without dirtying memory.\n\n- ImageIO can resize images at cost of resized image only.\n\n**Do** ✅\n![922ac245.png](28bfb5ac-c3fa-4575-a1b1-72fcbacc9069/922ac245.png)\n\nThe bad is that you have to specify some options. \n\n## Resize image effectively\n\nThis is a function of resizing image without reading it into the memory, using ImageIO.  \n\n```swift\nfunc resize(url: NSURL, maxPixelSize: Int) -> CGImage? {\n    let imgSource = CGImageSourceCreateWithURL(url, nil)\n    guard let imageSource = imgSource else {\n        return nil\n    }\n\n    var scaledImage: CGImage?\n    let options: [NSString: Any] = [\n            // The maximum width and height in pixels of a thumbnail.\n            kCGImageSourceThumbnailMaxPixelSize: maxPixelSize,\n            kCGImageSourceCreateThumbnailFromImageAlways: true,\n            // Should include kCGImageSourceCreateThumbnailWithTransform: true in the options dictionary. Otherwise, the image result will appear rotated when an image is taken from camera in the portrait orientation.\n            kCGImageSourceCreateThumbnailWithTransform: true\n    ]\n    scaledImage = CGImageSourceCreateThumbnailAtIndex(imageSource, 0, options as CFDictionary)\n\n    return scaledImage\n}\n\n\nlet filePath = Bundle.main.path(forResource:\"large_leaves_70mp\", ofType: \"jpg\")\n\nlet url = NSURL(fileURLWithPath: filePath ?? \"\")\n\nlet image = resize(url: url, maxPixelSize: 600)\n```\n\n## Optimizing when in the background\n\n### foreground/background\n\nThe strategy is simple, when `UIApplicationDidEnterBackground`, we unload images; and when `UIApplicationWillEnterForeground`, load images. \n\n\n### on-screen/off-screen \n\nunload large resource when off-screen, `viewDidDisappear`; and load large resource when on-screen, `viewWillAppear`. \n\n## Debug \n\nUse memory graphs to further understand and reduce memory footprint\n\n\n## Ref \n\n- [An great example of how to use command line tools to find root cause of an image memory issue.](https://developer.apple.com/videos/play/wwdc2018/416/)  \n\n## Related \n\n- [An-glimpse-of-iOS-Memory-Deep-Dive](https://suelan.github.io/2020/05/03/An-glimpse-of-iOS-Memory-Deep-Dive/)\n- [Work with Wider Color ](https://suelan.github.io/2020/05/09/20190509-Work-with-Wider-Color)","tags":["Image","Debug","Memory"],"categories":["iOS"]},{"title":"A glimpse of iOS Memory Deep Dive","url":"/2020/05/03/An-glimpse-of-iOS-Memory-Deep-Dive/","content":"\nThis is an pretty good session about iOS memory. [iOS Memory Deep Dive - WWDC 2018 - Videos - Apple Developer](https://developer.apple.com/videos/play/wwdc2018/416/). I saw it and took some notes here. \n\n> Not all memory is created equal. \n\nThere are dirty memory, clean memory, compressed memory in iOS system. We have to know the differences between them. \n\n## Page  \n\nPage is typically 16KB in size and operating system gives it to you when your app requests memory.  \n\n```\nmemory in use = number of pages x page size \n```\n\n![b576f28d.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/b576f28d.png)\n\nSome pages can hold multiple objects, and some objects\ncan span multiple pages. \n\n\n\n### Pages Types \n  - Clean\n    - Data that can be paged out of memory\n    - Memory mapped files\n    - frameworks*\n     \n  - Dirty \n    - memory written by an app \n    - all heap allocations\n    - decoded image buffers\n  - Comporessed \n\n> There is no traditional disk swap in iOS \n\n\n## Memory compressor \n\nThe system will do the compression and decompression for you by memory compressor.\n\nWhat does Memory compressor do? \n\n- Compresses unaccessed pages \n- Decompresses pages upon access\n\n\nBefore being compressed: \n\n\n![cdb635fb.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/cdb635fb.png)\n\nAfter being compressed: \n![8b7d45fa.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/8b7d45fa.png)\n\n\nWhen you got Memory warning, you App is not always the cause. Maybe because the compressor freeing memory. Like, you receiving a phone call while using the App.\n\nAfter being decompressed: \n\n![f0910e00.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/f0910e00.png)\n\nAfter removing objects in `didReceiveMemoryWarning` \n\n\n![28bedf77.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/28bedf77.png)\n\n## Caching \n\n- Trade-offs between CPU and memory. Caching can reduce the CPU usage and time complexity, but it costs memory. \n- Remember the compressor. When decompressing, the used memory will be increased.\n- Prefer NSCache over dictionary. \n\n\n## Memory Profile \n\nIt is the dirty size + the compressed size that the system uses to determine how much memory the app is really using. \n\nWe should mainly focuse on these two part, dirty and compressed memory when analyzing the memory profile.  \n![8af52c4f.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/8af52c4f.png)\n\n\n\n## Tools for Profiling Footprint \n\n1. Xcode memory gauge\n  ![447accd0.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/447accd0.png)\n  \n2. Instruments\n- Allocations \n- Leaks \n- VM Tracker \n  - providing profiles for dirty and compressed memories. \n  - ![69341a61.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/69341a61.png)\n- Virtual memory trace \n  - ![1ca65c7e.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/1ca65c7e.png)\n3. Debugger \n ![cd78fa8b.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/cd78fa8b.png)\n4. memory graph \n\n![af606628.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/af606628.png)\n\n## working with memory graph using commands\n\n\n### vmmap \n\n\n\n`vmmap` helps to show some dirty memory info of your app. In general, we should look for the big number for the size. \nThere are `virtual size`, `resident size`, `dirty size`, `swapped size` columns here. \n\nAccording to this [session](https://developer.apple.com/videos/play/wwdc2018/416/), we can ignore the `virtual size`, because it is memory requested by the app, while not neccessarily be used.  `swapped size` is related to compressed memory. So we should care more about `dirty size` and `swapped size`.\n\n#### An example of using vmmap to debug a memory issue\n\nFirst, we can use summary info to look for the big numbers in `virtual size` and `swapped size` colomn. Here, we find `CG Image` takes much more memory than others. \n\n\n```\nvmmap --summary PlanetPics.memgraph\n```\n![d58088d1.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/d58088d1.png)\n\n\nThen, we use `grep` to get more info about `CG Image`. \n![751c8f78.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/751c8f78.png)\n\nThere are  two regions here, the last row is summary info. The secong CG Image region takes more takes more dirty and swapped memory. So we have to see more infomation of this region by using `--verbose` option.\n\nAll these commands can work with other shell commands, like redirecting the output stream a `output.txt` file. \n\n\n```\nvmmap --verbose PlanetPics.memgraph | grep \" CG image\" | > output.txt\n```\n![14c0b2ff.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/14c0b2ff.png)\n\n\n\nAnd we will more regions.   \n\n> It turns out that vmmap, by default, if it finds contiguous regions, it collapses. A general rule. the later region was created, the later my app's life cycle it happened. Chance are this later region is more closely tied to whatever caused that memory pike. \n\nSo, we start to look at the last region. We can use the start memory address of the last region and search it in the memory graph in XCode.\n\n![5d389834.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/5d389834.png)\n\nOr use `leak` to get the trace tree. By scanning these info, we would find more clues. \n\n![f63287f5.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/f63287f5.png)\n\nHere, using `malloc_history` to see the back trace for this object, we found the related code creating this particular VM memory. \n\n![d8143352.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/d8143352.png)\n\n\n1. vmmap and AWK\n\nThis command can work with other commands. \n![bca9bf95.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/bca9bf95.png)\n\n### leak \n\n```\nleaks App.memgraph\n```\nIt not only shows the cycle, but also the root object of the cycle. \n\n- leak circle\n![21107588.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/21107588.png)\n\n- root object\n![fbc1d8bb.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/fbc1d8bb.png)\n\n### heap \n\n- Shows objects allocated on the heap; \n- useful for indentifying large objects in memory adn what allocated it. \n```\nheap App.memgraph\nheap App.memgraph -addresses all | <classes-pattern>\n```\n\n`heap` command shows the class name  in `CLASS_NAME` column, the num of the class in `COUNT` column, the average size of the object  in the `AVG` column, the total size in the `BYTES` column. \n\n\n```\nheap App.memgraph -sortBySize | > ~/output.txt\n```\n\n\n![b0766b6a.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/b0766b6a.png)\n\n\n### malloc_history\n\nIn some cases, we not only want to know the memory size, but also want to know the how it created. So, here comes the `malloc_history` command.\n\n- enable the malloc_stack logging\n\n![1153a225.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/1153a225.png)\n\n\n```\nmalloc_history App.memgraph [address]\n```\n\n\n![a70d0d43.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/a70d0d43.png)\n\n### Which tool to pick \n\n![d68340ee.png](f30bdfea-25ac-4eb9-af3e-278a74a85022/d68340ee.png)\n\n\nUse `vmmap` and `heap` to find some objects or regions with big number,  use `leak` to see references between objects, like finding circular reference; use `malloc_history` to see how it is created.  \n\n## Related: \n\n- [iOS-images-in-memory](https://suelan.github.io/2020/05/03/iOS-images-in-memory/)","tags":["WWDC","Image","Debug","Memory"],"categories":["iOS"]},{"title":"How Flipper network plugin works under the hood","url":"/2020/04/25/How-to-inspect-network-activity-of-your-iOS-applicatoin/","content":"\nRecently, Facebook launched [Flipper](https://github.com/facebook/flipper), A desktop debugging platform for mobile developers.  And there is an embedded network plugin, `FlipperKitNetworkPlugin` ,  which works as an inspector of network activities in our application. Let's figure out how it can achieve that. \n\n## Overview \n\nHere comes the class diagram of this network plugin. \n\n![class](class.png)\n\nIn these classes, `FLEXNetworkObserver` is the key one for this plugin. \n\nWhen the plugin starts, it will inject all the `NSURLConnectionDelegate` classes and functions to observe the remote request and response event. \n\n## Swizzle \n\nThe key idea is to swizzle any classes that implement one of the selectors in `URLSession` and `NSURLConnectionDelegate` , and get chance to get the request and response data. \n\nThe process is like this: \n\n1. find out selectors in `URLSession` and `NSURLConnectionDelegate`  which are related to network activities. \n2. Retrieve all the class definitions that have been registered with the Objective-C runtime. The Objective-C runtime library automatically registers all the classes defined in your source code. \n3. Find any class that implements one of the above selectors\n4. Inject this class\n    \n\n\n```objective-c\n+ (void)injectIntoAllNSURLConnectionDelegateClasses {\n  // Only allow swizzling once.\n  static dispatch_once_t onceToken;\n  dispatch_once(&onceToken, ^{\n    // 1. 🌟 Swizzle any classes that implement one of these selectors.  \n   const SEL selectors[] = {\n      @selector(connectionDidFinishLoading:),\n      @selector(connection:willSendRequest:redirectResponse:),\n      @selector(connection:didReceiveResponse:),\n      @selector(connection:didReceiveData:),\n      @selector(connection:didFailWithError:),\n      @selector\n      (URLSession:\n             task:willPerformHTTPRedirection:newRequest:completionHandler:),\n      @selector(URLSession:dataTask:didReceiveData:),\n      @selector(URLSession:dataTask:didReceiveResponse:completionHandler:),\n      @selector(URLSession:task:didCompleteWithError:),\n      @selector(URLSession:dataTask:didBecomeDownloadTask:),\n      @selector(URLSession:\n              downloadTask:didWriteData:totalBytesWritten\n                          :totalBytesExpectedToWrite:),\n      @selector(URLSession:downloadTask:didFinishDownloadingToURL:)\n    };\n\n    const int numSelectors = sizeof(selectors) / sizeof(SEL);\n\n    // 2. 🌟 Retrieve all the class definitions that have been registered with the Objective-C runtime. The Objective-C runtime library automatically registers all the classes defined in your source code. \n \n    Class* classes = NULL;\n    // 2.1 🌟 You can pass NULL to obtain the total number of registered class definitions without actually retrieving any class definitions.\n    int numClasses = objc_getClassList(NULL, 0);\n\n    if (numClasses > 0) {\n        // 2.2 🌟 An array of Class values. Each Class value points to one class definition\n      classes = (__unsafe_unretained Class*)malloc(sizeof(Class) * numClasses);\n      numClasses = objc_getClassList(classes, numClasses);\n      // 3. 🌟 Find any class that implements one of the above selectors\n      for (NSInteger classIndex = 0; classIndex < numClasses; ++classIndex) {\n        Class className = classes[classIndex];\n\n        if (className == [FLEXNetworkObserver class]) {\n          continue;\n        }\n\n        // Use the runtime API rather than the methods on NSObject to avoid\n        // sending messages to classes we're not interested in swizzling.\n        // Otherwise we hit +initialize on all classes. NOTE: calling\n        // class_getInstanceMethod() DOES send +initialize to the class. That's\n        // why we iterate through the method list.\n        unsigned int methodCount = 0;\n        Method* methods = class_copyMethodList(className, &methodCount);\n        BOOL matchingSelectorFound = NO;\n        for (unsigned int methodIndex = 0; methodIndex < methodCount;\n             methodIndex++) {\n          for (int selectorIndex = 0; selectorIndex < numSelectors;\n               ++selectorIndex) {\n            // Find a target method in this class \n            if (method_getName(methods[methodIndex]) ==\n                selectors[selectorIndex]) {\n              // 4. 🌟 Inject this class  \n              [self injectIntoDelegateClass:className];\n              matchingSelectorFound = YES;\n              break;\n            }\n          }\n          if (matchingSelectorFound) {\n            break;\n          }\n        }\n        free(methods);\n      }\n\n      free(classes);\n    }\n\n    [self injectIntoNSURLConnectionCancel];\n    [self injectIntoNSURLSessionTaskResume];\n\n    [self injectIntoNSURLConnectionAsynchronousClassMethod];\n    [self injectIntoNSURLConnectionSynchronousClassMethod];\n\n    [self injectIntoNSURLSessionAsyncDataAndDownloadTaskMethods];\n    [self injectIntoNSURLSessionAsyncUploadTaskMethods];\n  });\n}\n```\n\nFor example, how to inject `connection:willSendRequest:redirectResponse:`?\n\n```objective-c \n\n+ (void)injectWillSendRequestIntoDelegateClass:(Class)cls {\n  SEL selector = \n  @selector(connection:willSendRequest:redirectResponse:);\n  //  🌟 Selector with `_flex_swizzle_` prefix\n  SEL swizzledSelector = [FLEXUtility swizzledSelectorForSelector:selector];\n\n  Protocol* protocol = @protocol(NSURLConnectionDataDelegate);\n  if (!protocol) {\n    protocol = @protocol(NSURLConnectionDelegate);\n  }\n  // 🌟 Get the original method description\n  struct objc_method_description methodDescription =\n      protocol_getMethodDescription(protocol, selector, NO, YES);\n\n  typedef NSURLRequest* (^NSURLConnectionWillSendRequestBlock)(\n      id<NSURLConnectionDelegate> slf,\n      NSURLConnection* connection,\n      NSURLRequest* request,\n      NSURLResponse* response);\n\n  // 🌟 If selector `connection:willSendRequest:redirectResponse:` is not a instance method in this class, use this block as the implementation for swizzledSelector\n  NSURLConnectionWillSendRequestBlock undefinedBlock = ^NSURLRequest*(\n      id<NSURLConnectionDelegate> slf,\n      NSURLConnection* connection,\n      NSURLRequest* request,\n      NSURLResponse* response) {\n    [[FLEXNetworkObserver sharedObserver] connection:connection\n                                     willSendRequest:request\n                                    redirectResponse:response\n                                            delegate:slf];\n    return request;\n  };\n\n  // The implementation for swizzledSelector\n  NSURLConnectionWillSendRequestBlock implementationBlock = ^NSURLRequest*(\n      id<NSURLConnectionDelegate> slf,\n      NSURLConnection* connection,\n      NSURLRequest* request,\n      NSURLResponse* response) {\n    __block NSURLRequest* returnValue = nil;\n    [self sniffWithoutDuplicationForObject:connection\n        selector:selector\n        sniffingBlock:^{\n          undefinedBlock(slf, connection, request, response);\n        }\n        originalImplementationBlock:^{\n          returnValue = ((id(*)(id, SEL, id, id, id))objc_msgSend)(\n              slf, swizzledSelector, connection, request, response);\n        }];\n    return returnValue;\n  };\n  // Swizzle; \n[FLEXUtility replaceImplementationOfSelector:selector\n                                  withSelector:swizzledSelector\n                                      forClass:cls\n                         withMethodDescription:methodDescription\n                           implementationBlock:implementationBlock\n                                undefinedBlock:undefinedBlock];\n}\n```\n\nThen, replace the original implementation of `connection:willSendRequest:redirectResponse:` method with flipper's own implementation for `swizzledSelector`. \n\n```objective-c \n\n+ (void)replaceImplementationOfSelector:(SEL)selector\n                           withSelector:(SEL)swizzledSelector\n                               forClass:(Class)cls\n                  withMethodDescription:\n                      (struct objc_method_description)methodDescription\n                    implementationBlock:(id)implementationBlock\n                         undefinedBlock:(id)undefinedBlock {\n  if ([self instanceRespondsButDoesNotImplementSelector:selector class:cls]) {\n    return;\n  }\n  \n  // The implementation for swizzledSelector\n  IMP implementation = imp_implementationWithBlock((id)(\n      [cls instancesRespondToSelector:selector] ? implementationBlock\n                                                : undefinedBlock));\n\n  Method oldMethod = class_getInstanceMethod(cls, selector);\n  if (oldMethod) {\n    // Add new method to the class, whose signature has `_flex_swizzle_` prefix and custom implementation \n    class_addMethod(\n        cls, swizzledSelector, implementation, methodDescription.types);\n\n    Method newMethod = class_getInstanceMethod(cls, swizzledSelector);\n\n    method_exchangeImplementations(oldMethod, newMethod);\n  } else {\n    class_addMethod(cls, selector, implementation, methodDescription.types);\n  }\n}\n\n```\n\nThe activity diagram for the above code  might be this,\n![activity](activity_swizzle.png)\n\n## Observer and Record\n\nIf there is an network activity, a use calls `connection:willSendRequest:redirectResponse:delegate:` \nor `connection:didReceiveResponse:delegate` is called in an object adopting `NSURLConnectionDelegate` protocol. In fact, its original implementations have been replaced. And Flipper's own implementations for these two selector are called, which call the related `willSendRequest:` and `didReceiveResponse:` method in `FLEXNetworkObserver` class.  So, Flipper got the chance to observe the request and response of network activities. \n\n![a](activity_network.png)\n\n\n","tags":["Debug","Flipper"],"categories":["iOS","Network"]},{"title":"iOS Simulator from the Command Line","url":"/2020/02/05/iOS-Simulator-from-the-Command-Line/","content":"\n`xcrun simctl` is command utils to control iOS simulator, just like  [adb](https://developer.android.com/studio/command-line/adb?hl=en) for Android. Sometimes, in CI server script, We need these simulator-integration command to interact with simulators and run test cases. \n\n If we run `xcrun simctl help`, here are some subcommands. When successful, most of these commands exit with 0; when failed, most exit with a non-zero number. \n\n```\nSubcommands:\n        create              Create a new device.\n        clone               Clone an existing device.\n        upgrade             Upgrade a device to a newer runtime.\n        delete              Delete spcified devices, unavailable devices, or all devices.\n        pair                Create a new watch and phone pair.\n        unpair              Unpair a watch and phone pair.\n        pair_activate       Set a given pair as active.\n        erase               Erase a device's contents and settings.\n        boot                Boot a device.\n        shutdown            Shutdown a device.\n        rename              Rename a device.\n        getenv              Print an environment variable from a running device.\n        openurl             Open a URL in a device.\n        addmedia            Add photos, live photos, videos, or contacts to the library of a device.\n        install             Install an app on a device.\n        uninstall           Uninstall an app from a device.\n        get_app_container   Print the path of the installed app's container\n        launch              Launch an application by identifier on a device.\n        terminate           Terminate an application by identifier on a device.\n        spawn               Spawn a process by executing a given executable on a device.\n        list                List available devices, device types, runtimes, or device pairs.\n        icloud_sync         Trigger iCloud sync on a device.\n        pbsync              Sync the pasteboard content from one pasteboard to another.\n        pbcopy              Copy standard input onto the device pasteboard.\n        pbpaste             Print the contents of the device's pasteboard to standard output.\n        help                Prints the usage for a given subcommand.\n        io                  Set up a device IO operation.\n        diagnose            Collect diagnostic information and logs.\n        logverbose          enable or disable verbose logging for a device\n        status_bar          Set or clear status bar overrides\n        ui                  Get or Set UI options\n        push                Send a simulated push notification\n        privacy             Grant, revoke, or reset privacy and permissions\n        keychain            Manipulate a device's keychain\n```\nJust see I can do a lot of things with these command. If wanting to know more about a specific subcommand, we can use `xcrun simctl help [subcommand]` to seek help. Like, `xcrun simctl help boot` \n\n\n### Simulator info \n\nuse `xcrun simctl list` to see all the simulator information. We can get a list of device types, a list of info of runtime names, a list of device names. \n  \n```\n== Device Types ==\niPhone 11 Pro (com.apple.CoreSimulator.SimDeviceType.iPhone-11-Pro)\niPhone 11 Pro Max (com.apple.CoreSimulator.SimDeviceType.iP\n\n== Runtimes ==\niOS 13.3 (13.3 - 17C45) - com.apple.CoreSimulator.SimRuntime.iOS-13-3 \n\n== Devices ==\n-- iOS 13.3 --\niPhone 11 Pro Max (34C9AC6A-577D-4CEF-8B10-20011DCFBA27) (Shutdown) \n```\n\nUse `xcrun simctl list device` to see the list of device info. Or use a device name to get paired devices' info, like name, uuid, and status. For example,  \n\n```\nxcrun simctl list devices \"iPhone 11 Pro Max\"\n```\n\n```\n== Devices ==\n-- iOS 12.4 --\n-- iOS 13.3 --\n    iPhone 11 Pro Max (34C9AC6A-577D-4CEF-8B10-20011DCFBA27) (Shutdown) \n-- tvOS 13.3 --\n-- watchOS 6.1 --\n-- Unavailale: com.apple.CoreSimulator.SimRuntime.iOS-13-0 --\n    iPhone 11 Pro Max (893827B6-91E0-417C-A179-68343F695040) (Creating) (unavailable, runtime profile not found)\n-- Unavailable: com.apple.CoreSimulator.SimRuntime.iOS-13-1 --\n    iPhone 11 Pro Max (F4B573E0-4106-4FF2-ADA8-16DCC053026C) (Shutdown) (unavailable, runtime profile not found)\n-- Unavailable: com.apple.CoreSimulator.SimRuntime.iOS-13-2 --\n    iPhone 11 Pro Max (B63C96BD-1CE2-499B-8387-3B8AEBF50931) (Creating) (unavailable, runtime profile not found)\n```\n\n### Get device environment variable \n\n`xcrun simctl getenv` is for printing an environment variable from a running device. \n\n```\nUsage: simctl getenv <device> <variable name>\n```\n\n\nTake the follow command as an example, the `SIMULATOR_UDID` environment variable contains the UDID of the simulated device. But it doesn't work for physical device. \n\n```\nxcrun simctl getenv booted SIMULATOR_UDID\n9362BF90-132F-4894-A057-CEBFEC9C1FB6\n```\n\nWe can add more environment variables by ourselves in schema for debugging use. \n![](environment_variable.png)\n\n[Launch Arguments & Environment Variables](https://nshipster.com/launch-arguments-and-environment-variables/)\n\n### Create a custom simulator\n\n\n`xcrun simctl create <name> <device type> <runtime>`\nFor example, if I would like to create a iPhone 11 Pro Max with iOS 13.3, I can use the follow command.\n\n```\nxcrun simctl create \"ry\" \"iPhone 11 Pro Max\" iOS13.3  \nBE9A72F0-5793-447B-BEC4-63A73242BED5 \n```\n\n\n\nThe `uuid` of the new simulator is `BE9A72F0-5793-447B-BEC4-63A73242BED5`, which is output in standard out. And errors comes to standard error. \n\n> Tips: you should use available runtime, or you will get an error of `invalid runtime: xxx`. \n\nIf in shell scrip, we can capture the new device's name using environment variable:\n\n```\nNEW_DEVICE=$(xcrun simctl create \"Test Phone\" \"iPhone XR\" iOS13.0)\necho \"🤖 Created ${NEW_DEVICE}\"\n🤖 Created BE9A72F0-5793-447B-BEC4-63A73242BED5\n```\n\nAnother way to create a simulator using GUI is to go to `Window` -> `Devices and Simulators` \n\n![create](create.png)\n   \n### Boot a simulator \n\nBoot a device using `$uuid` \n\n`xcrun simctl boot BE9A72F0-5793-447B-BEC4-63A73242BED5` \n\nUse `simctl shutdown <device>` to shutdown a device. \n\n### Install/Uninstall app \n\n`xcrun simctl install <device> <path>`. We use this command to install an app on a device. \n\n```\n➜  xcrun simctl install booted ./demo.app\n```\n\n `booted` is the alias name of the booted device. We can also use `uuid` of a device.\n\n use ` simctl uninstall <device> <app bundle identifier>` to uninstall an app. like \n `xcrun simctl uninstall booted com.rong.lan.CubeTransitionAnimationDemo`  \n\n### Launch \n\n`xcrun simctl launch <device> <bundle> <arguments>`. \n\nLaunch command is used to launch a application in your simulator device.\n\n```\nxcrun simctl launch booted com.apple.example -MyDefaultKey YES\n```\n\n`com.apple.example` is bundle id of the application. \n\nIf we use `--console-pty`,  launch command will connect the standard output and error of the application to the terminal line.\n\n```\n➜  xcrun simctl launch --console-pty booted com.rong.lan.CubeTransitionAnimationDemo\n\ncom.rong.lan.CubeTransitionAnimationDemo: 98045\n2020-02-09 10:38:28.594 3DCubeTransitionAnimationDemo[98045:931065] gesture end translation x -281.000000; velocity-1056.111584\n2020-02-09 10:38:28.594 3DCubeTransitionAnimationDemo[98045:931065] timer current tx -281.000332\n2020-02-09 10:38:28.611 3DCubeTransitionAnimationDemo[98045:931065] timer current tx -285.030635\n2020-02-09 10:38:28.627 3DCubeTransitionAnimationDemo[98045:931065] timer current tx -289.060938\n```\n\n\n Use `xcrun simctl terminate <device> <bundle>` to terminate an application by identifier on a device.\n### Container Path \n\n`xcrun simctl simctl get_app_container <device> <app bundle identifier> [<container>]`  command is used to get the path of the installed app's container.  \n\n```\ncontainer   Optionally specify the container. Defaults to app.\n  app                 The .app bundle\n  data                The application's data container\n  groups              The App Group containers\n  <group identifier>  A specific App Group container\n```\n\n\nFor example\n\n```\n➜ xcrun simctl get_app_container booted com.rong.lan.CubeTransitionAnimationDemo \n~/Library/Developer/CoreSimulator/Devices/BE9A72F0-5793-447B-BEC4-63A73242BED5/data/Containers/Bundle/Application/135A7B46-DE38-47EC-9871-D1F3615E9CE5/3DCubeTransitionAnimationDemo.app\n➜ xcrun simctl get_app_container booted com.rong.lan.CubeTransitionAnimationDemo data \n~/Library/Developer/CoreSimulator/Devices/BE9A72F0-5793-447B-BEC4-63A73242BED5/data/Containers/Data/Application/10D64231-20B5-4DFE-B1E9-277AD9C02C4F\n```\n\n### Spawn \n\nSpawn command will pause xspawn, a process inside the simulator environment. \n\n```\nxcrun simctl spawn booted defaults write com.example.app ResetDatabase -bool YES\n```\nHere, we use `defaults` utils, because we already have a booted device `BE9A72F0-5793-447B-BEC4-63A73242BED5`, we don't have to specify the device. \n\n`com.example.app` is bundle id of my application. We reset `ResetDatabase` to YES. \nThis is a handy way to change the user defaults for the application before its running.  \n\n### Log Stream \n\nspwan command would work with log stream utility. We can pass a predicate and filter the log output. Here the predicate is `senderImagePath CONTAINS \"nsurlsessiond\"`. We can debug something wrong with URL session. \n\n```\nxcrun simctl spawn booted log stream --predicate 'senderImagePath CONTAINS \"nsurlsessiond\"'\n```\n![spwan](spawn_log.png)\n\nAlso, we can use different predicates to filter what we want.  \n\n```\nxcrun simctl spawn booted log stream — predicate ‘processImagePath endswith “xxx”’\nxcrun simctl spawn booted log stream — predicate ‘eventMessage contains “error” and messageType == info’\n\n```\n\n\n### Dignose \n\nIn a auto-test system, if having some kind of issue, by using this command, you can not only collect logs on disk but also capture ephemeral logging and dump system state. \n\n```\n➜  xcrun simctl diagnose -l                              \nWriting to /private/tmp/simctl_diagnose_2020_02_09.10-10-56+0800\nGetting Simulator component versions...\nCollecting CoreSimulator logs...\nCollecting device information (this may take some time)...\nThis operation will time-out after 300 seconds.\nGathering 15 crash reports...\nCompressing Archive...\nSuccessfully wrote simctl diagnose archive to '/private/tmp/simctl_diagnose_2020_02_09.10-10-56+0800.tar.gz'\n```\n\n![diagnose](diagnose.png)\n\n### Clone \nClone is a very powerful command. See details in [wwdc2019/418](https://developer.apple.com/videos/play/wwdc2019/418/).  \n\n`xcrun simctl clone <device> <clone name>`.  You can copy your custom device using this command. \n\n```\n// boot base simulator ry\n➜ xcrun simctl boot ry   \n➜ xcrun simctl install ry ./demo.app\n// Must shutdown it before clone \n➜ xcrun simctl shutdown all \n➜ xcrun simctl clone ry ry-1  \n➜ xcrun simctl clone ry ry-2 \n➜ xcrun simctl boot ry-1 && xcrun simctl boot ry-2 \n```\n\n\nTwo new devices are created with the same contents. \n\n![clone](clone.png)\n\n\n### Push Notification to simulator\n\n1. Create a `.apns` file, `ExamplePush.apns` \n\n```\n{\n    \"Simulator Target Bundle\": \"com.facebook.flipper\",\n    \"aps\": {\n        \"alert\": \"This is a simulated notification!\",\n        \"badge\": 3,\n        \"sound\": \"default\"\n    }\n}\n```\n\n[valid Apple Push Notification values](https://developer.apple.com/documentation/usernotifications/setting_up_a_remote_notification_server/generating_a_remote_notification). Noted that the `Target Bundle` should be the same as the `bundle identifier`  \n\n2. Drag and drop an APNs file onto the target simulator. \n\n> The file must be a JSON file with a valid Apple Push Notification Service payload, including the “aps” key. It must also contain a top-level “Simulator Target Bundle” with a string value matching the target application‘s bundle identifier. --  https://stackoverflow.com/a/60085404/4026902\n\n\n\nOr, we use command lines. \n\n```\nxcrun simctl push booted com.facebook.flipper ExamplePush.apns\n```\n\n\n```\n➜  ~ xcrun simctl push \nSend a simulated push notification\nUsage: simctl push <device> [<bundle identifier>] (<json file> | -)\n\n        bundle identifier\n             The bundle identifier of the target application\n             If the payload file contains a 'Simulator Target Bundle' top-level key this parameter may be omitted.\n             If both are provided this argument will override the value from the payload.\n        json file\n             Path to a JSON payload or '-' to read from stdin. The payload must:\n               - Contain an object at the top level.\n               - Contain an 'aps' key with valid Apple Push Notification values.\n               - Be 4096 bytes or less.\n\nOnly application remote push notifications are supported. VoIP, Complication, File Provider, and other types are not supported.\n\n```\n\n### Manipulate a device's keychain \n\n```\n➜  ~ xcrun simctl keychain\nManipulate a device's keychain\nUsage: simctl keychain <device> <action> [arguments]\n\n    add-root-cert [path]\n        Add a certificate to the trusted root store.\n\n    add-cert [path]\n        Add a certificate to the keychain.\n\n    reset\n        Reset the keychain.\n```\n\n```\nxcrun simctl keychain booted add-root-cert myCA.cer\n```\n\n### Privacy and Permissions \n\nThese commands, introduced in Xcode 11.4,  could be very useful when you are developing some features and have to test the permissions.  \n\n```\n➜  ~ xcrun simctl privacy                                         \nGrant, revoke, or reset privacy and permissions\nUsage: simctl privacy <device> <action> <service> [<bundle identifier>]\n\n        action\n             The action to take:\n                 grant - Grant access without prompting. Requires bundle identifier.\n                 revoke - Revoke access, denying all use of the service. Requires bundle identifier.\n                 reset - Reset access, prompting on next use. Bundle identifier optional.\n             Some permission changes will terminate the application if running.\n        service\n             The service:\n                 all - Apply the action to all services.\n                 calendar - Allow access to calendar.\n                 contacts-limited - Allow access to basic contact info.\n                 contacts - Allow access to full contact details.\n                 location - Allow access to location services when app is in use.\n                 location-always - Allow access to location services at all times.\n                 photos-add - Allow adding photos to the photo library.\n                 photos - Allow full access to the photo library.\n                 media-library - Allow access to the media library.\n                 microphone - Allow access to audio input.\n                 motion - Allow access to motion and fitness data.\n                 reminders - Allow access to reminders.\n                 siri - Allow use of the app with Siri.\n        bundle identifier\n             The bundle identifier of the target application.\n\nExamples:\n        reset all permissions: privacy <device> reset all\n        grant test host photo permissions: privacy <device> grant photos com.example.app.test-host\n```\nFor example,\n\n```\n➜  ~ xcrun simctl privacy booted grant location com.facebook.flipper\n➜  ~ xcrun simctl privacy booted grant photos com.facebook.flipper\n```\n\nand use `revoke` to revoke the permissions. \n\n\n### Switch the appearance style in a device between light and dark.\n\n```\nxcrun simctl ui booted appearance dark\nxcrun simctl ui booted appearance light\n```\n\n### StatsBar override \n\n`Usage: simctl status_bar <device> [list | clear | override <override arguments>]`\n\nIt seems it can support a lot of overrides variables in status bar. But I have figure out the scenarios to use them. \n\n```\n➜  ~ xcrun simctl status_bar                                    \nSet or clear status bar overrides\nUsage: simctl status_bar <device> [list | clear | override <override arguments>]\n\nSupported Operations:\n    list\n        List existing overrides.\n\n    clear\n        Clear all existing status bar overrides.\n\n    override <override arguments>\n        Set status bar override values, according to these flags.\n        You may specify any combination of these flags (at least one is required):\n\n        --time <string>\n             Set the date or time to a fixed value.\n             If the string is a valid ISO date string it will also set the date on relevant devices.\n        --dataNetwork <dataNetworkType>\n             If specified must be one of 'wifi', '3g', '4g', 'lte', 'lte-a', or 'lte+'.\n        --wifiMode <mode>\n             If specified must be one of 'searching', 'failed', or 'active'.\n        --wifiBars <int>\n             If specified must be 0-3.\n        --cellularMode <mode>\n             If specified must be one of 'notSupported', 'searching', 'failed', or 'active'.\n        --cellularBars <int>\n             If specified must be 0-4.\n        --operatorName <string>\n             Set the cellular operator/carrier name. Use '' for the empty string.\n        --batteryState <state>\n             If specified must be one of 'charging', 'charged', or 'discharging'.\n        --batteryLevel <int>\n             If specified must be 0-100.\n```\n\n```\n// change the `dataNetwork` from `wifi` to `4g`\n➜  ~ xcrun simctl status_bar booted override --dataNetwork '4g'\n```\n\n```\nxcrun simctl status_bar booted override --time 15:42 --cellularBars 1 --dataNetwork '3g' --wifiMode 'failed' --batteryState 'charging'\n```\n![status bar](status_bar_test.png)\n\nand use `clear` option to clear all the settings.\n\n```\nxcrun simctl status_bar booted clear\n```\n\nhttps://developer.apple.com/videos/play/wwdc2020/10647/\n\n### Record Video \n\nWe can run `xcrun simctl io --help` to see more. \n\n```\nxcrun simctl io <device> recordVideo <file>\n```\n\n```\nxcrun simctl io booted recordVideo video.mp4\n```\nThis command records the content of the screen of the current booted simulator, and save it to the video.mp4 file.  To stop recording, we have to use `ctl+c` in the terminal. \n\n```\nxcrun simctl io booted recordVideo  -f video.mp4\n```\n`recordVideo` cannot save recorded video output into a file that already exists unless we use  `-f` flag to override the existing file. \n\n```\nxcrun simctl io booted recordVideo video.mp4 --codec h264 --mask ignored video.mp4\n```\n - By default, codec type is `hevc`. \n - Ignore the mask when the mask is rendered black because of compatibility issues. \n\n\nAnd we can also capture the out of the external display of the simulator. \n```\nxcrun simctl io booted recordVideo --display external external.mp4 \n```\n\n![](record_video.gif)\n\n### Other useful commands\n\n```\n// Open a URL in a device.\nsimctl openurl <device> <URL>\n// add a photo or movie to the Photos library of the specified simulator \nxcrun simctl addmedia <device> <file1> <file2>\n// Set up a device IO operation. screenshot or recordVideo \nxcrun simctl io <device> screenshot <output.png>\n\n```\n\n> Ref: \n> https://developer.apple.com/videos/play/wwdc2019/418/\n> https://www.iosdev.recipes/simctl/\n> https://nshipster.com/simctl/ \n> https://developer.apple.com/documentation/xcode_release_notes/xcode_11_4_release_notes\n","tags":["WWDC","Popular Article","Debug","Simulator"],"categories":["iOS"]},{"title":"Understand onViewableItemsChanged in FlatList","url":"/2020/01/21/onViewableItemsChanged/","content":"\nIf you want to get viewable items in the [FlatList], you had better take a look at the `onViewableItemsChanged` prop. For example, suppose you have a video list, and you want automatically play the video when the video is appearing on the screen for a few seconds. In iOS, there is [visibleCells](https://developer.apple.com/documentation/uikit/uicollectionview/1618056-visiblecells) in `UITableView` to achieve this. In React Native, I am glad to tell you that `FlatList` has a more powerful property, `onViewableItemsChanged`. `This article would help you better understand how to use the `onViewableItemsChanged` prop in the [FlatList], and how it works under the hood.\n\n## What is onViewableItemsChanged\n\n`onViewableItemsChanged` is a prop in [VirtualizedList](https://facebook.github.io/react-native/docs/virtualizedlist#onviewableitemschanged) and [FlatList](https://facebook.github.io/react-native/docs/flatlist#onviewableitemschanged). When you scroll a FlatList, the items showing on the FlatList change. Then, this function is called, telling you what current `viewableItems` are and what `changed` items are. \n\nThis function should be used together with [viewabilityConfig](https://facebook.github.io/react-native/docs/virtualizedlist#viewabilityconfig). A specific `onViewableItemsChanged` will be called when its corresponding `ViewabilityConfig`'s conditions are met.\n\nHere is [ViewabilityConfig](https://facebook.github.io/react-native/docs/flatlist#viewabilityconfig)\n```js \nexport type ViewabilityConfig = {\n  /**\n   * Minimum amount of time (in milliseconds) that an item must be physically viewable before the\n   * viewability callback will be fired. A high number means that scrolling through content without\n   * stopping will not mark the content as viewable.\n   */\n  minimumViewTime?: number,\n\n  /**\n   * Percent of viewport that must be covered for a partially occluded item to count as\n   * \"viewable\", 0-100. Fully visible items are always considered viewable. A value of 0 means\n   * that a single pixel in the viewport makes the item viewable, and a value of 100 means that\n   * an item must be either entirely visible or cover the entire viewport to count as viewable.\n   */\n  viewAreaCoveragePercentThreshold?: number,\n\n  /**\n   * Similar to `viewAreaPercentThreshold`, but considers the percent of the item that is visible,\n   * rather than the fraction of the viewable area it covers.\n   */\n  itemVisiblePercentThreshold?: number,\n\n  /**\n   * Nothing is considered viewable until the user scrolls or `recordInteraction` is called after\n   * render.\n   */\n  waitForInteraction?: boolean,\n|};\n```\nHere is the type of `onViewableItemsChanged` function: \n```js\n /**\n   * Called when the viewability of rows changes, as defined by the\n   * `viewabilityConfig` prop.\n   */\n  onViewableItemsChanged?: ?(info: {\n    viewableItems: Array<ViewToken>,\n    changed: Array<ViewToken>,\n    ...\n  }) => void,\n  \nexport type ViewToken = {\n  item: any,\n  // The key of this item\n  key: string,\n  index: ?number,\n  // indicated whether this item is viewable or not\n  isViewable: boolean,\n  section?: any,\n  ...\n};\n```\n\n## How to use it\n\nLet's look at two simple example.\n\n```javascript\n  viewabilityConfig = {\n    waitForInteraction: true,\n    // At least one of the viewAreaCoveragePercentThreshold or itemVisiblePercentThreshold is required.\n    viewAreaCoveragePercentThreshold: 95,\n    itemVisiblePercentThreshold: 75\n  }\n\n  onViewableItemsChanged = ({viewableItems, changed}) => {\n    console.log(\"Visible items are\", viewableItems);\n    console.log(\"Changed in this iteration\", changed);\n  };\n\n  render() {\n    return (\n      <FlatList\n        viewabilityConfig={this.viewabilityConfig}\n        onViewableItemsChanged={this.onViewableItemsChanged}\n        data={this._items}\n        renderItem={this._renderItem}\n        keyExtractor={item => item.id}\n      />\n    )\n  }\n```\n\nBesides, supposed you have to implement different logic for items with 60% viewable region and those with 75% viewable region. You can use `viewabilityConfigCallbackPairs`, which contains an list of key/value objects, which define different `viewability` configurations and `onViewableItemsChanged` callbacks.  \n\n```javascript\n<FlatList\n    data={this._items}\n    renderItem={this._renderItem}\n    keyExtractor={(item) => item.id }\n    viewabilityConfigCallbackPairs={this._viewabilityConfigCallbackPairs}\n/>\n\nthis._viewabilityConfigCallbackPairs = [{\n    viewabilityConfig: {\n      minimumViewTime: 600,\n      itemVisiblePercentThreshold: 60\n    },\n    onViewableItemsChanged: this.handleItemsPartiallyVisible60\n  },\n  {\n    viewabilityConfig: {\n      minimumViewTime: 700,\n      itemVisiblePercentThreshold: 75\n    },\n    onViewableItemsChanged: this.handleItemsPartiallyVisible75\n  }\n];\n```\n\n## How does onViewableItemsChanged works\n\n### Viewable Region \n\n  The layout and viewable region information for VirtualizedList is stored in `_scrollMetrics` object. Through the `nativeEvent` in `onScroll` callback, VirtualizedList gets these layout information.\n\n```js\nconst timestamp = e.timeStamp;\nlet visibleLength = this._selectLength(e.nativeEvent.layoutMeasurement);\nlet contentLength = this._selectLength(e.nativeEvent.contentSize);\nlet offset = this._selectOffset(e.nativeEvent.contentOffset);\nlet dOffset = offset - this._scrollMetrics.offset;\n\n// ... more code here\n\n this._scrollMetrics = {\n      contentLength,\n      dt,\n      dOffset,\n      offset,\n      timestamp,\n      velocity,\n      visibleLength,\n    };\n\n```\n\nIf it is a vertical VirtualizedList, the  `layout.layoutMeasurement.height` in the `nativeEvent` is assigned to `visibleLength`; which is the height of viewable region here.  Also, in a vertical VirtualizedList, the  `layout.layoutMeasurement.height`  is equal to viewportHeight.\n\n![5d152b82.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/5d152b82.png)\n\n### Overview \n\n![a0336b02.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/a0336b02.png)\n\n#### Different `viewabilityConfig`  in one `VirtualizedList`  \n\n`_viewabilityTuples` is an array inside `VirtualizedList` to store `ViewabilityHelper/onViewableItemsChanged` pairs. This array is initialized in the `constructor` function.\n\n```js\n_viewabilityTuples: Array<ViewabilityHelperCallbackTuple> = [];\n\ntype ViewabilityHelperCallbackTuple = {\n  viewabilityHelper: ViewabilityHelper,\n  onViewableItemsChanged: (info: {\n    viewableItems: Array<ViewToken>,\n    changed: Array<ViewToken>,\n    ...\n  }) => void,\n  ...\n};\n```\n\nIf you define [viewabilityConfigCallbackPairs](https://facebook.github.io/react-native/docs/flatlist#viewabilityconfigcallbackpairs),  each `viewabilityConfig` will be used to initialize a different `ViewabilityHelper` object.\n\n[ref code](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/VirtualizedList.js#L743).\n\n```js\n if (this.props.viewabilityConfigCallbackPairs) {\n      this._viewabilityTuples = this.props.viewabilityConfigCallbackPairs.map(\n        pair => ({\n          viewabilityHelper: new ViewabilityHelper(pair.viewabilityConfig),\n          onViewableItemsChanged: pair.onViewableItemsChanged,\n        }),\n      );\n    } else if (this.props.onViewableItemsChanged) {\n      this._viewabilityTuples.push({\n        viewabilityHelper: new ViewabilityHelper(this.props.viewabilityConfig),\n        onViewableItemsChanged: this.props.onViewableItemsChanged,\n      });\n    }\n\n```\n\n`ViewabilityHelper` is `a utility class for calculating viewable items based on the viewabilityConfig and metrics, like the scroll position and layout.`\n\nAs I mentioned before, in a `VirtualizedList` could has several `ViewabilityHelper` objects in `_viewabilityTuples`, containing different `viewabilityConfig` to handle different viewability conditions. Let's take a look at some important props in `ViewabilityHelper`.\n\n```js\nclass ViewabilityHelper {\n  _config: ViewabilityConfig;\n  _hasInteracted: boolean = false;\n  /* A set of `timeoutID`, used for memory management */\n  _timers: Set<number> = new Set();\n  // Indexes of the viewable items\n  _viewableIndices: Array<number> = [];\n  // A map for viewable items\n  _viewableItems: Map<string, ViewToken> = new Map();\n}\n```\n\n#### Items' layout\n\nIn the overview graph, you can see a func `_updateViewableItems` called in many scenarios. For example, it is called in `onScroll` callback. Then, It calls `viewabilityHelper.onUpdate` to find out the viewable items, which appear in the viewport for VirtualizedList.\n\n```js\n_updateViewableItems(data: any) {\n    const {getItemCount} = this.props;\n\n    this._viewabilityTuples.forEach(tuple => {\n      tuple.viewabilityHelper.onUpdate(\n        getItemCount(data),\n        // contentOffset of the list \n        this._scrollMetrics.offset,\n        // 🌟 viewportHeight \n        this._scrollMetrics.visibleLength, \n        this._getFrameMetrics,\n        this._createViewToken,\n        tuple.onViewableItemsChanged,\n        this.state,\n      );\n    });\n  }\n\n```\n- `this._scrollMetrics.visibleLength` is used as `viewportHeight`\n- `this._createViewToken` is used to construct a `ViewToken` object, which contains `item` data, `index`, `key` and `isViewable` flag of the `item`. \n- [this._getFrameMetrics](1864) is a function to get layout information of the item cell by index. The item layout is from `getItemLayout` prop of  `VirtualizedList` or `this._frames` map. `this._frames` stores the itemKey/itemLayout pairs.  \n\n```js\n// this._frames stores the item cell layout info\n{ [cellKey]: {\n      // offset of the item cell\n      offset: number, \n      // length of the item cell. width or height determined by the direction of the VirtualizedList\n      length: number, \n      index: number,\n      inLayout: boolean,\n    }\n}\n```\n\n- By `this.state`, we know the range of the rendered items by  `first` and `last` value. `VirtualizedList` updates these two values when the rendered items are changed.\n\n```js\ntype State = {\n  // The range of the rendered items, \n  // used for the optimization to reduce the scan size\n  first: number,\n  last: number,\n  ...\n};\n```\n\n### How to find out viewable items\n \nIn `onUpdate` method, it calls `computeViewableItems` to get `viewableIndices`. `viewableIndices` is an array of indexes of the viewable items.  So, how does `computeViewableItems`  work?  \n\n#### How to get the indexes of viewable items\n\nIn `computeViewableItems` in the `ViewabilityHelper` class, it iterates items from `${first}` to `${last}`. If an item is viewable, it will be stored in an array named `viewableIndices`.\n\n```js\n  for (let idx = first; idx <= last; idx++) {\n      const metrics = getFrameMetrics(idx);\n      if (!metrics) {\n        continue;\n      }\n      // The top of current item cell, relative to the screen coordinate\n      const top = metrics.offset - scrollOffset;\n      // The bottom of current item cell, relative to the screen coordinate\n      const bottom = top + metrics.length;\n      if (top < viewportHeight && bottom > 0) {\n        firstVisible = idx;\n        if (\n          _isViewable(\n            viewAreaMode,\n            viewablePercentThreshold,\n            top,\n            bottom,\n            viewportHeight,\n            metrics.length,\n          )\n        ) {\n          viewableIndices.push(idx);\n        }\n      } else if (firstVisible >= 0) {\n        break;\n      }\n    }\n    return viewableIndices;\n  }\n```\n\nFrom the code, we can see the `top` and `bottom` value is related to the screen coordinate. I drew a graph to show the relationship between `metrics.offset`, `scrollOffset`, `metrics.length` , `top` and `bottom`, to help you better understand the above code.\n\n![layout.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/3252d60e.png)\n\n### What kind of item is viewable\n\n An item is said to be viewable when it meets the following conditions\n for longer than `${minimumViewTime}` milliseconds (after an interaction if `waitForInteraction`\n is true):\n \n1. the fraction of the item visible in the view area >= `itemVisiblePercentThreshold`.\nWhen it comes to the fraction of the item visible in the view area, we need to care about\n cases shown in the following graph. RN use `Math.min(bottom, viewportHeight) - Math.max(top, 0)` to calculate the viewable length. \n    \n  ![partial](viewable-partial.png)\n\n1. Entirely visible on screen when the height of a item is bigger than the `viewportHeight`.\n\n![7c4f2df0.png](entire-viewable.png)\n\n[ref](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L64)\n\n```js\nfunction _isViewable(\n  viewAreaMode: boolean,\n  viewablePercentThreshold: number,\n  top: number,\n  bottom: number,\n  viewportHeight: number,\n  itemLength: number,\n): boolean {\n  if (_isEntirelyVisible(top, bottom, viewportHeight)) {\n    // Entirely visible \n    return true;\n  } else {\n    // Get viewable height of this item cell \n    const pixels = _getPixelsVisible(top, bottom, viewportHeight);\n    // Get the viewable percentage of this item cell \n    const percent =\n      100 * (viewAreaMode ? pixels / viewportHeight : pixels / itemLength);\n    return percent >= viewablePercentThreshold;\n  }\n}\n\nfunction _getPixelsVisible(\n  top: number,\n  bottom: number,\n  viewportHeight: number,\n): number {\n  const visibleHeight = Math.min(bottom, viewportHeight) - Math.max(top, 0);\n  return Math.max(0, visibleHeight);\n}\n\nfunction _isEntirelyVisible(\n  top: number,\n  bottom: number,\n  viewportHeight: number,\n): boolean {\n  return top >= 0 && bottom <= viewportHeight && bottom > top;\n}\n```\n[code here](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L300)\n\n### Timer and Schedule \n\nIn [`onUpdate` func in ViewabilityHelper](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L228), if we define `minimumViewTime` value, the `_onUpdateSync` is scheduled to be called. It is the handler of the `timeout`.\n\n```js\n this._viewableIndices = viewableIndices;\n if (this._config.minimumViewTime) {\n      const handle = setTimeout(() => {\n        this._timers.delete(handle);\n        // filter out  indices that have gone out of view after minimumViewTime \n        // figure out which items are gone, which items are showing \n        this._onUpdateSync(\n          viewableIndices,\n          onViewableItemsChanged,\n          createViewToken,\n        );\n      }, this._config.minimumViewTime);\n      this._timers.add(handle);\n    } else {\n      this._onUpdateSync(\n        viewableIndices,\n        onViewableItemsChanged,\n        createViewToken,\n      );\n    }\n```\n\nAnd, If after a few seconds, ${minimumViewTime}, if some items aren't longer viewable, the [_onUpdateSync](https://github.com/facebook/react-native/blob/84adc85523770ebfee749a020920e0b216cf69f8/Libraries/Lists/ViewabilityHelper.js#L267) func, filter out these indices that have gone out of viewport.\n\n```js\n    // Filter out indices that have gone out of view after `minimumViewTime`\n    viewableIndicesToCheck = viewableIndicesToCheck.filter(ii =>\n      this._viewableIndices.includes(ii),\n    );\n\n```\n![99830c30.png](/img/9af4f3b0-fe64-4a98-b94e-d456f65ae7cc/99830c30.png)\n\nIn the above graph, at first, the `_viewableIndices` is from 1 to 9. Then the user scrolls the `VirtualizedList`  and the `_onUpdateSync` is triggered after `minimumViewTime`. At this moment, the current `_viewableIndices` is from 2 to 10. So the item indexed 1 is filtered out.\n\n### 6. How to get changed items \n\nComparing with the last time when  `onViewableItemsChanged` is triggered, at this time to trigger  `onViewableItemsChanged`. Some viewable items will be out of the screen, some hidden items will become viewable. In `_onUpdateSync` function, the `preItems`  map stores the information about previous visible items, the previous means last time when `VirtualizedList` calls `onViewableItemsChanged`. Now it has a `nextItems` map, which stores the information about viewable items this time. Then it figures out the `changed` items by comparing these two maps. Then, it calls `onViewableItemsChanged`, passing `viewableItems` and `changed` items. \n\n```js\n_onUpdateSync(\n    viewableIndicesToCheck,\n    onViewableItemsChanged,\n    createViewToken,\n  ) {\n    // Filter out indices that have gone out of view since this call was scheduled.\n    viewableIndicesToCheck = viewableIndicesToCheck.filter(ii =>\n      this._viewableIndices.includes(ii),\n    );\n    const prevItems = this._viewableItems;\n    // Using map, so the time complexity would be o(n) \n    const nextItems = new Map(\n      viewableIndicesToCheck.map(ii => {\n        const viewable = createViewToken(ii, true);\n        return [viewable.key, viewable];\n      }),\n    );\n\n    const changed = [];\n    for (const [key, viewable] of nextItems) {\n      if (!prevItems.has(key)) {\n        changed.push(viewable);\n      }\n    }\n    for (const [key, viewable] of prevItems) {\n      if (!nextItems.has(key)) {\n        changed.push({...viewable, isViewable: false});\n      }\n    }\n    if (changed.length > 0) {\n      this._viewableItems = nextItems;\n      onViewableItemsChanged({\n        viewableItems: Array.from(nextItems.values()),\n        changed,\n        viewabilityConfig: this._config,\n      });\n    }\n  }\n}\n```","tags":["Popular Article","Dive into React Native"],"categories":["React Native"]},{"title":"Gaussian Filter","url":"/2019/07/12/Gaussian-Filter/","content":"\n高斯函数在学术领域运用的非常广泛。 写工程产品的时候，经常用它来去除图片或者视频的噪音，平滑图片, Blur处理。我们今天来看看高斯滤波, Gaussian Filter。 \n**1D的高斯函数**\n一维的高斯函数（或者叫正态分布）方程跟图形如下: \n$$G(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}}$$\n![image.png](/img/Gaussian-Filter/gaussian.png)\n\n$\\mu$是均值；$\\sigma$ 是标准方差。它有个重要特点是 -$\\sigma$ 到+$\\sigma$ 之间的G(x)与x轴围成的面积占全部面积的68.2%.  -2$\\sigma$ 到+2$\\sigma$之间的面积占95%。-3$\\sigma$ 到+3$\\sigma$之间的面积占99.7%。\n如果我们给-3$\\sigma$ 到+3$\\sigma$区间, 它几乎包括了所有可能的点。这个特性对Filter kernel的生成很重要。\n\n\n**2D的高斯函数**\n$$G(x, y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$$\n\n![image.png](/img/Gaussian-Filter/2d-gaussian.png)\n\n\n**所谓高斯滤波操作，其实就是用高斯函数对image做卷积计算**。但一般图像在计算机中一般是离散的3D矩阵，而高斯函数是连续函数，所以我们要从连续高斯函数中采样生成离散的2D矩阵，即Gaussian Filter Kernel。 我们可以控制Kernal的size，让它的点都落在-3$\\sigma$ 到+3$\\sigma$区间内。\n### 生成高斯kernel \n\n```c++\n// Function to create Gaussian filter; sigma is standard deviation\nMatrix getGaussian(int height, int width, double sigma)\n{\n    Matrix kernel(height, Array(width));\n    // sum is for normalization \n    double sum=0.0;\n    int i,j;\n    \n   // generating the kernel \n    for (i=0 ; i<height ; i++) {\n        for (j=0 ; j<width ; j++) {\n            // using gaussian function to generate gaussian filter \n            kernel[i][j] = exp(-(i*i+j*j)/(2*sigma*sigma))/(2*M_PI*sigma*sigma);\n            sum += kernel[i][j];\n        }\n    }\n   \n   // normalising the Kernel \n    for (i=0 ; i<height ; i++) {\n        for (j=0 ; j<width ; j++) {\n            kernel[i][j] /= sum;\n        }\n    }\n\n    return kernel;\n}\n```\n[代码来源](https://gist.github.com/OmarAflak/aca9d0dc8d583ff5a5dc16ca5cdda86a)\n比如，我们用高斯函数生成了一个5x5， $\\sigma$是1的高斯核2D矩阵:\n![image.png](/img/Gaussian-Filter/gaussian_matrix.png)\n它有几个特点： \n1. 最中间的值最大，值向周围递减\n2. $\\sigma$越大，高斯函数的峰越宽，临接的数值差越大\n\n### 对图片应用高斯Filter\n对某个像素点image[i][j]，Fitler对原图对应的像素点做点乘，相加。 生成新的值。\n![https://www.youtube.com/watch?v=C_zFhWdM4ic](/img/Gaussian-Filter/convoltion.gif)\n[材料来源](https://www.youtube.com/watch?v=C_zFhWdM4ic)\n```c++\nImage applyFilter(Image &image, Matrix &filter){\n    assert(image.size()==3 && filter.size()!=0);\n\n    int height = image[0].size();\n    int width = image[0][0].size();\n    int filterHeight = filter.size();\n    int filterWidth = filter[0].size();\n    int newImageHeight = height-filterHeight+1;\n    int newImageWidth = width-filterWidth+1;\n    int d,i,j,h,w;\n\n    Image newImage(3, Matrix(newImageHeight, Array(newImageWidth)));\n    \n   // iter the image pixel\n    for (d=0 ; d<3 ; d++) {\n        for (i=0 ; i<newImageHeight ; i++) {\n            for (j=0 ; j<newImageWidth ; j++) {\n                // using filter convolute the image matrix\n                for (h=i ; h<i+filterHeight ; h++) {\n                    for (w=j ; w<j+filterWidth ; w++) {\n                        newImage[d][i][j] += filter[h-i][w-j]*image[d][h][w];\n                    }\n                }\n            }\n        }\n    }\n\n    return newImage;\n}\n```\n如下图，图片被平滑处理了。\n![image.png](/img/Gaussian-Filter/blur_image.png)\n\n#### More: \n[https://gist.github.com/OmarAflak/aca9d0dc8d583ff5a5dc16ca5cdda86a](https://gist.github.com/OmarAflak/aca9d0dc8d583ff5a5dc16ca5cdda86a)\n\n","tags":["CV"],"categories":["Algorithm"]},{"title":"792. Number of Matching Subsequences","url":"/2019/07/06/792-Number-of-Matching-Subsequences/","content":"\n## [题目](https://leetcode-cn.com/problems/number-of-matching-subsequences/)\n\n## Solution 1 \n思路：存储 + 二分查找\n1. 首先将字符一集对应的下标存储在26 * n的二维数组中。比如对字符串 'abcdea'存储为\n\n| Char | Index |\n| --- | --- |\n| 0 | [0, 5] |\n| 1 | [1] |\n| 2 | [2] |\n| 3 | [3] |\n| 4 | [4] |\n| ... |  |\n| 25 |  |\n\n对应代码: \n\n```c++\n  vector<vector<int>> store(26, vector<int>());\n    for (int i = 0; i < S.size(); ++i) {\n        // 存储字母跟index\n        store[S[i] - 'a'].push_back(i);\n    }\n```\n\n1. 对某个word，查找它的字符是否在二维数组中。\n\n```c++\nint numMatchingSubseq(string S, vector<string>& words) {\n    vector<vector<int>> store(26, vector<int>());\n    for (int i = 0; i < S.size(); ++i) {\n        // 存储字母跟index\n        store[S[i] - 'a'].push_back(i);\n    }\n\n    int res = 0;\n    for (auto &word: words) {\n        int x = -1;\n        bool found = true;\n        for (auto c: word) {\n            // search\n            auto it = upper_bound(store[c - 'a'].begin(), store[c - 'a'].end(), x);\n            if (it == store[c - 'a'].end()) {\n                found = false;\n                break;\n            } else {\n                // 更新最新的下标位置\n                x = *it;\n            }\n        }\n        if (found) res++;\n    }\n\n    return res;\n}\n```\n## Solution 2 \n第二种思路，来自[Stefan大神](https://leetcode.com/problems/number-of-matching-subsequences/discuss/117634/Efficient-and-simple-go-through-words-in-parallel-with-explanation)。 \n这种思路，存储的是words中等待匹配的字符的index pair。比如 words = [\"a\", \"bb\", \"acd\", \"ace\"]存储的结果是: \n|  idx | pair |\n| --- | --- |\n| ‘a' | [(0, 1), (2, 1), (3, 1)] |\n| ‘b' | [(1, 1)] |\n\n\n\n```c++\nint numMatchingSubseq(string S, vector<string>& words) {\n    vector<pair<int, int>> waiting[128];\n    for (int i = 0; i < words.size(); i++)\n        waiting[words[i][0]].emplace_back(i, 1);\n    for (char c : S) {\n        auto advance = waiting[c];\n        waiting[c].clear();\n        for (auto it : advance)\n            waiting[words[it.first][it.second++]].push_back(it);\n    }\n\n    return waiting[0].size();\n}\n```\n\n"},{"title":"1011. Capacity To Ship Packages Within D Days","url":"/2019/06/14/1011-Capacity-To-Ship-Packages-Within-D-Days/","content":"## [题目](https://leetcode.com/problems/capacity-to-ship-packages-within-d-days/)\n## 分析\n来自Vlad神的解答https://leetcode.com/problems/capacity-to-ship-packages-within-d-days/discuss/256737/C%2B%2B-Binary-Search \n\n先定下可能的承重范围: \n1. 最大 maxCap 是所有包裹的重量和\n2. 最小 minCap = max{ maxCap/D, 最重的包裹重量) \n3. 用 Binary Search 查找 `the least weight capacity of the ship`, 该船能在D天内运送完所有货物\n\n```c++\n// 求载货力为 capacity 的船运完所有货物的天数\nint countDays(vector<int>& weights, int capacity) {\n    int count = 1, load = 0;\n    for (auto w: weights) {\n        load += w;\n        if (load > capacity) {\n            // 超过载重能力，第二天继续运载\n            load = w;\n            count++;\n        }\n    }\n\n    return count;\n}\n\nint shipWithinDays(vector<int>& weights, int D) {\n    auto maxCap = std::accumulate(weights.begin(), weights.end(), 0);\n    auto minCap = max(*max_element(weights.begin(), weights.end()), maxCap / D);\n    // Binary Search \n    while (minCap < maxCap) {\n        int mid = (minCap + maxCap) / 2;\n        if (countDays(weights, mid) <= D) {\n            maxCap = mid;\n        } else {\n            minCap = mid + 1;\n        }\n    }\n\n    return minCap;\n}\n\n```","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode:1014. Best Sightseeing Pair","url":"/2019/06/11/LeetCode-1014-Best-Sightseeing-Pair/","content":"\n## 题目： [1014. Best Sightseeing Pair](https://leetcode.com/problems/best-sightseeing-pair/)\n \n\n### 分析\n这道题求 `the maximum score of a pair of sightseeing spots`; score = A[i] + A[j] + i - j)。 是个最优解问题。  \n迭代中，当前idx为i; 要考虑 (0, i-1)的数中对score增益最大的数的下标是max_idx。 计算 (max_idx, i)的score， 并跟之前最大值做比较。\n\n```c++\nint maxScoreSightseeingPair(vector<int> & A) {\n    // 2<= A.length <= 50000\n    int max_idx = 0, res = A[0], inc = 0;\n    for (int i = 1; i < A.size(); ++i) {\n        inc = A[max_idx] - i + max_idx;\n        res = max(res, A[i] + inc);\n        max_idx = A[i] > inc ? i : max_idx;\n    }\n\n    return res;\n}\n```\n\n**更为简约的写法：**\nmax_inc每次迭代后都自减1，是因为进入下一次迭代i+1的时候，它对分数的增益只剩下了A[max_inc] + i - (i+1)。\n```c++\nint maxScoreSightseeingPair2(vector<int>& A) {\n    int max_inc = A[0] - 1, res = 0;\n    for (int i = 1; i < A.size(); ++i, max_inc--) {\n        res = max(res, max_inc + A[i]);\n        max_inc = max(A[i], max_inc);\n    }\n\n    return res;\n}\n```\n\n时间复杂度: $o(n)$","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"理解手机GPS定位原理","url":"/2019/06/08/理解GPS定位原理/","content":"\n本文取材自 TED教学视频[How does your smartphone know your location? - Wilton L. Virgo](https://www.youtube.com/watch?v=70cDSUI4XKE)\n我们的手机是如何准确定位的呢？ 答案在离我们2000多英里的卫星上。\n\n第一个问题： 为啥卫星上的时间对GPS定位如此重要？ 因为我们要知道手机跟卫星的距离。 每个卫星在不断对外广播信号。信号中记录自己的创建时间。\n\n\n![48bce392.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/48bce392.png)\n\n手机收到信号后，利用收到信号的到达时间， 计算自己跟卫星的距离: \n\n$$distance = c * \\Delta T $$\n\nc: 光的速度\n$\\Delta T$: 信号传播的时间间隔 $time_{arrive} - time_{create}$\n\n但是c = 299,792,458 m/s, 非常大。 如果用秒做单位计算$\\Delta T$， 地球上所有点，甚至有些远离我们的位置，计算出来的distance都是一样的值。 \n\n![f8edfbb6.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/f8edfbb6.png)\n\n\n所以我们需要非常非常非常精确的时钟计算时间. 于是原子钟粉墨登场. 就像机械钟靠嘀嗒嘀嗒摇摆来计时， 原子钟也有这种间隔时间固定的滴答滴答计时方式。 \n\n## 原子钟\n\n![782d2620.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/782d2620.png)\n原子钟依赖原子跃迁所释放或吸收的电磁波来计时。原子在一个轨道跑了一圈后，跃迁到另一个轨道的时候会以电磁波形式释放出能量。\n\n![a68ec7af.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/a68ec7af.png)\n\n能量计算公式： $\\Delta E = h \\nu$ $\\Delta E$ 变化的能量; h是常量(h=6.626x$10^{-34}$ Js)。 $\\nu$是频率。 比如铯原子钟，它的频率是个固定值 9,192,631,770Hz，你可以想象为一个每秒跑9billion圈的时钟。所以用原子钟可以每秒精确到 1/1billion。 \n\n![0bc32fc3.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/ca6ea804.png)\n这张图的detector是用来检测probe laser固定频率发出的电磁波。\n\n\n有了精确的时间，我们可以知道手机跟卫星的距离。 以卫星为中心，distance为半径画圆(球)\n\n![f58c51ad.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/f58c51ad.png)\n\n如果多几个卫星，我们可以用几何公式计算出它们的空间交叉点\n\n![293478f1.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/293478f1.png)\n\n![6cbd0ed3.png](/img/a9bb4ba0-9918-4e5c-9fc0-3b9a28363e6b/6cbd0ed3.png)\n\n","categories":["LBS"]},{"title":"714. Best Time to Buy and Sell Stock with Transaction Fee","url":"/2019/06/06/714-Best-Time-to-Buy-and-Sell-Stock-with-Transaction-Fee/","content":"\n##  [题目](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-transaction-fee)\n\n## 分析\n\n### 定义两个状态变量: \n- buy_profit: 若i-1天，持有股票，最大利润是 $(buy_profit)\n- sell_profit: 若i-1天，卖出股票, 最大利润是 $(sell_profit)\n\n### 买卖利润情况： \n\n**最开始**: i == 0;  `int buy_profit = -prices[0], sell_profit = 0`\n**第i天**: \n\n- 当天买: \n    - 维持i-1天持有, 不变； $buy\\_profit_i == buy\\_profit_{i-1}$ \n    - i-1天卖出，i天买进 (因为题目要求每次只能买1 share of stock, 买入前必须把手上的stock都卖出); $buy\\_profit_i = sell\\_profit_{i-1} - prices[i]$\n- 当天卖:  \n    - i-1天持有，i天卖出; 当天的利润为 $sell\\_profit_i=buy\\_profit_i-1 + prices[i] - fee$\n    - i-1天已经卖出，当天不操作；利润为 $sell\\_profit_i == sell\\_profit_{i-1}$ \n    \n每个i迭代，我们都要考虑这四种情况，计算出buy_profit跟sell_profit的局部最优. \n\n\n### 例子\nInput: prices = [1, 3, 2, 8, 4, 9], fee = 2\n\n最优操作： \n\n|  | 1 | 3 | 2 | 8 | 4 | 9 |\n| --- | --- | --- | --- | --- | --- | --- |\n| max buy_profit | -1 | -1 max{-1, -3} | -1 max{-1, -2}| -1 max{-1, 8}| 1 max{1, -4} | 1 max{1, -4}|\n| max sell_profit | 0 | 0 max{0, 0}| 0 max{0, -1}| 5 max{0, 5}| 5 max{5, 3}| 8 {5, 8}|\n\n### 贪心算法\nA greedy algorithm always makes the choice that `looks best at the moment` That is, it makes a `locally optimal choice` in the hope that this choice will `lead to a globally optimal solution`. \n\n\n## Greedy Algorithm   \n\n\n```c++\nint maxProfit(vector<int>& prices, int fee) {\n    if (prices.empty()) return 0;\n    int buy_profit = -prices[0], sell_profit = 0;\n    for (int i = 1; i < prices.size(); ++i) {\n        buy_profit = max(buy_profit, sell_profit - prices[i]);\n        sell_profit = max(sell_profit, buy_profit + prices[i] - fee);\n     }\n\n    return sell_profit;\n}\n```\n或者\n\n```c++\n    int maxProfit(vector<int>& prices, int fee) {\n      int n = prices.size();\n      if (n <= 1 ) return 0; // need at least 2 days to make a transactions\n      \n      vector<int> buys (n); // buys [i] means max money on day i ending in buy  state (have stock in hand)\n      vector<int> sells(n); // sells[i] means max money on day i ending in sell state (no stock in hand)\n      \n      buys [0] = -prices[0];\n      sells[0] = 0;\n      \n      for (int i = 1; i < n; ++i) {\n        buys [i] = max(buys [i-1], sells[i-1]-prices[i]);     // buy  state to buy  state: continue holding onto stock\n                                                              // sell state to buy  state: buy on day i\n        sells[i] = max(sells[i-1], buys [i-1]+prices[i]-fee); // sell state to sell state: continue not holding any stock\n                                                              // buy  state to sell state: sell on day i\n      }\n      return sells[n-1];\n    }\n```\n时间复杂度: $o(n)$","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode:413. Arithmetic Slices","url":"/2019/06/04/LeetCode-413-Arithmetic-Slices/","content":"\n##  [413. Arithmetic Slices](https://leetcode.com/problems/arithmetic-slices/)\n这道题，简而言之，求数组里，等差序列的个数。 \n\n比如\n```\nA = [1, 2, 3, 4]\n有3个等差数列\n[1, 2, 3], [2, 3, 4], [1, 2, 3, 4]\n```\n\n题目没有说明A是等差数列，所以也要考虑A不是等差数列，但是其子数组是等差数列的情况。\n```\nA = [1, 3, 5, 7, 9, 15, 20, 25]\n1, 3, 5\n\n3, 5, 7\n1, 3, 5, 7\n\n5, 7, 9\n3, 5, 7, 9\n1, 3, 5, 7, 9\n\n15, 20, 25\n```\n\n## Solution \n\n```c++\nint numberOfArithmeticSlices(vector<int>& A) {\n    int dp = 0;\n    int sum = 0;\n\n    for (int i = 2; i < A.size(); ++i) {\n        if (A[i] - A[i-1] == A[i-1] - A[i-2])  {\n           dp = 1+dp;\n           sum += dp;\n        } else {\n           dp = 0;\n        }\n    }\n    return sum;\n}\n```","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"ReactNative开发-神器Reactoron","url":"/2019/05/23/ReactNative-reactoron/","content":"Reactoron能改善React Native开发体验。 \n<!--more--> \n \nReactoron这个开发工具，把我们输出的日志像twitter信息流一样保存起来，等我们需要的时候，可以回过头过滤找到日志，展开日志详情查看。提高ReactNative开发效率。 看日志会特别方便，体验也不错。\n\n![image](https://github.com/infinitered/reactotron/raw/master/docs/images/quick-start-react-native/react-demo-native-reactotron.jpg)\n\n项目地址： [GitHub - infinitered/reactotron: A desktop app for inspecting your React JS and React Native projects. macOS, Linux, and Windows.](https://github.com/infinitered/reactotron)\n\n下载最新的release包，本地安装。\n\n## 使用\n\n### 1. 集成在React Native项目中\n\n```sh\nnpm i --save-dev reactotron-react-native\n// or\nyarn add reactotron-react-native --dev\n```\n\n### 2. 配置文件\n\n创建`ReactotronConfig.js`\n\n基础用法：\n```js\nimport Reactotron from 'reactotron-react-native'\n\nReactotron\n  .configure() // controls connection & communication settings\n  .useReactNative() // add all built-in react native plugins\n  .connect() // let's connect!\n```\n高级配置: \n\n```js\nimport Reactotron from 'reactotron-react-native'\n\nReactotron\n  .configure({\n    name: \"React Native Demo\"\n  })\n  .useReactNative({     \n      asyncStorage: {ignore: []},\n      networking: {\n          ignoreUrls: new RegExp(`http://127.0.0.1:19000/logs`)\n      },\n      editor: false,\n      errors: {veto: (stackFrame) => false},\n      overlay: false,})\n  .connect();\n```\n\n#### asyncStorage \n\n参数类型：\n\n```js\nexport interface AsyncStorageOptions {\n    ignore?: string[];\n}\n```\n\n`ignore`的值，传入key数组，`reactotron`不会展示这些key的存储数据\n\n#### networking\n参数类型： \n```js\nexport interface NetworkingOptions {\n    ignoreContentTypes?: RegExp; // 如果response的Content-Type匹配上这个正则表达式，不展示response，\n    ignoreUrls?: RegExp; //  要忽略的urls\n}\n```\n例子：\n```js networking({\n  ignoreContentTypes: /^(image)\\/.*$/i,\n  ignoreUrls: /\\/(logs|symbolicate)$/,\n})\n```\n\n\n#### Error \n参数类型：\n```js\nexport interface TrackGlobalErrorsOptions {\n    veto?: (frame: any) => boolean;\n}\n```\n`veto`函数，我们可以通过它指定我们不想看到的堆栈信息.这里的frame指stack frame.\n\n比如： 如下忽略报错时所有react-native module里头的stack frame.\n```js\nReactotron\n  .configure()\n  .use(trackGlobalErrors({\n    veto: frame => frame.fileName.indexOf('/node_modules/react-native/') >= 0\n   }))\n  .connect()\n```\n### 3. improt\n\n 在`App.js` 或者`index.js`文件头中引入：\n \n```js\nif(__DEV__) {\n  import('./ReactotronConfig').then(() => console.log('Reactotron Configured'))\n}\n```\n\n### 4. 打点\n\n像用`console.log`一样，调用 `Reactotron.log`\n\nReactNative项目跑起来后，可以在Reactotron面板上看到： \n\n![9b1dbee4.png](https://github.com/infinitered/reactotron/raw/master/docs/images/quick-start-react-native/hello-1.jpg)\n\n其他API： \n```js\nReactotron.log({ numbers: [1, 2, 3], boolean: false, nested: { here: 'we go' } })\n\nReactotron.warn('*glares*')\nReactotron.error('Now you\\'ve done it.')\nReactotron.display({\n  name: 'KNOCK KNOCK',\n  preview: 'Who\\'s there?',\n  value: 'Orange.'\n})\n\nReactotron.display({\n  name: 'ORANGE',\n  preview: 'Who?',\n  value: 'Orange you glad you don\\'t know me in real life?',\n  important: true\n})\n\n```\n\n## Redux的数据信息\n[reactotron/plugin-redux.md at master · infinitered/reactotron · GitHub](https://github.com/infinitered/reactotron/blob/master/docs/plugin-redux.md)\n![](https://github.com/infinitered/reactotron/raw/master/docs/images/redux/redux-keys-values.jpg)\n\n[YouTube](https://www.youtube.com/watch?v=UiPo9A9k7xc)\n\n\n","tags":["React Native Dev"],"categories":["React Native"]},{"title":"LeetCode:542. 01 Matrix-DP","url":"/2019/05/23/LeetCode-542-01-Matrix-DP/","content":"Given a matrix consists of 0 and 1, find the distance of the nearest 0 for each cell.\n\n<!--more-->\n \n\n## 题目: [01-matrix](https://leetcode.com/problems/01-matrix/)\nGiven a matrix consists of 0 and 1, find the distance of the nearest 0 for each cell.\n\nThe distance between two adjacent cells is 1.\n```\nExample:\nInput:\n[[0,0,0],\n [0,1,0],\n [1,1,1]]\n\nOutput:\n[[0,0,0],\n [0,1,0],\n [1,2,1]]\n```\n## 分析： \n题目有点没讲明白，这道题，求值为1的cell到最近的0的最短距离。\n\n这道题，我的第一想法是BFS，后来看到DP写法更优雅。[Simple-Java-solution](https://leetcode.com/problems/01-matrix/discuss/101051/Simple-Java-solution-beat-99-(use-DP))\n\n可以发现规律。对matrix[i][j], 如果知道它上下左右四个cell到0的最短距离，那么\n$$matrix[i][j] = min(left, top, right, bottom) + 1$$\n\n1. 遍历matrix矩阵，matrix[i][j]不为0，计算 leftCell 跟 topCell最小值，再加1. \n2. 再倒叙遍历matrix, matrix[i][j]不为0, 先计算rightCell 跟 topCell的最小值，再跟min(left, top)的值比较\n\n```c++\n vector<vector<int>> updateMatrix(vector<vector<int>>& matrix) {\n     if (matrix.empty()) return {};\n     int n = (int)matrix.size(), m = (int)matrix[0].size(), MAX_LEN = 10002;\n     for (int i = 0; i < n; ++i) {\n         for (int j = 0; j < m; ++j) {\n             if (matrix[i][j] != 0) {\n                 int top = (i - 1 < 0) ? MAX_LEN : matrix[i-1][j];\n                 int left = (j - 1 < 0) ? MAX_LEN : matrix[i][j-1];\n                 matrix[i][j] = 1 + min(top, left);\n             }\n         }\n    \n     for (int i = n - 1; i >= 0; i--) {\n         for (int j = m - 1; j >= 0; j--) {\n             if(matrix[i][j] != 0) {\n                 int right = (j + 1 >= m) ? MAX_LEN: matrix[i][j+1];\n                 int bottom = (i + 1 >= n) ? MAX_LEN: matrix[i+1][j];\n                 matrix[i][j] = min(min(right, bottom) + 1, matrix[i][j]);\n             }\n         }\n     }\n     return matrix;\n }\n```\n### 时间复杂度 $o(n^2)$\n### 空间复杂度 $o(1)$\n\n```\nRuntime: 184 ms, faster than 96.53% of C++ online submissions for 01 Matrix.\nMemory Usage: 20.9 MB, less than 91.39% of C++ online submissions for 01 Matrix.\n```\n有人问，为啥要两次遍历？ 不能像下面这么写吗？\n\n```c++\n// 错误的写法\n vector<vector<int>> updateMatrix(vector<vector<int>>& matrix) {\n       if (matrix.empty()) return {};\n       int n = (int)matrix.size(), m = (int)matrix[0].size();\n       for (int i = 0; i < n; ++i) {\n           for (int j = 0; j < m; ++j) {\n               if (matrix[i][j] != 0) {\n                   int top = (i - 1 < 0) ? INT32_MAX : matrix[i-1][j];\n                   int left = (j - 1 < 0) ? INT32_MAX : matrix[i][j-1];\n                   int right = (j + 1 >= m) ? INT32_MAX : matrix[i][j+1];\n                   int bottom = (i + 1 >= n) ? INT32_MAX : matrix[i+1][j];\n                   matrix[i][j] = 1 + min(min(top, left), min(right, bottom));\n               }\n           }\n       }\n       return matrix;\n   }\n```\n问题在于，顺序遍历时候，bottom跟right还没更新为正确的值。比如下图，遍历到matrix[3][0]的时候，matrix[3, 1] 还是1， 而matrix[2][0] == 2; 结果就出错了。\n```\n0 0 0 0 0 \n1 0 0 0 0 \n1 1 1 0 0 \n1 1 1 1 0 \n```\n","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode:650. 2 Keys Keyboard","url":"/2019/05/20/LeetCode-650-2-Keys-Keyboard/","content":"\n## 题意: \nnotepad里只有一个'A'字符串。 只能允许两个操作: \n\n1. Copy All: 把notepad里所有的字符串copy\n2. Paste: 复制上次copy的内容\n\n问，最少的步骤（copy & paste) 能生成n个'A'\n\n## 分析\n\n可以发现规律: \n\n\n| n | op | cur char |\n| --- | --- | --- |\n| 2 | c | A |\n|  | p | AA |\n| 3 | c | A |\n|  | p | AA |\n|  | p | AAA |\n| 4 | c | A |\n|  | p | AA |\n|  | c | AA |\n|  | p | AAAA |\n| 5 | c | A |\n|  | p | AA |\n|  | p | AAA |\n|  | p | AAAA |\n|  | p | AAAAA |\n| 6 | c | A |\n|  | p | AA |\n|  | c | AA |\n|  | p | AAAAA |\n|  | p | AAAAAA |\n\n当n为质数， 所需最少步骤为n; 当n不是质数， 所需步骤为 n的质因数相加之和。比如6 = 2 x 3;它所需最小步骤 2+3 = 5\n\n## Solution 1： 质因数分解\n```c++\nint minSteps(int n) {\n    int ans = 0, d = 2;\n    while (n > 1) {\n        while (n % d == 0)  {\n            ans += d;\n            n /= d;\n        }\n        d++;\n    }\n\n    return ans;\n}\n```\n\n## Solution 2: \n\n```c++\nint minSteps(int n) {\n    if (n <= 1) return 0;\n    if (n <= 5) return n;\n    // n>1的操作，前两步骤都是copy & paste, 从'A'变成 'AA', 所以 cur_len == 2, res == 2, 上次copy的字符数量 == 1, 如果下一次要copy & paste, 要一次copy'AA' 2个字符  \n    int cur_len = 2, res = 2, next_cp_num = 2, copy_num = 1;\n    while (cur_len < n) {\n        if ((n - cur_len) % next_cp_num == 0) {\n           // copy + paste\n           cur_len += next_cp_num;\n           copy_num = next_cp_num;\n           // copy + paste; 2 steps\n           res += 2;\n        } else {\n            // paste the characters copied last time \n            cur_len += copy_num;\n            // only paste, 1 step\n            res += 1;\n        }\n\n        // 题目要求：Copy操作要Copy所有字符\n        next_cp_num = cur_len;\n    }\n\n    return res;\n}\n```\n","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"小白读论文:Semantic Image Synthesis with Spatially-Adaptive Normalization","url":"/2019/05/18/Semantic-Image-Synthesis-with-Spatially-Adaptive-Normalization/","content":"[GauGAN: Changing Sketches into Photorealistic Masterpieces](https://www.youtube.com/watch?v=p5U4NgVGAwg&feature=youtu.be) 3月的时候，英伟达发布了一个视频挺火的： 你只要粗略勾勒简单的线条，AI就能生成逼真的写实图片。\n\n\n  \n  \n\n\n<!--more-->\n[GauGAN: Changing Sketches into Photorealistic Masterpieces](https://www.youtube.com/watch?v=p5U4NgVGAwg&feature=youtu.be) 3月的时候，英伟达发布了一个视频挺火的： 你只要粗略勾勒简单的线条，AI就能生成逼真的写实图片。\n\n![68747470733a2f2f6e766c6162732e6769746875622e696f2f53504144452f2f696d616765732f6f6365616e2e676966](https://camo.githubusercontent.com/a295a79daea9d1dd0cb16b48055607d0f17258b2/68747470733a2f2f6e766c6162732e6769746875622e696f2f53504144452f2f696d616765732f6f6365616e2e676966)\n[GitHub地址](https://github.com/NVlabs/SPADE)\n那它是怎么实现的呢？ 这个项目用的是GAN算法。\n## GAN模型的任务： \n**学习任务** : 输入semantic segmentation mask, 合成 photorealistic images。 \n\n`Semantic Image` 是啥叻？ 直观上理解，如下图： \n\n![31085460.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/31085460.png)\n\n`Image segmentation`呢？ \n```\nImage segmentation is a computer vision task in which we label specific regions of an image according to what's being shown. \nthe goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented.\n```\n如下图里的每个像素都被分类归属到不同的class\n![Screen-Shot-2018-05-17-at-9.02.15-PM.png](https://www.jeremyjordan.me/content/images/2018/05/Screen-Shot-2018-05-17-at-9.02.15-PM.png)\n[图片来源](https://www.jeremyjordan.me/semantic-segmentation/#representing)\n\n## SPADE:  SPatially-Adaptive (DE)normalization\n\n### [Normalizaing training sets](https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=5c39b3d9b1544824a0675bd3f4ed78d5#/learn/content?type=detail&id=2001701046)\n首先，要了解一下Normalization的处理跟好处。\n\n**处理**： 以逻辑回归为例, 它的输入特征$X$,权重$W$, map函数如下\n$$f(x) = \\sum_{i=1}^{n}x_i*w_i$$\n\n1. 先求输入的特征$x$的期望\n$$\\mu=\\frac{1}{n}\\sum_{i=1}^{n}x_i$$\n\n2. 再求$x$的方差\n\n$$\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n}(x_i - \\mu)^2$$\n\n3. 再对输入特征做Normalization: \n$$\\frac{x-u}{\\sigma^2}$$\n\n**好处**是，经过处理的input特征值分布更集中均匀， 如下图的第三个坐标系， \n![826f032b.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/826f032b.png)\n\n对于损失函数，\n$$J(w, x) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}, y)$$\n用梯度下降训练W，B的时候，Normalization后，形状更圆一些，更容易优化。无论初始从哪个位置开始，你都可以用较大的步长,比较容易找到适合的w,b的值，使得J（w,b)的值最小。\n![6ad7add2.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/6ad7add2.png)\n\n### [Batch Normalization](https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=f3e0afd9612c439a9f25d08040d39eab#/learn/content?type=detail&id=2001701055) \n[改善深层神经网络：超参数调试、正则化以及优化 - 网易云课堂](https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=f3e0afd9612c439a9f25d08040d39eab#/learn/content?type=detail&id=2001701055)\n\nBatch Norm不止normailize input feature;也可将normalization process应用在神经网络中的hidden layer上。\n\n![747a0d26.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/747a0d26.png)\n\n比如对隐藏层$a^{[2]}$的输出进行正则化处理，加速下一层的参数$w^{[3]}$,$b^{[3]}$的训练速度。比如$a^{[2]}$层的神经单元分别是 $z^{(1)}, z^{(2)}...z^{(m)}$\n\n对它的处理是\n1. 求期望:\n$$\\mu = \\frac{1}{m}\\sum_{i=1}^{m}z_i$$\n2. 求方差:\n$$\\sigma^2 = \\frac{1}{m}\\sum_{i=1}^{m}(z_i - u)^2$$\n3. norimal\n$$z_i = \\frac{z_i-u}{\\sqrt{\\sigma^2 + \\varepsilon}}$$\n加上$\\varepsilon$是防止$\\sigma^2$为0\n4. 加上 $\\gamma$ 跟 $\\beta$； `scale and shift the normalized value`\n$$\\hat{z} = \\gamma z_i + \\beta$$\n \n\n$\\gamma$ 跟 $\\beta$ 也是参数，跟`w, b`一样在训练过程中迭代学习。 神经网络中他们也常在激活层之前进行Batch Normalization处理。 \n\n### (Spatially-Adaptive normalization)SPADE\n这篇论文提出自己的normalization思路，$h^i$是 i-th层的激活函数输出。\n正则化处理:\n$$\\gamma_{c, y, x}^i (m)\\frac{h_{n, c, y, x}^i - \\mu_c^i}{\\sigma_c^i} + \\beta_{c, y, x}^{i}(m)$$\n\nc: $c \\epsilon C^i, C^i$是i-th层的channel个数\nx: $x \\epsilon W^i, W^i$是i-th层的宽\ny: $y \\epsilon H^i$, 高\nm: segmentation mask m\n$\\gamma_{c, y, x}^i$跟$\\beta_{c, y, x}^{i}$ 是函数，用卷积网络实现\n\n**结构图**： \n\n![2f3fe4e8.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/1ec7011c.png)\n- `3x3-Conv-k`是 3x3卷积层，有k个卷积filter, filter size 3x3\n- `ReLU` 激活函数 \n- 这里的`Resize`用的是`nearest-neighbor downsampling`，不细说了。\n\n它的处理流程是这样，对sematic image 进行resize、卷积、ReLU激活处理， 即$\\gamma_{c, y, x}^i(m)$跟$\\beta_{c, y, x}^{i}(m)$， 乘、加上`Batch Normalization`的输出数据$\\frac{h_{n, c, y, x}^i - \\mu_c^i}{\\sigma_c^i}$ ， \n![ab4c46cb.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/ad9094aa.png)\n\n比起传统Batch Normal,SPADE的$\\gamma_{c, y, x}^i(m)$跟$\\beta_{c, y, x}^{i}(m)$是对sematic image做卷积操作，它在normalization过程中保存更多semantic的信息。论文中也认为这是SPADE效果更好的原因。\n\n#### 相关代码： \n`normalization.py`\n\n```python\n//  用传统的normalization method正则化激活函数输出\n  if param_free_norm_type == 'instance':\n      self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=False)\n  elif param_free_norm_type == 'syncbatch':\n      self.param_free_norm = SynchronizedBatchNorm2d(norm_nc, affine=False)\n  elif param_free_norm_type == 'batch':\n      self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=False)\n  else:\n      raise ValueError('%s is not a recognized param-free norm type in SPADE'\n                             % param_free_norm_type)\n\n \n```\n```python\n   // 构建gamma,beta函数, 卷积层实现\n   self.mlp_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n   self.mlp_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n```\n\n```python\n  def forward(self, x, segmap):\n\n        # Part 1. generate parameter-free normalized activations\n        normalized = self.param_free_norm(x)\n\n        # ✨✨✨ Part 2. produce scaling and bias conditioned on semantic map\n        segmap = F.interpolate(segmap, size=x.size()[2:], mode='nearest')\n        actv = self.mlp_shared(segmap)\n        gamma = self.mlp_gamma(actv)\n        beta = self.mlp_beta(actv)\n\n        # apply scale and bias\n        out = normalized * (1 + gamma) + beta\n\n        return out\n```\n\n\n## 模型架构 GANs\n\nGANs由两部分组成： \n\n1. generator：负责合成写实风格的图片\n2. discriminator: 负责找茬。认出这是张合成图片， 而不是真实的照片（or 写实图片）\n### generator 架构\n\n首先\n\n![d3313a9e.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/d3313a9e.png)\n\n这幅图里好多SPADE ResBlk啊，啥是SPADE ResBlk? 下面是它的结构图： \n\n![630b2d2a.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/630b2d2a.png)\n\n- `3x3-Conv-k`是 3x3卷积层，有k个卷积filter, filter size 3x3\n- `ReLU` 激活函数\n- SPADE激活见上文分析\n\n\n那`ResBlk`呢？ \n这要从大名鼎鼎的残差网络说起 [Residual block](https://mooc.study.163.com/learn/2001281004?tid=2001392030&_trace_c_p_k2_=5c60eb2c1e0d4adbb2516471e9ebb431#/learn/content?type=detail&id=2001728692) （强烈推荐Andrew Ng公开课; 弄明白几个点： 1. Residual Block要解决什么问题;  2. 它的设计;  3. 为啥有效。 再回来看SPADE ResBlk)\n\n![fd021761.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/fd021761.png)\n```python\n    def __init__(self, fin, fout, opt):\n        super().__init__()\n        # Attributes\n        self.learned_shortcut = (fin != fout)\n        fmiddle = min(fin, fout)\n\n        # create conv layers\n        self.conv_0 = nn.Conv2d(fin, fmiddle, kernel_size=3, padding=1)\n        self.conv_1 = nn.Conv2d(fmiddle, fout, kernel_size=3, padding=1)\n        if self.learned_shortcut:\n            self.conv_s = nn.Conv2d(fin, fout, kernel_size=1, bias=False)\n\n        # apply spectral norm if specified\n        if 'spectral' in opt.norm_G:\n            self.conv_0 = spectral_norm(self.conv_0)\n            self.conv_1 = spectral_norm(self.conv_1)\n            if self.learned_shortcut:\n                self.conv_s = spectral_norm(self.conv_s)\n\n        # ✨✨✨ define normalization layers\n        spade_config_str = opt.norm_G.replace('spectral', '')\n        self.norm_0 = SPADE(spade_config_str, fin, opt.semantic_nc)\n        self.norm_1 = SPADE(spade_config_str, fmiddle, opt.semantic_nc)\n        if self.learned_shortcut:\n            self.norm_s = SPADE(spade_config_str, fin, opt.semantic_nc)\n```\n## Discriminator \n\ndiscriminator架构图。 (segmentation image,  image)作为输入， 任务是识别image是不是假的。\n![c5347e81.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/c5347e81.png)\n\nimage encoder将图片encode生成均值向量跟方差向量， 计算出noise input输入给generator, segmentation mask也会通过SPADE ResBlks输入给generator。 generator生成image跟segmentation image contact后，再输入给discriminator, discriminator来辨别真伪。 \n![f4341bd9.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/f4341bd9.png)\n\n### Training Data \n\n成对的segmentation masks跟真实图片。 (segmentation mask, real image) \n\n### Test \n\n1.安装:\n\n```sh\ngit clone https://github.com/NVlabs/SPADE.git\ncd SPADE/\n```\n2.这个项目依赖PyTorch 1.0跟python3.0+. 还依赖Synchronized-BatchNorm-PyTorch仓库。\n\n```\n// SPADE目录下\ncd models/networks/\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../\n```\n3.用PyCharm打开这个项目, Preference -> Project Interpreter -> Project -> Project Interpreter; 选python3.+的解释器, PyCharm会提示安装依赖的package。依赖包安装好后，如下图: \n\n![ed349b19.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/ed349b19.png)\n\n4.下载提前训练好的模型\n[checkpoints.tar.gz - Google 云端硬盘](https://drive.google.com/file/d/12gvlTbMvUcJewQlSEaZdeb2CdOB-b8kQ/view)\n\n```\ncd checkpoints\ntar xvf checkpoints.tar.gz\ncd ../\n\nls\n// checkpoints目录如下:\nade20k_pretrained     checkpoints.tar.gz    cityscapes_pretrained coco_pretrained\n```\n5.编辑Configuration, 运行test.py脚本。\n```sh\npython test.py --name [type]_pretrained --dataset_mode [dataset] --dataroot [path_to_dataset]\n```\n\n参数： \n- `[type]_pretrained` 先渲染好的模型，coco_pretrained， ade20k_pretrained， cityscapes_pretrained中任选一个。\n- `[dataset]` 填coco, ade20k, 或者cityscapes \n- `[path_to_dataset]` 数据，比如./datasets/coco_stuff\n\n比如，我的参数: \n```\n--name\ncoco_pretrained\n--dataset_mode\ncoco\n--dataroot\n./datasets/coco_stuff\n--gpu_ids\n-1\n```\n输出的路径： `./results/[type]_pretrained/` 我的是`./results/coco_pretrained/`\n\n![412b71cb.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/412b71cb.png)\n\n这几张图片真是看的我有点失望，再看看下图论文的图片。 果然论文的图片都是精挑细选, 套路满满。\n\n![b037261d.png](/img/7c2b5608-840f-411f-bcd4-024df194b0de/b037261d.png)\n\n- [An overview of semantic image segmentation.](https://www.jeremyjordan.me/semantic-segmentation/)","tags":["Image Segment"],"categories":["Neural Network"]},{"title":"The Weights of the YOLO Neural Network","url":"/2019/05/12/The-Weights-of-the-YOLO-Neural-Network/","content":"\n## Load Weights\n\nFirst, see this C library function:  \n```c\nsize_t fread ( void * ptr, size_t size, size_t count, FILE * stream );\n```\n**Parameters**\n- **ptr** − Pointer to a block of memory with a size of at least (size*count) bytes, converted to a void*.\n\n- **size** − This is the size in bytes of each element to be read.\n\n- **count** − This is the number of elements, each one with a size of size bytes.\n\n- **stream** − This is the pointer to a FILE object that specifies an input stream.\n\nThen, in the `load_weights_upto` function in `parser.c`, it begins to load weights for layers from xxx.weights. \n```c\nvoid load_weights_upto(network *net, char *filename, int start, int cutoff) {\n ...\n     // Begin to load weights for layers\n    for(i = start; i < net->n && i < cutoff; ++i){\n        layer l = net->layers[i];\n        if (l.dontload) continue;\n        if(l.type == CONVOLUTIONAL || l.type == DECONVOLUTIONAL){\n            load_convolutional_weights(l, fp);\n        }\n  ...\n}\n```\n\n### Convolutional Layer\nIn `load_convolutional_weights` function, it loads values of biases for filters. One bias for one filter. \n\n```c\n    fread(l.biases, sizeof(float), l.n, fp);\n```\n`l.n` is the number of filter in this layer. \n\nAssign the values to scales, rolling_mean and rooling_variance \n```\n if (l.batch_normalize && (!l.dontloadscales)){\n        fread(l.scales, sizeof(float), l.n, fp);\n        fread(l.rolling_mean, sizeof(float), l.n, fp);\n        fread(l.rolling_variance, sizeof(float), l.n, fp);\n```\n        \nAnd load weights for filters in this layer. The default value of `l.groups` is 1.\n```c\n    int num = l.c/l.groups*l.n*l.size*l.size;\n    fread(l.weights, sizeof(float), num, fp);\n```\n\n`l.c` is input channel. The number of input channel equal to the number of channel of a filter in this layer. Thus, `l.size` is the size of a filter.\n\nFor a 3x3x3 filter (size=3, channel=3), it has 3x3x3=27 parameters as follow  \n\n![-w208](/img/15576478323378/15576531132966.jpg)\n\nIf a convolutional layer has 3 such filters, it will have 3 values for bias, 3x3x3x3 .Its weight layout in memory is like this: \n\n![-w746](/img/15576478323378/15576535368751.jpg)\n\n## Write Weights \n\n`save_weights_upto` and `save_convolutional_weights`functions show how to save weights into a xxx.weights file. It's just a reverse process. \n\n```c\nvoid save_convolutional_weights(layer l, FILE *fp)\n{\n    if(l.binary){\n        //save_convolutional_weights_binary(l, fp);\n        //return;\n    }\n    int num = l.nweights;\n    fwrite(l.biases, sizeof(float), l.n, fp);\n    if (l.batch_normalize){\n        fwrite(l.scales, sizeof(float), l.n, fp);\n        fwrite(l.rolling_mean, sizeof(float), l.n, fp);\n        fwrite(l.rolling_variance, sizeof(float), l.n, fp);\n    }\n    fwrite(l.weights, sizeof(float), num, fp);\n}\n```\n\n```\nsize_t fwrite ( const void * ptr, size_t size, size_t count, FILE * stream );\n\n```\n\n**Parameters**\n- **ptr**\nPointer to the array of elements to be written, converted to a const void*.\n- **size**\nSize in bytes of each element to be written.\nsize_t is an unsigned integral type.\n- **count**\n Number of elements, each one with a size of size bytes.\nsize_t is an unsigned integral type.\n- **stream**\nPointer to a FILE object that specifies an output stream.\n","tags":["YOLO"],"categories":["Neural Network"]},{"title":"LeetCode:237. Delete Node in a Linked List","url":"/2019/05/12/LeetCode-237-Delete-Node-in-a-Linked-List/","content":"\nWrite a function to delete a node (except the tail) in a singly linked list, given only access to that node.\n\n<!--more-->\n\n## [题目](https://leetcode.com/problems/delete-node-in-a-linked-list/)\n\nWrite a function to delete a node (except the tail) in a singly linked list, given only access to that node.\n\nGiven linked list -- head = [4,5,1,9], which looks like following:\n\n![237_example.png](https://assets.leetcode.com/uploads/2018/12/28/237_example.png)\n\n## 分析： \n\n如果我们有一个如下的Linked List，想删除值是5的节点. 这道题要求 ，`only access to that node`。\n\n```\n4 -> 5 -> 1\n```\n\n![48d29b19.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/48d29b19.png)\n留意图中，要删除的对象的地址是0x7ff07ae00090\n\n```c++\n    void deleteNode(ListNode* node) {\n        *node = *(node->next);\n    }\n```\n\n`*node`对node指针取内容，返回是一个对象, 对象地址0x7ff07ae00090\n\n![f94bba4f.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/f94bba4f.png)\n\n`*node->next`对node指针取内容，返回是一个对象， 对象地址0x7ff07ae000a0\n\n![69411ad8.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/69411ad8.png)\n\n执行\n```\n*node = *(node->next);\n```\n结果如下： \n\n![83d8670d.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/83d8670d.png)\n\nnode指针所执行的对象地址不变，但是对象内容发生变化。就像三个房子，位置没变， 但是第三个房子里的住户搬到了第二个房子里住了。 node指针指向的对象的地址依旧是0x7ff07ae00090, val不再是5而是1， next指针也执向NULL。但是我们也丢失了对0x7ff07ae000a0对象的指针引用。\n\n![e8798a20.png](/img/f394f304-a25b-4128-bcaa-779a974c8c4a/e8798a20.png)","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode  Flatten a Multilevel Doubly Linked List","url":"/2019/05/12/LeetCode-Flatten-a-Multilevel-Doubly-Linked-List/","content":"Flatten the list so that all the nodes appear in a single-level, doubly linked list. You are given the head of the first level of the list.\n\n<!--more-->\n\n题目： [430. Flatten a Multilevel Doubly Linked List]([Loading...](https://leetcode.com/problems/flatten-a-multilevel-doubly-linked-list/)\n)\n\n分析： \n![da80f35a.png](/img/ed6ee62a-3dcb-4189-9404-14b91692d436/da80f35a.png)\n\n 当遇到有child的Node，先用`*next`存cur->next; 把cur->next指针指向child, child->pre指向cur； 接着以child为起点找到该曾最后一个Node，让它指向`*next`的节点。 接着以原来的child为cur Node重新开始一轮。 \n\n```c++\n    class Node {\n    public:\n        int val;\n        Node *prev;\n        Node *next;\n        Node *child;\n\n        Node() {}\n\n        Node(int _val, Node *_prev, Node *_next, Node *_child) {\n            val = _val;\n            prev = _prev;\n            next = _next;\n            child = _child;\n        }\n    };\n\n    Node *flatten(Node *head) {\n        Node *cur = head;\n        while (cur) {\n            if (cur->child) {\n                Node *next = cur->next;\n                cur->next = cur->child;\n                cur->child = nullptr;\n                cur->next->prev = cur;\n\n                // iter the children \n                Node *p = cur->next;\n                while (p->next) p = p->next;\n                  \n                p->next = next;\n                if (next) next->prev = p;\n            }\n            cur = cur->next;\n        }\n\n        return head;\n    }\n```\n\n时间复杂度： $O(n)$","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"YOLO - From Configuration File to Convolutional Layers","url":"/2019/05/08/The-Implementation-of-Convolutional-and-MaxPool-layer/","content":"\n Let's firstly see how `Darknet` construct a neural network. See at `detector.c` `test_detector` function, it construct a network by parsing  the `xxx.cfg` file and `xxx.weights` file. In my case, they are yolo3-tiny.cfg and yolo3-tiny.weights \n <!-- more --> \n\n\nI am trying to understand [Darknet source code](https://pjreddie.com/darknet/yolov2/) that implements YOLO algorithm. First, I run the detector.\n\n```\n./darknet detect cfg/yolov3-tiny.cfg yolov3-tiny.weights data/dog.jpg\n```\n## Parse the argumenets \n\nIn `main` function, it goes to function `test_detector` according to the first argument`detect`. \n\n```c\nif (0 == strcmp(argv[1], \"detect\")){\n   float thresh = find_float_arg(argc, argv, \"-thresh\", .5);\n   char *filename = (argc > 4) ? argv[4]: 0;\n   char *outfile = find_char_arg(argc, argv, \"-out\", 0);\n   int fullscreen = find_arg(argc, argv, \"-fullscreen\");\n   test_detector(\"cfg/coco.data\", argv[2], argv[3], filename, thresh, .5, outfile, fullscreen);\n   }   \n```\n\nHere is the architecture of neural network defined by yolov3-tiny.cfg\n\n```\n\nlayer     filters    size              input                output\n    0 conv     16  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  16  0.150 BFLOPs\n    1 max          2 x 2 / 2   416 x 416 x  16   ->   208 x 208 x  16\n    2 conv     32  3 x 3 / 1   208 x 208 x  16   ->   208 x 208 x  32  0.399 BFLOPs\n    3 max          2 x 2 / 2   208 x 208 x  32   ->   104 x 104 x  32\n    4 conv     64  3 x 3 / 1   104 x 104 x  32   ->   104 x 104 x  64  0.399 BFLOPs\n    5 max          2 x 2 / 2   104 x 104 x  64   ->    52 x  52 x  64\n    6 conv    128  3 x 3 / 1    52 x  52 x  64   ->    52 x  52 x 128  0.399 BFLOPs\n    7 max          2 x 2 / 2    52 x  52 x 128   ->    26 x  26 x 128\n    8 conv    256  3 x 3 / 1    26 x  26 x 128   ->    26 x  26 x 256  0.399 BFLOPs\n    9 max          2 x 2 / 2    26 x  26 x 256   ->    13 x  13 x 256\n   10 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512  0.399 BFLOPs\n   11 max          2 x 2 / 1    13 x  13 x 512   ->    13 x  13 x 512\n   12 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n   13 conv    256  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 256  0.089 BFLOPs\n   14 conv    512  3 x 3 / 1    13 x  13 x 256   ->    13 x  13 x 512  0.399 BFLOPs\n   15 conv    255  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x 255  0.044 BFLOPs\n   16 yolo\n   17 route  13\n   18 conv    128  1 x 1 / 1    13 x  13 x 256   ->    13 x  13 x 128  0.011 BFLOPs\n   19 upsample            2x    13 x  13 x 128   ->    26 x  26 x 128\n   20 route  19 8\n   21 conv    256  3 x 3 / 1    26 x  26 x 384   ->    26 x  26 x 256  1.196 BFLOPs\n   22 conv    255  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x 255  0.088 BFLOPs\n   23 yolo\n```\nNow, let's see how Darknet construct a nerual network. See  `detector.c` `test_detector` function, it construct a network by parsing  the `xxx.cfg` file and `xxx.weights` file. In my case, they are yolo3-tiny.cfg and yolo3-tiny.weights \n\n\n## Parse the configuration file\n\n### Sections in the file \n\nThe code to parse the yolo.cfg file is here:\n\n```c\nlist *read_cfg(char *filename)\n{\n    FILE *file = fopen(filename, \"r\");\n    if(file == 0) file_error(filename);\n    char *line;\n    int nu = 0;\n    list *options = make_list();\n    section *current = 0;\n    while((line=fgetl(file)) != 0){\n        ++ nu;\n        strip(line);\n        switch(line[0]){\n            case '[':\n                current = malloc(sizeof(section));\n                list_insert(options, current);\n                current->options = make_list();\n                current->type = line;\n                break;\n            case '\\0':\n            case '#':\n            case ';':\n                free(line);\n                break;\n            default:\n                if(!read_option(line, current->options)){\n                    fprintf(stderr, \"Config file error line %d, could parse: %s\\n\", nu, line);\n                    free(line);\n                }\n                break;\n        }\n    }\n    fclose(file);\n    return options;\n}\n```\n\n\nfor exmaple: \n\n```js\n[net]              // '[' is a tag for a section, the type of current setion is '[net]'\n# Testing          // ignore\nbatch=1         \nsubdivisions=1\n# Training\n# batch=64\n# subdivisions=2\nwidth=416\nheight=416\nchannels=3\nmomentum=0.9\ndecay=0.0005\nangle=0\nsaturation = 1.5\nexposure = 1.5\nhue=.1\n                 // ignore\nlearning_rate=0.001\n...\n\n[convolutional]    // [convoltional] \n...\n\n[maxpool]      // [maxpool] \n\n...\n[yolo]\n...\n\n[route]\n...\n\n```\n\n#### `[net]`\n\nIn section '[net]', `batch=1` is a option stored in `kvp`(option_list.c line 70) structure. Its key is batch, value is 1. Then this kvp object will be inserted into a node list (see it at option_list.c line76 & list.c line 40).\nAfter parsing the yolo3-tiny.cfg file, We will get a section list; its size is 25. Because there are 25 \\'[\\' tags in yolo3-tiny.cfg\n\n\nIn `parse_network_cfg` function, it parses the `[net]` section to get the params for the whole network. \n\n```c\nnetwork *parse_network_cfg(char *filename)\n{\n    list *sections = read_cfg(filename);\n    node *n = sections->front;\n    if(!n) error(\"Config file has no sections\");\n    network *net = make_network(sections->size - 1);\n    // other codes ...\n    \n}\n```\n\n#### `[convolutional]`\n\nThen parse the different sections. \n\n```c\n        s = (section *)n->val;\n        options = s->options;\n        layer l = {0};\n        LAYER_TYPE lt = string_to_layer_type(s->type);\n        if(lt == CONVOLUTIONAL){\n            l = parse_convolutional(options, params);\n        }else if(lt == DECONVOLUTIONAL){\n            l = parse_deconvolutional(options, params);\n        }else if(lt == LOCAL){\n            l = parse_local(options, params);\n        }else if(lt == ACTIVE){\n            l = parse_activation(options, params);\n        // other code here ...\n       \n```\n\n\nFor the first `[convolutional]` section in the yolo3-tiny.cfg as follow, the darknet will construct a `convolutional_layer` using thess params (see function `parse_convolutional` in parse.c and  function `make_convolutional_layer` in convolutional_layer.c)\n\n```js\n[convolutional]\nbatch_normalize=1\nfilters=16\nsize=3\nstride=1\npad=1\nactivation=leaky\n```\n\nIn this layer, there are 16 filters; the size of each filter is 3X3Xnum_channel; what is num_channel? well, `the number of channels in a filter must match the number of channels in input volume`, so here num_channel is equal to 3. The stride value for filters is 1, padding value is 1. \n\n\nLet's see how darknet calculate the output size of convolutional_layer by the input size(`l.h`) and filter params (`l.size`, `l.pad`, `l.stride`). There is a formula that shows how size of input volume relates to the one of output volume\n \n\n```c\n\nint convolutional_out_height(convolutional_layer l)\n{\n    return (l.h + 2*l.pad - l.size) / l.stride + 1;\n}\n\nint convolutional_out_width(convolutional_layer l)\n{\n    return (l.w + 2*l.pad - l.size) / l.stride + 1;\n}\n\n```\n\n As for yolo3-tiny.cfg, for this first convolutional_layer, its input size is 416 x 416 and channel is 3. So its ouput height is (416+2x1 - 3)/1 + 1 = 416, its output width is 416 too. `What about its output channel? It equals to the number of filters (16)`. \n \n ```c\n \n  l.out_c = n    // in func make_convolutional_layer\n  \n ```\n So its output volume size is 416 X 416 X 16.\n \n \n ![02b028d9.png](/img/995676c2-24ed-4165-8224-0bc01148242a/9b76325f.png)\n \n For a beginner, I strongly recommend these courses: [Strided Convolutions - Foundations of Convolutional Neural Networks \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/strided-convolutions-wfUhx) and  [One Layer of a Convolutional Network - Foundations of Convolutional Neural Networks \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/one-layer-of-a-convolutional-network-nsiuW)\n  \nNow, we have 16 filters that are 3X3X3 in this layer, `how many parameters does this layer have`?  Each filter is a 3X3X3 volume, so it's 27 numbers tp be learned, and then plus the bias, so that was the b parameters. it's 28 parameters. There are 16 filters so that would be 448 parameters to be learned in this layer. \n \n```c\n\n    // c: the number of channels; n: the number of filters; \n    // size: the number of filter width or height; groups: default is 1 \n    l.weights = calloc(c/groups*n*size*size, sizeof(float));\n    l.weight_updates = calloc(c/groups*n*size*size, sizeof(float));\n\n    l.biases = calloc(n, sizeof(float));\n    l.bias_updates = calloc(n, sizeof(float));\n\n    l.nweights = c/groups*n*size*size;\n    l.nbiases = n;\n\n```\n \n \n#### Activation \n \n In this convolution layer, it choose leaky ReLU as activation function. The function is defined as follow  where α is a small constant.\n \n $$\nf(x)=\\begin{cases}\nαx,\\quad x\\leq 0 \\\\\\\\ \nx,\\quad x>0\n\\end{cases}\n$$\n\n \n Still, I recommend this course for a beginner. [Activation functions - Shallow neural networks \\| Coursera](https://www.coursera.org/lecture/neural-networks-deep-learning/activation-functions-4dDC1)\n\n \nThere are `forward_activation_layer` and `backward_activation_layer` in Darknet. Both of them handle batch inputs. \n\nFor forward activation layer, leaky_activate is to computes f(x)\n\n ```c\n static inline float leaky_activate(float x){return (x>0) ? x : .1*x;}\n ```\n For backward activation layer, leaky_gradient returns the slop of the function \n\n```c\nstatic inline float leaky_gradient(float x){return (x>0) ? 1 : .1;}\n```\n\n\n \n \n#### [maxpool]\n \n Maxpool layer is used to reduce the size of representation to speed up computation as well as to make some of the features it detects a bit more robust. Look at the `tiny-yolo3.cfg`\n \n ```js\n [maxpool]\nsize=2\nstride=2\n\n ```\n ```c\n maxpool_layer make_maxpool_layer(int batch, int h, int w, int c, int size, int stride, int padding)\n{\n    maxpool_layer l = {0};\n    l.type = MAXPOOL;\n    l.batch = batch;\n    l.h = h;\n    l.w = w;\n    l.c = c;         // output channel equals to input one \n    l.pad = padding;  // default value is size - 1\n    l.out_w = (w + padding - size)/stride + 1;\n    l.out_h = (h + padding - size)/stride + 1;\n    l.out_c = c;\n    l.outputs = l.out_h * l.out_w * l.out_c;\n    // other codes ...\n    return l;\n}\n\n \n ```\n This `[maxpool]` sections comes after the `[convolutional]` section. Its input size(416 x 416 x 16) equal to the output size of the former layer (416 x 416 x  16). The filter size is 2 x 2, stride is 2. Each time, the filter would move 2 steps, for a 4x4x1 input volume, its output is 2x2x1 volume. \n![e65fb56d.png](/img/995676c2-24ed-4165-8224-0bc01148242a/e65fb56d.png)\n```\n9 == max(1, 3, 2, 9)\n2 == max(2, 1, 1, 1)\n6 == max(1, 3, 5, 6)\n3 == max(2, 3, 1, 2)\n```\nSo in this layer, its ouput width equals to (int)((416+ 1 - 2)/2 + 1), 208. And the number of its output channels equals to the number of input channels. Now, we know its output volume size is 208 X 208 X 16. There is no parameter to be learned. \n\n**input volume size**: \n\n$$ n_H . n_W . n_c$$\n\n  $n_c$ : the number of channels\n\n**output volume size**: \n\n$$(\\frac{n_H + padding-f}{stride} + 1) . (\\frac{n_W + padding-f}{stride} +1) . n_c$$\n \n$f$: the width or height of a filter\n \n [Pooling Layers - Foundations of Convolutional Neural Networks \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/pooling-layers-hELHk)\n \n #### Why does 1 x 1 convolution do? \n \n [Networks in Networks and 1x1 Convolutions - Deep convolutional models: case studies \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/networks-in-networks-and-1x1-convolutions-ZTb8x)\n \n \n For example, in this picture, the number of input volume channels ,192, has gotten too big, we can shrink it to a 28x28x32 dimension volume using 32 filters that are 1x1x192. So this is a way to shrink the number of channels .\n \n ![a085e0e4.png](/img/995676c2-24ed-4165-8224-0bc01148242a/a085e0e4.png)\n \n \n In YOLO, it implements fully connected layer by two convolutional layer. \n \n ```\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=255\nactivation=linear\n ```\n \n [Convolutional Implementation of Sliding Windows - Object detection \\| Coursera](https://www.coursera.org/lecture/convolutional-neural-networks/convolutional-implementation-of-sliding-windows-6UnU4)\n \n","tags":["YOLO"],"categories":["Neural Network"]},{"title":"LeetCode Unique Paths 1-2","url":"/2019/05/08/Leetcode-Unique-Paths-1-2/","content":"Leetcode Unique Paths 1-2 \n<!-- more --> \n\n# Unique Paths 1-2\n\n## 题目1： [Unique Paths 1](https://leetcode.com/problems/unique-paths/)\n\n![e2ca2848.png](/img//c5619f25-13a6-4e38-b7f8-d87ff624f5b5/e2ca2848.png)\n\n### 动态规划解题步骤要点: \n\n1. 找到最优解的结构\n2. 递归方案\n3. bottom-up 或者 top-down方式求最优解\n4. 优化，空间换时间\n\n### 分析\n\n这道题很简单。\n1. 定义一个 mxn 的二维数组grides[m][n]， 对应格子地图。对应途中grides[2][6]\n\n![e594b650.png](/img//c5619f25-13a6-4e38-b7f8-d87ff624f5b5/e594b650.png)\n比如，我们想知道从(0,0)到(1, 2)有几条路。根据题目要求，只能往右走或者下走一个格子。\n我们先看从(1, 1)到（1，2），两种走法： \n- (2, 0) -> (1, 2)\n- (1, 1) -> (1, 2)\n\n再看从(0, 0)到(2， 0) 只有一条路: (0, 0) -> (1, 1) -> (2, 0)； grides[2][0] = 1。\n\n从(0, 0)格子到(1,1)格子，有两种路: \n- (0,0) -> (0, 1)-> (1, 1)\n- (0,0) -> (1, 0)-> (1, 1)\n那么grides(1, 1) = 2. \n \n很容易发现规律， grids[m][n] = grids[m - 1][n] + grides[m][n -1]; 可用递归求解。但是纯碎的递归有很多重复计算。 如下图的递归树： \n![72a3d4ef.png](/img//c5619f25-13a6-4e38-b7f8-d87ff624f5b5/72a3d4ef.png)\n所以我们引入一个record数组，记录已经计算的结果，省去重复计算。\n\n时间复杂度: \no(m* n)\n\n```c++\nint inner_path(int i, int j, int m, int n, vector<vector<int>>& record) {\n    if (i < 0 || j < 0) {\n        return 0;\n    }\n\n    if (record[i][j]) {\n        return record[i][j];\n    }\n\n    if ((i == 0) && (j == 0)) {\n        return 1;\n    }\n\n    record[i][j] = inner_path(i-1, j, m, n, record) + inner_path(i, j-1, m, n, record);\n    return record[i][j];\n}\n\nint uniquePaths(int m, int n) {\n    vector<vector<int>> res(m, vector<int>(n, 0));\n    return inner_path(m-1, n-1, m, n, res);\n}\n```\n\n### [Unique Paths 2](https://leetcode.com/problems/unique-paths-ii/)\n\n分析： \n跟Unique Paths 1比起来，多了障碍物。如果(i, j)是障碍物，那么grid(i, j) = 0, 表示我们无法经由(i, j) 到达终点。\n\n\n\n```c++\nint path_helper(int i, int j, int m, int n, vector<vector<int>>& record, vector<vector<int>> &obstacleGrid) {\n        if (i < 0 || j < 0 || obstacleGrid[i][j] == 1) {\n            return 0;\n        }\n\n        if (record[i][j]) {\n            return record[i][j];\n        }\n\n        if ((i == 0) && (j == 0)) {\n            return 1;\n        }\n\n        record[i][j] = path_helper(i - 1, j, m, n, record, obstacleGrid) + path_helper(i, j - 1, m, n, record, obstacleGrid);\n        return record[i][j];\n    }\n\n    int uniquePathsWithObstacles(vector<vector<int>>& obstacleGrid) {\n        if (obstacleGrid.empty()) return 0;\n        int m = (int)obstacleGrid.size();\n        int n = (int)obstacleGrid[0].size();\n\n        vector<vector<int>> res(m, vector<int>(n, 0));\n        return path_helper(m - 1, n - 1, m, n, res, obstacleGrid);\n    }\n```\n\n自底向上的写法： \n\n```c++\n   int uniquePathsWithObstacles(vector<vector<int>>& grid) {\n        int rows = grid.size();\n        if(rows == 0) return 0;\n        int cols = grid[0].size();\n        vector<vector<long>> res(rows+1, vector<long>(cols+1, 0));\n        for(int i=rows-1; i>=0;i--){\n            for(int j=cols-1; j>=0;j--){\n                if(grid[i][j] == 1) res[i][j] = 0;\n                else if(i == rows-1 && j == cols-1) res[i][j] = 1;\n                else res[i][j] = res[i][j+1] + res[i+1][j];\n            }\n        }\n        return res[0][0];\n    }\n```","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"LeetCode 959. Regions Cut By Slashes 笔记","url":"/2019/04/23/Leetcode-959-Regions-Cut-By-Slashes/","content":"\n题目：https://leetcode.com/problems/regions-cut-by-slashes/description/\n\n## Solution1: DFS \n\nTime Complexity::  $O(n^2)$\n\n### 分析： \n[这个神奇的思路](https://leetcode.com/problems/regions-cut-by-slashes/discuss/205674/C++-with-picture-DFS-on-upscaled-grid)分割格子，转化为图的DFS问题。\n```json\nInput:\n[\n  \"\\\\/\",\n  \"/\\\\\"\n]\n```\n\n把`\\\\`，`/`或者` `分别分割成3*3的格子。图转化为: \n\n```json\n[\n 1,0,0,0,0,1,\n 0,1,0,0,1,0,\n 0,0,1,1,0,0\n 0,0,1,1,0,0\n 0,1,0,0,1,0\n 1,0,0,0,0,1\n]\n```\n\n问题就变成： 计算被1分割开的区域的数量。\n\n类似的[孤岛数量问题](https://www.geeksforgeeks.org/find-number-of-islands/) 都是同一个问题的变种：[Counting the number of connected components in an undirected graph](https://www.geeksforgeeks.org/connected-components-in-an-undirected-graph/)\n\n```c++\nvoid dfs(vector<vector<int>>& board, int i, int j ) {\n    // index out of range\n    if (i < 0 || j < 0 || i >= board.size() || j >= board[0].size()) return;\n    // this grid has been visited or it was part of a slash character\n    if (board[i][j] == 1) return;\n\n    // mark this grid visited\n    board[i][j] = true;\n\n    dfs(board, i - 1, j);\n    dfs(board, i + 1, j);\n    dfs(board, i, j - 1);\n    dfs(board, i, j + 1);\n}\n\nint regionsBySlashes(vector<string>& grid) {\n    if (grid.empty())\n        return 0;\n    int row = (int)grid.size(), col = (int)grid[0].size();\n    vector<vector<int>> board (row * 3, vector<int>(col * 3, 0));\n\n    // n*n graph represented as 3n*3n graph\n    for (int i = 0; i < row; ++i) {\n        for (int j = 0; j < col; ++j) {\n            if (grid[i][j] == '/') board[i * 3][j * 3 + 2] = board[i * 3 + 1][j * 3 + 1] = board[i * 3 + 2][j * 3] = 1;\n            if (grid[i][j] == '\\\\') board[i * 3][j * 3] = board[i * 3 + 1][j * 3 + 1] = board[i * 3 + 2][j * 3 + 2] = 1;\n        }\n    }\n\n    int cnt = 0;\n    for (int i = 0; i < row * 3; ++i) {\n        for (int j = 0; j < col * 3; ++j) {\n            // only count components connected by space\n            if (!board[i][j]) {\n               dfs(board, i, j);\n               cnt++;\n            }\n        }\n    }\n\n    return cnt;\n}\n\n```\n\n如果分割为2*2的格子，会遇到这个问题:\n```\nInput:\n[\n  \"//\",\n  \"/ \"\n]\nOutput: 5\nExpected: 3\n\n0101\n1010\n0100\n1000\n```\n01**0**1\n1**0**10\n**0**100\n1000\n\n加粗的这三个0，被分割开了。题意要求是连在一起的。\n\n\n## Solution2: DSU\n\nTime Complexity:  $O(n^2*\\alpha(n))$\nSpace Complexity: $O(n^2)$\n\n### 分析： \n\n#### DSU: \nhttps://www.youtube.com/watch?v=YKE4Vd1ysPI\nhttps://www.youtube.com/watch?v=gpmOaSBcbYA\n\nDSU中用数组来表示树， 如下： \n\n| idx | 0 |  1 | 2 |\n| --- | --- | --- | --- |\n| parent | 1 | -1 | 1 |\n\n \nparent[0] = 1, 代表node 0的parent是1； parent[2] = 1代表node 2的parent是1; parent[1] = -1, 代表它是root。 \n\n```\n   1\n /  \\\n0    2\n```\n\n两个operation： \n**find(x)**: find root of cluster in which x is \n\n```\n   1                   5\n  / \\                 / \\\n 0   2               6   7\n    / \\                   \\\n   3   4                  8\n```\n比如： 我们想找3跟8所在cluster的root， find(3) == 1,  find(8) == 5\n\n```c\n/*递归查找root*/\nint find(int x, int parent[]) {\n    int x_root = x; \n    while (parent[x_root]!= -1) {\n        x_root = parent[x_root];\n    }\n    return x_root;\n}\n```\n**union(x, y)**: union two cluster where x, y are in \n\n比如： 我们想union(3, 8),  就要先找到3的x_root， 跟8的y_root，然后合并两个root.\n\n```c\nint union(int x, int y, int parent[]) {\n    int x_root = find(x, parent);\n    int y_root = find(y, parent); \n    if (x_root == y_root) {\n        return 0; \n    } else {\n        // y_root 变成 x_root的根\n        parent[x_root] = y_root;\n        return 1\n    }\n}\n```\n\n```\n              5\n         /   / \\\n        1   6   7\n       / \\       \\\n      0   2       8\n         / \\ \n        3   4 \n```\n\n                                \nDSU腻害的一点是优化后，用$O(1)$的average time cost, 检测图里有咩有环\n\n两种优化： \n- Make tree flat \n- Union by rank\n\nhttps://www.youtube.com/watch?v=VJnUwsE4fWA\n\n\n### 分割成4个三角形， 上下左右\n每个格子分割成上下左右四个三角形。\nhttps://assets.leetcode.com/uploads/2018/12/15/3.png\n\n每个三角形给个idx: 0, 1, 2, 3分别对应 top, right, bottom, left\n```\n\\ 0 /\n3 \\ 1\n/ 2 \\\n```\nn*n的图；变成 4*n*n的数组。 初始化时数组parent的每个值都是-1, 代表每个点都是独立的。我们遍历grid中的每个点, grid[i][j]， 分别进行如下操作： \n\n'/':  上、左连接； 下、右连接\n'\\\\': 上、右连接； 左、下连接\n' ': 四个部分连接\n\n对每个grid[i][j], 合并grid[i-1][j]的bottom三角形根grid[i][j]的top 三角形；合并grid[i][j-1]的right三角形跟grid[i][j]的left三角形。\n\n最终代码如下:\n\n```c++\nclass DSU {\nprivate:\n    // use array represents a graph\n    vector<int> parent;\n    int row = 0;\npublic:\n    // num of root of independent cluster\n    int num_root = 0;\n\n    DSU(int n) {\n        parent = vector<int>(n * n * 4, -1);\n        num_root = n * n * 4;\n        row = n;\n    }\n\n    int find(int x) {\n        // find the root of the cluster where x is iteratively\n        while (parent[x] != -1) {\n            x = parent[x];\n        }\n        return x;\n    }\n\n    /**\n    * return: 1: successfully; 0: failed\n    */\n    int union_cluster(int x, int y) {\n        int x_root = find(x);\n        int y_root = find(y);\n        if (x_root == y_root) {\n            return 0;\n        } else {\n            int min_ = min(x_root, y_root);\n            int max_ = max(x_root, y_root);\n            parent[min_] = max_;\n            \n            num_root--;\n            return 1;\n        };\n    }\n\n    /**\n     * 将图中（i,j)位置的点，映射到数组的idx\n     * @param i\n     * @param j\n     * @param part\n     * @param n\n     * @return\n     */\n    int idx(int i, int j, int part) {\n        return (i * row + j) * 4 + part;\n    }\n};\n\n\n// https://leetcode.com/problems/regions-cut-by-slashes/discuss/205680/JavaC%2B%2BPython-Split-4-parts-and-Union-Find\nint regionsBySlashes(vector<string> &grid) {\n    if (grid.empty()) return 0;\n    int n = (int) grid.size();\n\n    DSU dsu = DSU(n);\n\n    for (int i = 0; i < n; ++i) {\n        for (int j = 0; j < n; ++j) {\n            // merge the bottom part of the (i-1, j) grid and the top part of the grid (i, j)\n            if (i > 0) dsu.union_cluster(dsu.idx(i - 1, j, 2), dsu.idx(i, j, 0));\n            // merge the right part of the (i, j-1) grid and the left part of the grid(i,j)\n            if (j > 0) dsu.union_cluster(dsu.idx(i, j - 1, 1), dsu.idx(i, j, 3));\n\n            if (grid[i][j] == '/') {\n                // union the top and the left part of this cell\n                dsu.union_cluster(dsu.idx(i, j, 3), dsu.idx(i, j, 0));\n                // union the right and the bottom of this cell\n                dsu.union_cluster(dsu.idx(i, j, 2), dsu.idx(i, j, 1));\n            }\n\n            if (grid[i][j] == '\\\\') {\n                dsu.union_cluster(dsu.idx(i, j, 0), dsu.idx(i, j, 1));\n                dsu.union_cluster(dsu.idx(i, j, 2), dsu.idx(i, j, 3));\n            }\n\n            if (grid[i][j] == ' ') {\n                dsu.union_cluster(dsu.idx(i, j, 0), dsu.idx(i, j, 2));\n                dsu.union_cluster(dsu.idx(i, j, 1), dsu.idx(i, j, 3));\n                dsu.union_cluster(dsu.idx(i, j, 1), dsu.idx(i, j, 2));\n            }\n        }\n    }\n\n    return dsu.num_root;\n}\n\n```\n\nhttps://leetcode.com/problems/regions-cut-by-slashes/discuss/205680/JavaC%2B%2BPython-Split-4-parts-and-Union-Find\n","tags":["Algorithm"],"categories":["Algorithm"]},{"title":"XMPP(6):XMPP-消息存储与拉取历史消息","url":"/2019/04/10/XMPP-6-XMPP-消息存储与拉取历史消息/","content":"\n\nXEP-0313定义了XMPP消息存储的规则。\n\n### 场景需求\n0313协议主要有这些场景： \n- 同账号多客户端之间的历史消息同步\n- 客户端拉取历史消息，按日期排序展示（想想我们在微信的历史消息）\n- 分页拉取消息\n\n### 存储\n\n1. 单条消息存储包括： \n- 消息发送跟接收的时间戳\n- from 跟 to 的JID\n- server-assigned UID\n- message stanza \n\n2. 消息的顺序要保存： 依赖timestamp要小心，因为多条消息可能共享时间戳\n3. 超过一定数量，可删除旧信息\n4. 群聊记录用MAM服务\n5. archive id ` <stanza-id/>`\n被archived过的消息，server要给它加上stanza-id\nExample 1. Client receives a message that has been archived\n\n```xml\n<message to='juliet@capulet.lit/balcony'\n         from='romeo@montague.lit/orchard'\n         type='chat'>\n  <body>Call me but love, and I'll be new baptized; Henceforth I never will be Romeo.</body>\n  <stanza-id xmlns='urn:xmpp:sid:0' by='juliet@capulet.lit' id='28482-98726-73623' />\n</message>\n\n```\nstanza-id: archive ID \n\n### 查询\n\n#### 1. A user queries their archive for messages\n用消息UID查询\n\n'urn:xmpp:mam:2' namespace, indicating the UID of the first and last message of the (possibly limited) result set. \n\n```xml\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2' queryid='f27' />\n</iq>\n```\n\n#### 2. Their server sends the matching messages\n\n\n\n```xml\n<message id='aeb213' to='juliet@capulet.lit/chamber'>\n  <result xmlns='urn:xmpp:mam:2' queryid='f27' id='28482-98726-73623'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:08:25Z'/>\n      <message xmlns='jabber:client' from=\"witch@shakespeare.lit\" to=\"macbeth@shakespeare.lit\">\n        <body>Hail to thee</body>\n      </message>\n    </forwarded>\n  </result>\n</message>\n\n```\n\n#### 3. Server returns the result IQ to signal the end\n\n\n```xml\n<iq type='result' id='juliet1'>\n  <fin xmlns='urn:xmpp:mam:2'>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <first index='0'>28482-98726-73623</first>\n      <last>09af3-cc343-b409f</last>\n    </set>\n  </fin>\n</iq>\n```\n\nserver的这条iq stanza标记查询结果结束。\n\n### 过滤器\n\n#### 1. 根据JID过滤\n\n`with` 字段 + JID(Bare JID)： 会拿到to或from地址匹配JID的信息; 如果没有with, 服务端返回query指定的时间段内的消息。 \n\n```xml \nExample 6. Querying for all messages to/from a particular JID¶\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='with'>\n        <value>juliet@capulet.lit</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\n**使用场景：**\nA想查询跟B的聊天记录，with字段的value设为B, 服务端返回的messages中，既有B发送给A的msg，也有A发送给B的msg。 \n\n![3c4760c7.png](/img/f3eaaed1-370f-4abc-93b2-a3312d3ebcd4/3c4760c7.png)\n#### 2. 根据接收时间过滤\n\n`start` 跟 `end` 字段标记时间戳。 时间戳格式见https://xmpp.org/extensions/xep-0082.html\n\n```xml\nExample 7. Querying the archive for all messages in a certain timespan¶\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='start'>\n         // UTC格式\n        <value>2010-06-07T00:00:00Z</value>\n      </field>\n      <field var='end'>\n        <value>2010-07-07T13:23:54Z</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n如果`end` 缺失， server会自动认为是最近的消息的存储时间\n\n``` xml\nExample 8. Querying the archive for all messages after a certain time¶\n<iq type='set' id='juliet1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='start'>\n        <value>2010-08-07T00:00:00Z</value>\n      </field>\n    </x>\n  </query>\n</iq>   \n```\n\n#### 3. 限定results的数量\n\n[Result Set Management (XEP-0059)](https://xmpp.org/extensions/xep-0059.html) \n\n```xml\nExample 9. A query using Result Set Management¶\n<iq type='set' id='q29302'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field var='FORM_TYPE' type='hidden'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field var='start'>\n        <value>2010-08-07T00:00:00Z</value>\n      </field>\n    </x>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <max>10</max>\n    </set>\n  </query>\n</iq>\n```\n\n这个请求，指定客户端最多只能收到10条stanzas。但服务端的返回结果可能回改变`set`的内容，返回自己限定的数量，比如： 这是返回`start`时间跟`end`时间段内的20条消息。\n\n```xml\nExample 10. Server responds to client with limited results using RSM¶\n<!-- result messages -->\n<iq type='result' id='q29302'>\n  <fin xmlns='urn:xmpp:mam:2'>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <first index='0'>28482-98726-73623</first>\n      <last>09af3-cc343-b409f</last>\n      <count>20</count>\n    </set>\n  </fin>\n</iq>\n```\n\n#### 4. 分页拉取消息\n\n如果之前已经获取了m条消息，客户端可以再发送同样的请求，拉取下一页消息。`set`中要带上`after`(上次拉取到的最后一条消息的UID)\n\n```xml\nExample 11. A page query using Result Set Management¶\n<iq type='set' id='q29303'>\n  <query xmlns='urn:xmpp:mam:2'>\n      <x xmlns='jabber:x:data' type='submit'>\n        <field var='FORM_TYPE' type='hidden'><value>urn:xmpp:mam:2</value></field>\n        <field var='start'><value>2010-08-07T00:00:00Z</value></field>\n      </x>\n      <set xmlns='http://jabber.org/protocol/rsm'>\n         <max>10</max>\n         <after>09af3-cc343-b409f</after>\n      </set>\n  </query>\n</iq>\n```\n\nserver返回最后一页消息，会在 fin里头带上`complete`属性，值为`ture`\n\n```xml\nExample 12. Server completes a result with the last page of messages¶\n<!-- result messages -->\n<iq type='result' id='u29303'>\n  <fin xmlns='urn:xmpp:mam:2' complete='true'>\n    <set xmlns='http://jabber.org/protocol/rsm'>\n      <first index='0'>23452-4534-1</first>\n      <last>390-2342-22</last>\n      <count>16</count>\n    </set>\n  </fin>\n</iq>\n    \n```\n\n**使用场景：**\n\nA客户端本地存储跟B的聊天信息， 最后一条message的id是`09af3-cc343-b409f`。 现在A想看看最近的消息（`09af3-cc343-b409f`后的message，可以发送iq请求中带上`<after>09af3-cc343-b409f</after>`。差量请求最新消息，基于游标的分页。\n#### 5.其他字段的筛选\n\n客户端查询服务端支持的其他字段\n```xml\nExample 13. Client requests supported query fields¶\n<iq type='get' id='form1'>\n  <query xmlns='urn:xmpp:mam:2'/>\n</iq>\n```\n\n```xml\nExample 14. Server returns supported fields¶\n<iq type='result' id='form1'>\n  <query xmlns='urn:xmpp:mam:2'>\n    <x xmlns='jabber:x:data' type='form'>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>urn:xmpp:mam:2</value>\n      </field>\n      <field type='jid-single' var='with'/>\n      // 按消息received时间查询\n      <field type='text-single' var='start'/>\n      <field type='text-single' var='end'/>\n      // 按文本查询\n      <field type='text-single' var='urn:example:xmpp:free-text-search'/>\n      // stanza内容\n      <field type='text-single' var='urn:example:xmpp:stanza-content'/>\n    </x>\n  </query>\n</iq>\n```\n### 返回的message stanza 结构\n\n- `message`被封装在`forwarded`元素中。 [XEP-0297: Stanza Forwarding](https://xmpp.org/extensions/xep-0297.html)\n- 带`result` 元素， 其属性id是这条message的UID\n- delay元素 [XEP-0203: Delayed Delivery](https://xmpp.org/extensions/xep-0203.html) message被收到的时间, UTC时间戳格式\n\n\n```xml\nExample 16. Server returns two matching messages¶\n<message id='aeb213' to='juliet@capulet.lit/chamber'>\n  <result xmlns='urn:xmpp:mam:2' queryid='f27' id='28482-98726-73623'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:08:25Z'/>\n      <message xmlns='jabber:client'\n        to='juliet@capulet.lit/balcony'\n        from='romeo@montague.lit/orchard'\n        type='chat'>\n        <body>Call me but love, and I'll be new baptized; Henceforth I never will be Romeo.</body>\n      </message>\n    </forwarded>\n  </result>\n</message>\n\n<message id='aeb214' to='juliet@capulet.lit/chamber'>\n  <result xmlns='urn:xmpp:mam:2' queryid='f27' id='5d398-28273-f7382'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:09:32Z'/>\n      <message xmlns='jabber:client'\n         to='romeo@montague.lit/orchard'\n         from='juliet@capulet.lit/balcony'\n         type='chat' id='8a54s'>\n        <body>What man art thou that thus bescreen'd in night so stumblest on my counsel?</body>\n      </message>\n    </forwarded>\n  </result>\n</message>\n    \n```\n\n## MUC Archive\n\n- 存储所有发送给roomJid的message\n- 不包含`private message`\n- user需要权限查询群历史聊天记录\n- `forward` stanza中带有`to`属性,值是roomJid，`from`值是userJid \n- `x`里有该消息的发送者Jid\n```xml\nExample 17. Server returns MUC messages¶\n<message id='iasd207' from='coven@chat.shakespeare.lit' to='hag66@shakespeare.lit/pda'>\n  <result xmlns='urn:xmpp:mam:2' queryid='g27' id='34482-21985-73620'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2002-10-13T23:58:37Z'/>\n      <message xmlns=\"jabber:client\"\n        from='coven@chat.shakespeare.lit/firstwitch'\n        id='162BEBB1-F6DB-4D9A-9BD8-CFDCC801A0B2'\n        type='groupchat'>\n        <body>Thrice the brinded cat hath mew'd.</body>\n        <x xmlns='http://jabber.org/protocol/muc#user'>\n          <item affiliation='none'\n                jid='witch1@shakespeare.lit'\n                role='participant' />\n        </x>\n      </message>\n    </forwarded>\n  </result>\n</message>\n\n<message id='iasd207' from='coven@chat.shakespeare.lit' to='hag66@shakespeare.lit/pda'>\n  <result xmlns='urn:xmpp:mam:2' queryid='g27' id='34482-21985-73620'>\n    <forwarded xmlns='urn:xmpp:forward:0'>\n      <delay xmlns='urn:xmpp:delay' stamp='2002-10-13T23:58:43Z'/>\n      <message xmlns=\"jabber:client\"\n        from='coven@chat.shakespeare.lit/secondwitch'\n        id='90057840-30FD-4141-AA44-103EEDF218FC'\n        type='groupchat'>\n        <body>Thrice and once the hedge-pig whined.</body>\n        <x xmlns='http://jabber.org/protocol/muc#user'>\n          <item affiliation='none'\n                jid='witch2@shakespeare.lit'\n                role='participant' />\n        </x>\n      </message>\n    </forwarded>\n  </result>\n</message>\n```\n[XEP-0313: Message Archive Management](https://xmpp.org/extensions/xep-0313.html#intro)","categories":["XMPP"]},{"title":"XMPP(5): 消息","url":"/2019/04/09/XMPP-5-消息/","content":"\n \n## Message消息体构造\n\n属性： \n1. to ：接收方地址， JID \n2. from ： 发送方， JID\n3. type \n  - chat: 一对一聊天\n  - error: 出错\n  - groupchat: 群聊\n  - headline: 通知、临时消息这种不需要回复的系统消息\n  - normal: 之前没有聊天的记录， 客户端可以回复的消息\n\n子元素\n1. body: 消息内容\n\n```xml\n<message\n    from='juliet@example.com/balcony'\n    id='b4vs9km4'\n    to='romeo@example.net'\n    type='chat'\n    xml:lang='en'>\n  <body>Wherefore art thou, Romeo?</body>\n</message>\n\n```\n2. Subject: 聊天的话题\n\n```xml\n\n<message\n    from='juliet@example.com/balcony'\n    id='c8xg3nf8'\n    to='romeo@example.net'\n    type='chat'\n    xml:lang='en'>\n  <subject>I implore you!</subject>\n  <body>Wherefore art thou, Romeo?</body>\n</message>\n```\n\n3. Thread: 聊天会话的唯一标识\n\n## Example \n\n对话： \n\n```xml\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net'\n        type='chat'\n        xml:lang='en'>\n      <body>My ears have not yet drunk a hundred words</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net'\n        type='chat'\n        xml:lang='en'>\n      <body>Of that tongue's utterance, yet I know the sound:</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net'\n        type='chat'\n        xml:lang='en'>\n      <body>Art thou not Romeo, and a Montague?</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nUC: <message\n        from='romeo@example.net/orchard'\n        to='juliet@example.com/balcony'\n        type='chat'\n        xml:lang='en'>\n      <body>Neither, fair saint, if either thee dislike.</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\nCC: <message\n        from='juliet@example.com/balcony'\n        to='romeo@example.net/orchard'\n        type='chat'\n        xml:lang='en'>\n      <body>How cam'st thou hither, tell me, and wherefore?</body>\n      <thread>e0ffe42b28561960c6b12b944a092794b9683a38</thread>\n    </message>\n\n```\n\n在[xmpp.js](https://github.com/xmppjs/xmpp.js/)中，客户端与服务端建立了WebSocket长链接后，发消息，需要自己构造消息体\n\n``` js \nconst {client, xml} = require('@xmpp/client')\n\nconst xmpp = client({\n  service: 'ws://localhost:5280/xmpp-websocket',\n  domain: 'localhost',\n  resource: 'example',\n  username: 'username',\n  password: 'password',\n})\n\n const message = xml(\n    'message',\n    {type: 'chat', to: address},\n    xml('body', 'hello world')\n  )\n  await xmpp.send(message)\n\n```\n\n如果收到消息会走到一个回调里, chat-sdk就可以根据type字段来分发。\n\n\n```js \nself.xmppClient.on('stanza', function (stanza: any) {\n    Utils.DLog('[Chat] RECV:', stanza.toString());\n    /**\n     * Detect typeof incoming stanza\n     * and fire the Listener\n     */\n    if (stanza.is('presence')) {\n        self._onPresence(stanza);\n    } else if (stanza.is('iq')) {\n        self._onIQ(stanza);\n    } else if (stanza.is('message')) {\n        if (stanza.attrs.type === 'headline') {\n            self._onSystemMessageListener(stanza);\n        } else if (stanza.attrs.type === 'error') {\n            self._onMessageErrorListener(stanza);\n        } else {\n            self._onMessage(stanza);\n        }\n    }\n});\n```\n\n- ref: https://xmpp.org/rfcs/rfc6121.html#message","categories":["XMPP"]},{"title":"JWT 入门","url":"/2019/04/03/JWT-入门/","content":"\n\n## 什么是JSON Web Tokens (JWT)？ \n\n\n```\n  JSON Web Token (JWT) is a compact, URL-safe means of representing\n   claims to be transferred between two parties.  The claims in a JWT\n   are encoded as a JSON object that is used as the payload of a JSON\n   Web Signature (JWS) structure or as the plaintext of a JSON Web\n   Encryption (JWE) structure, enabling the claims to be digitally\n   signed or integrity protected with a Message Authentication Code\n   (MAC) and/or encrypted.\n   \n\n```\n\n## 怎么用？ \n\nauthentication时，当user成功登录，server生成access token, 发送给user；user请求server时带上JWT，server通过JWT验证是否是可信任的客户端请求了。\n\n\n![1*SSXUQJ1dWjiUrDoKaaiGLA.png](https://cdn-images-1.medium.com/max/1600/1*SSXUQJ1dWjiUrDoKaaiGLA.png)\n\n## 结构\n\n在客户端看来JWT是一串encode加密过的字符串,`header.payload.signature`，如下图左边。但它decode后其实是下图右边的JSON结构体\n\n![legacy-app-auth-5.png](https://cdn.auth0.com/blog/legacy-app-auth/legacy-app-auth-5.png)\n\n#### 1. 生成header\n\ne.g.\n```json\n{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}\n```\n\n这里，alg的值指定用HMAC-SHA256算法签名\n\n#### 2. 生成payload\n\n包含用户相关的信息\n```\nThe second part of the token is the payload, which contains the claims. \nClaims are statements about an entity (typically, the user) and additional data. \n```\n有三种[claims](https://tools.ietf.org/html/rfc7519#section-4.1): registered, public, and private claims.\n\ne.g.\n```json\n\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"iat\": 1516239022\n}\n```\n\n#### 3.生成signature\n\n```js\n\nHMACSHA256(\n  base64UrlEncode(header) + \".\" +\n  base64UrlEncode(payload),\n  your-256-bit-secret\n) \n```\n把header跟payload encode结构后，用'.'连接，生成: <span style=\"color:#fb015b\"> eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span><span>.</span>\n<span style=\"color:#d63aff\"> eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ</span>\n\n再用指定的hash算法(例子是HS256),用私钥（服务端的）生成签名:<span style=\"color:#00b9f1\">SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c<span>\n\n\n## 验证\n\n如图1， JWT由Authentication server生成， 在client认证后发给client； client请求application server的时候带上JWT，application server在认证阶段从Authentiation server那儿拿到scret key；用同样算法生成signature， 跟client发来的JWT的signature做比较，看是否match。\n\n\n\n\n\n\n\n\n\n\n\n\n[5 Easy Steps to Understanding JSON Web Tokens (JWT)](https://medium.com/vandium-software/5-easy-steps-to-understanding-json-web-tokens-jwt-1164c0adfcec)\n[JSON Web Token Introduction - jwt.io](https://jwt.io/introduction/) \n[RFC 7519 - JSON Web Token (JWT)](https://tools.ietf.org/html/rfc7519)","tags":["Auth"],"categories":["Network"]},{"title":"XMPP(4):Search 和 vCard","url":"/2019/03/31/XMPP-4-Search-vCard/","content":"`jabber:iq:search`协议用来查找用户信息。\n\n1. 我们先查询可以用哪些字段查找用户\n<!-- more -->\n\n# XMPP Search \n\n`jabber:iq:search`协议用来查找用户信息。\n\n1. 我们先查询可以用哪些字段查找用户\n\n```xml\n// Requesting Search Fields\n\n<iq type='get'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\n2. service 返回\n\n```xml\n// Receiving Search Fields\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <instructions>\n      Fill in one or more fields to search\n      for any matching Jabber users.\n    </instructions>\n    <first/>\n    <last/>\n    <nick/>\n    <email/>\n  </query>\n</iq>\n```\n3. 服务端返回，可以用`first` `last` `nick` `email` 这几个字段找人。接着就用last查人.\n\n```xml\n// Submitting a Search Request\n\n<iq type='set'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <last>Capulet</last>\n  </query>\n</iq>\n```\n\n服务端可以能会返回好多个last匹配的item\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <item jid='juliet@capulet.com'>\n      <first>Juliet</first>\n      <last>Capulet</last>\n      <nick>JuliC</nick>\n      <email>juliet@shakespeare.lit</email>\n    </item>\n    <item jid='tybalt@shakespeare.lit'>\n      <first>Tybalt</first>\n      <last>Capulet</last>\n      <nick>ty</nick>\n      <email>tybalt@shakespeare.lit</email>\n    </item>\n  </query>\n</iq>\n```\n没有结果的话，query就没有子元素\n\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\nXMPP Search \n\n`jabber:iq:search`协议用来查找用户信息。\n\n我们先查询可以用哪些字段查找用户\n\n```xml\n// Requesting Search Fields\n\n<iq type='get'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\nservice 返回\n\n```xml\n// Receiving Search Fields\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search1'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <instructions>\n      Fill in one or more fields to search\n      for any matching Jabber users.\n    </instructions>\n    <first/>\n    <last/>\n    <nick/>\n    <email/>\n  </query>\n</iq>\n```\n服务端返回，可以用`first` `last` `nick` `email` 这几个字段找人。接着就用last查人.\n\n```xml\n// Submitting a Search Request\n\n<iq type='set'\n    from='romeo@montague.net/home'\n    to='characters.shakespeare.lit'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <last>Capulet</last>\n  </query>\n</iq>\n```\n\n服务端可以能会返回好多个last匹配的item\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'>\n    <item jid='juliet@capulet.com'>\n      <first>Juliet</first>\n      <last>Capulet</last>\n      <nick>JuliC</nick>\n      <email>juliet@shakespeare.lit</email>\n    </item>\n    <item jid='tybalt@shakespeare.lit'>\n      <first>Tybalt</first>\n      <last>Capulet</last>\n      <nick>ty</nick>\n      <email>tybalt@shakespeare.lit</email>\n    </item>\n  </query>\n</iq>\n```\n没有结果的话，query就没有子元素\n\n```xml\n<iq type='result'\n    from='characters.shakespeare.lit'\n    to='romeo@montague.net/home'\n    id='search2'\n    xml:lang='en'>\n  <query xmlns='jabber:iq:search'/>\n</iq>\n```\n\n# vCard \nvCard协议主要负责用户信息存储，就像个人名片。\n\n1. 查看自己的vCard\n如果客户端想查询自己的vCard, 需要发送IQ-set stanza，注意没有to地址哦。\n\n```xml\n<iq from='stpeter@jabber.org/roundabout'\n    id='v1'\n    type='get'>\n  <vCard xmlns='vcard-temp'/>\n</iq>\n```\n\n2. 返回信息\n接着服务端返回一堆的用户信息\n\n```xml\n\n<iq id='v1'\n    to='stpeter@jabber.org/roundabout'\n    type='result'>\n  <vCard xmlns='vcard-temp'>\n    <FN>Peter Saint-Andre</FN>\n    <N>\n      <FAMILY>Saint-Andre</FAMILY>\n      <GIVEN>Peter</GIVEN>\n      <MIDDLE/>\n    </N>\n    <NICKNAME>stpeter</NICKNAME>\n    <URL>http://www.xmpp.org/xsf/people/stpeter.shtml</URL>\n    <BDAY>1966-08-06</BDAY>\n    <ORG>\n      <ORGNAME>XMPP Standards Foundation</ORGNAME>\n      <ORGUNIT/>\n    </ORG>\n    <TITLE>Executive Director</TITLE>\n    <ROLE>Patron Saint</ROLE>\n    <TEL><WORK/><VOICE/><NUMBER>303-308-3282</NUMBER></TEL>\n    <TEL><WORK/><FAX/><NUMBER/></TEL>\n    <TEL><WORK/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <WORK/>\n      <EXTADD>Suite 600</EXTADD>\n      <STREET>1899 Wynkoop Street</STREET>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80202</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <TEL><HOME/><VOICE/><NUMBER>303-555-1212</NUMBER></TEL>\n    <TEL><HOME/><FAX/><NUMBER/></TEL>\n    <TEL><HOME/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <HOME/>\n      <EXTADD/>\n      <STREET/>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80209</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <EMAIL><INTERNET/><PREF/><USERID>stpeter@jabber.org</USERID></EMAIL>\n    <JABBERID>stpeter@jabber.org</JABBERID>\n    <DESC>\n      More information about me is located on my\n      personal website: http://www.saint-andre.com/\n    </DESC>\n  </vCard>\n</iq>\n```\n如果没有相关vCard，会返回error\n```xml\n// item-not-found\n<iq id='v1'\n    to='stpeter@jabber.org/roundabout'\n    type='error'>\n  <vCard xmlns='vcard-temp'/>\n  <error type='cancel'>\n    <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n```xml\n// empty element\n<iq id='v1'\n    to='stpeter@jabber.org/roundabout'\n    type='result'>\n  <vCard xmlns='vcard-temp'/>\n</iq>\n\n```\n\n3. 查看别人的vCard\n\n用IQ-get stanza, 带上to地址\n\n```xml \n\n<iq from='stpeter@jabber.org/roundabout'\n    id='v3'\n    to='jer@jabber.org'\n    type='get'>\n  <vCard xmlns='vcard-temp'/>\n</iq>\n```\n\n```xml\n<iq from='jer@jabber.org'\n    to='stpeter@jabber.org/roundabout'\n    type='result'\n    id='v3'>\n  <vCard xmlns='vcard-temp'>\n    <FN>JeremieMiller</FN>\n    <N>\n      <GIVEN>Jeremie</GIVEN>\n      <FAMILY>Miller</FAMILY>\n      <MIDDLE/>\n    </N>\n    <NICKNAME>jer</NICKNAME>\n    <EMAIL><INTERNET/><PREF/><USERID>jeremie@jabber.org</USERID></EMAIL>\n    <JABBERID>jer@jabber.org</JABBERID>\n  </vCard>\n</iq>\n\n```\n\n4. 更新vCard\n\n客户端可以用IQ-set stanza 更新自己的vCard信息\n\n```xml\n<iq id='v2' type='set'>\n  <vCard xmlns='vcard-temp'>\n    <FN>Peter Saint-Andre</FN>\n    <N>\n      <FAMILY>Saint-Andre</FAMILY>\n      <GIVEN>Peter</GIVEN>\n      <MIDDLE/>\n    </N>\n    <NICKNAME>stpeter</NICKNAME>\n    <URL>http://www.xmpp.org/xsf/people/stpeter.shtml</URL>\n    <BDAY>1966-08-06</BDAY>\n    <ORG>\n      <ORGNAME>XMPP Standards Foundation</ORGNAME>\n      <ORGUNIT/>\n    </ORG>\n    <TITLE>Executive Director</TITLE>\n    <ROLE>Patron Saint</ROLE>\n    <TEL><WORK/><VOICE/><NUMBER>303-308-3282</NUMBER></TEL>\n    <TEL><WORK/><FAX/><NUMBER/></TEL>\n    <TEL><WORK/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <WORK/>\n      <EXTADD>Suite 600</EXTADD>\n      <STREET>1899 Wynkoop Street</STREET>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80202</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <TEL><HOME/><VOICE/><NUMBER>303-555-1212</NUMBER></TEL>\n    <TEL><HOME/><FAX/><NUMBER/></TEL>\n    <TEL><HOME/><MSG/><NUMBER/></TEL>\n    <ADR>\n      <HOME/>\n      <EXTADD/>\n      <STREET/>\n      <LOCALITY>Denver</LOCALITY>\n      <REGION>CO</REGION>\n      <PCODE>80209</PCODE>\n      <CTRY>USA</CTRY>\n    </ADR>\n    <EMAIL><INTERNET/><PREF/><USERID>stpeter@jabber.org</USERID></EMAIL>\n    <JABBERID>stpeter@jabber.org</JABBERID>\n    <DESC>\n      Check out my blog at https://stpeter.im/\n    </DESC>\n  </vCard>\n</iq>\n```\n\n服务端返回结果\n\n```xml\n<iq id='v2'\n    to='stpeter@jabber.org/roundabout'\n    type='result'/>\n```\n\nref: https://xmpp.org/extensions/xep-0054.html#intro\nref: https://xmpp.org/extensions/xep-0055.html#intro","categories":["XMPP"]},{"title":"影响曝光的3个因素","url":"/2019/03/31/影响曝光的几个因素/","content":"\n\n\n## 进光量\n\n`曝光`也指单位面积上光子的数量。\n\n- 如果我们没有捕获足够的光，那么相片就会`欠曝`:\n\n<img src=\"/img/15000130641224/15000133443588.jpg\" width = \"368\" height = \"500\" alt=\"图片名称\" align=center />\n\n\n- 如果我们捕获的光太多，图像就会`过曝`:\n\n<img src=\"/img/15000130641224/15000133832576.jpg\" width = \"368\" height = \"500\" alt=\"图片名称\" align=center />\n\n\n\n## 三个要素可以影响曝光的进光量\n\n- 快门速度\n- 光圈\n- 感光度 (ISO)\n\n![](/img/15000130641224/15006272782478.jpg)\n\n想象相机是黑暗房间，有个窗户（光圈）， 有块窗帘（快门），窗户越大进光量越大，窗帘拉开的时间越久。 窗户对面有面镜子（感官元件），捕获光子成像。\n\n## 1.快门速度\n当我们捕捉图片时，图像传感器需要捕捉一段时间的光。 这个时间段曝光时间（也叫快门速度。相机中一般用`1/400、8`这样的形式表示）这个数值越大，快门开启的时间越长，进入相机的光线就越多，但运动的物体很可能模糊.\n\n看下图： \n\n![](/img/15000130641224/15006271573170.jpg)\n\n\n## 2.感光度 (ISO)\n\n它被用来衡量图像传感器对光的`灵敏程度`，以及因此带来的曝光噪音。ISO越大，传感器越灵敏，捕获光能力越强，照片越亮，但噪点也越多。\n\n![](/img/15000130641224/15006272197963.jpg)\n\n####左： ISO 32 和 1/3 秒曝光\n####右： ISO 1600 和 1/180 秒\n![](/img/15000130641224/15000247388896.jpg)\n\n\n**图像传感器**\n这个部分就相当于我们眼睛里的视网膜。图像传感器可以将光或者光子转换为电信号。\n\n**图像传感器是由海量的独个的像素传感器串起来的巨大矩形区域** 我们可以将每个像素传感器想象成一个装电荷的桶。当光子撞击到像素传感器的光二极管时，它们将在这个像素的桶中缓慢地积攒电荷。最后，每个像素都会有它自己的一小桶电子。这些电荷的数量是依赖于光子数量的 -- 或者说是决定于打到这个特定的点上的光的强度。\n\n因为我们有一个像素传感器的二维阵列，我们现在就拥有能够反应出所有这些位置的光的强度的一组二维电荷阵列了。**在 iPhone 6 上，我们有八百万个这样的微小的像素传感器**，以及它们所对应的电荷桶。\n\n\n## 3.光圈\n\n相机的镜头的光圈(Aperture)是用来衡量到达图像感应器的光所通过的`通孔的大小`的\n\n\n#### 曝光值\n\n曝光值（Exposure Value，EV）代表能够给出同样曝光的所有相机光圈快门组合\n\n![](/img/15000130641224/15026013567638.jpg)\n其中N是光圈（f值）；t是曝光时间（快门），单位秒。曝光值0（EV0）对应于曝光时间为1秒而光圈为f/1.0的组合或其等效组合。\n\n`曝光值 != 曝光量`\n\n####曝光量（photometric exposure）\n\n![](/img/15000130641224/15026015278605.jpg)\n其中  H是曝光量， E是影像平面的照度，而  t是曝光时间。照度 E由f值所控制，但也取决于环境亮度。\n\n## 光圈与景深\n\n##### 景深\n\n![](/img/15000130641224/15026018990936.jpg)\n\n![](/img/15000130641224/15026016717518.jpg)\n\n![](/img/15000130641224/15026016975426.jpg)\n\n光圈系数= `镜头焦距/光圈孔径`；常用的镜头的光圈数序列为\n`1， 1.4， 2， 2.8， 4， 5.6， 8， 11， 16， 22， 32， 45， 64，90，128`\n\n\n\n\n","tags":["CV"]},{"title":"XMPP(3):Roster&联系人","url":"/2019/03/31/Roster-联系人/","content":"\n\n\n\nXMPP中联系人模块协议是`jabber:iq:roster`. Roster直接翻译叫花名册，其实它就是联系人列表啦。\n\n## 客户端获取联系人列表\n\n比较简单，发送IQ stanza给server. xmlns=`jabber:iq:roster`;type='get'\n\n```xml\n\n<iq from='user@server.com/balcony'\n       id='bv1bs71f'\n       type='get'>\n    <query xmlns='jabber:iq:roster'/>\n  </iq>\n\n```\n返回结果的item中有联系人Jid\n\n```xml\n<iq id='bv1bs71f'\n       to='user@server.com/balcony'\n       type='result'>\n    <query xmlns='jabber:iq:roster' ver='ver7'>\n      <item jid='contact1@server.com'/>\n      <item jid='contact2@server.com'/>\n    </query>\n  </iq>\n\n```\n\n## 添加联系人(加好友）的流程 \n\n方法有两种，第一种用IQ set, 见[rfc6121](https://xmpp.org/rfcs/rfc6121.html#roster-add).\n\n1. 客户端请求添加联系人\n\nxmlns用`jabber:iq:roster`; 带上想添加的用户jid. name可以不带; `group`分组用。\n\n\n```xml\n<iq from='user@server.com/balcony' type='set' id='roster_2'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n```\n\n2.1. server通知同一个账户关联的所有客户端: 联系人列表更新了。\n\n```xml\n\n<iq to='user@server.com/balcony'\n    type='set'\n    id='a78b4q6ha463'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'\n          subscription='none'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n\n<iq to='user@server.com/chamber'\n    type='set'\n    id='a78b4q6ha464'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'\n          subscription='none'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n```\n\nserver回复IQ stanza给请求添加联系人的客户端balcony\n```xml\n<iq to='user@server.com/balcony' type='result' id='roster_2'/>\n```\n\n\n##  删除联系人\n\n给server发送个IQ set， subscription一定是'remove'.\n\n```xml\n\n<iq from='user@server.com/balcony' type='set' id='roster_4'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com' subscription='remove'/>\n  </query>\n</iq>\n\n```\n\n## Presence\n\n增删联系人的另一种方法是Presence订阅机制.Presence stanza其实有两种功能：\n- 广播online/offline状态, [之前文章](https://suelan.github.io/2019/03/26/XMPP-Overview/#The-Presence-Stanza)提过\n- 控制联系人订阅. 就是增删好友功能咯\n\n我们用type来区分这两种功能。type是`available| unavailable`， presence stanza表达online/offline状态。type若是`subscribe | subscribed | unsubscribe| unsubscribed`，就跟联系人有关啦。\n\n\nsubscribtion有四种状态：\n- NONE :  \n- TO  :  user订阅contact的状态\n- FROM : contact被user订阅\n- BOTH : user跟contact相互subcribe\n\n![flow](https://www.blikoontech.com/wp-content/uploads/2018/03/XMPP_Subscription_Flow.png)\n\n如上图：一开始user跟contact没啥关系，subscription状态都是none。 接着user发送了一条Presence stanza给contact，想subscribe他的状态。如下：\n```xml\n// from user\n<presence to='contact@server.com' type='subscribe'/>\n```\n现在user用`jabber:iq:roster` 查询所有联系人的时候，会发现item多了一条, contact还没确认, 所以 ask='subscribe', subscribtion='none'\n\n```xml\n// user's roster\n<item ask='subscribe' subscription='none' jid='contact@server.com'/>\n```\nserver要将消息转发给contact客户端, contact登录时，会收到一条来自user的presence stanza; type是'subscribe'。 我们可以用这条消息来做“收到来自user添加好友的请求”这样的功能\n```xml\n<presence from='user@server.com' to='contact@server.com' type='subscribe' xmlns='jabber:client'></presence>\n```\n\n同时contact/dev设备会收到Roster更新的信息. \n```xml\n<iq  from='contact@server.com' to='contact@server.com/dev' id='13a99ca5' type='result' xmlns='jabber:client'>\n    <query  xmlns='jabber:iq:roster'>\n         <item  ask='subscribe' subscription='none' jid='user@server.com'/>\n       </query>\n</iq>\n```\n#### 接受请求\n如果contact接受请求，他要发送一条presence给user. type值是'subscribed'\n\n```xml\n<presence to='user@server.com' type='subscribed'/>\n```\n\nuser这边的roster会更新\n```xml\n// user's roster\n<item subscription='to' jid='contact@server.com'/>\n```\n这时在contact的roster列表里，user的subscription是from。 ```xml\n// contact's roster\n<item ask='subscribe' subscription='from' jid='user@server.com'/>\n```\n\n接着contact也请求订阅user \n\n```xml\n<iq from='user@server.com/balcony' type='set' id='roster_2'>\n  <query xmlns='jabber:iq:roster'>\n    <item jid='contact@server.com'\n          name='contact'>\n      <group>Servants</group>\n    </item>\n  </query>\n</iq>\n```\n\nContact同样流程后，他两的subscription都变成了both。\n\n#### 拒绝\n如果contact想拒绝user的请求，也是发送presence \n```xml\n<presence to='user@server.com' type='unsubscribed'/>\n```\n如果user想取消对contact的订阅, 发送presence stanza，type 是unsubscribed\n```xml\n<presence to='contact@server.com' type='unsubscribed'/>\n```\n\n\nref: https://xmpp.org/rfcs/rfc3921.html#roster","categories":["XMPP"]},{"title":"XMPP(2):注册账户","url":"/2019/03/29/XMPP-2-注册账户/","content":"\n\n\n## XMPP注册流程\n\n\n#### 1. client发送消息体, 去服务端查询注册需要的字段\n\n\n```xml\n<iq type='get' id='reg1' to='localhost'>\n  <query xmlns='jabber:iq:register'/>\n</iq>\n```\n\nxmlns是 `jabber:iq:register`, type是`get`\n\n#### 2.1. 未注册：返回注册需要的字段\n\n```xml\n<iq type='result' id='reg1'>\n  <query xmlns='jabber:iq:register'>\n    <instructions>\n      Choose a username and password for use with this service.\n      Please also provide your email address.\n    </instructions>\n    <username/>\n    <password/>\n    <email/>\n  </query>\n</iq>\n```\n\n`<instructions/>` element：SHOULD contain an <instructions/> element (whose XML character data MAY be modified to reflect the fact that the entity is currently registered)\n\n#### 2.2. 已注册：服务端的返回结果\n\n```xml\n<iq  xmlns='jabber:client' xml:lang='en' to='olivia@localhost/180244803852118156522754' from='localhost' type='result' id='reg1'>\n    <query  xmlns='jabber:iq:register'>\n        <username>olivia</username>\n        <registered/>\n        <password/>\n        <instructions>Choose a username and password to register with this server</instructions>\n    </query>\n</iq>\n```\n\nhost会根据\"from\"的地址判断entity是否已经注册了，IQ result消息有一个空的`<registered/>`， 标示该entiry已经注册过了。\n\n#### 3.client 注册 \n\niq stanza的type是`set`, xmlns`jabber:iq:register`\n\n```xml\n<iq type='set' id='reg2'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>Calliope</password>\n    <email>bard@shakespeare.lit</email>\n  </query>\n</iq>\n```\n\n#### 4.1 注册成功 \n\n```xml\n<iq type='result' id='reg2'/>\n\n```\n\n#### 4.2 注册失败，命名冲突\n\n```xml\n<iq type='error' id='reg2'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>m1cro$oft</password>\n    <email>billg@bigcompany.com</email>\n  </query>\n  <error code='409' type='cancel'>\n    <conflict xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n#### 4.3 消息不全 ` <not-acceptable/> `\n\n```xml\n<iq type='error' id='reg2'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>Calliope</password>\n  </query>\n  <error code='406' type='modify'>\n    <not-acceptable xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n#### 4.4 服务端访问权限问题\n\n```xml\n<iq  xmlns='jabber:client' xml:lang='en' to='olivia@localhost/180244803852118156522754' from='olivia@localhost' type='error' id='reg2'>\n    <query  xmlns='jabber:iq:register'>\n        <email>bard@shakespeare.lit</email>\n        <username>bill</username>\n        <password>Calliope</password>\n    </query>\n    <error  code='403' type='auth'>\n        <forbidden  xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n        <text  xmlns='urn:ietf:params:xml:ns:xmpp-stanzas' xml:lang='en'>Access denied by service policy</text>\n    </error>\n</iq>\n```\n\n#### 5.如果用第三方注册的方式，可能需要补充一些额外的信息\n\n客户端查询\n\n```xml\n<iq type='get'\n    from='juliet@capulet.com/balcony'\n    to='contests.shakespeare.lit'\n    id='reg3'>\n  <query xmlns='jabber:iq:register'/>\n</iq>\n```\n\n#### 6.服务端返回消息， 提示需要提供的信息\n\n```xml\n<iq type='result'\n    from='contests.shakespeare.lit'\n    to='juliet@capulet.com/balcony'\n    id='reg3'>\n  <query xmlns='jabber:iq:register'>\n    <instructions>\n      Use the enclosed form to register. If your Jabber client does not\n      support Data Forms, visit http://www.shakespeare.lit/contests.php\n    </instructions>\n    <x xmlns='jabber:x:data' type='form'>\n      <title>Contest Registration</title>\n      <instructions>\n        Please provide the following information\n        to sign up for our special contests!\n      </instructions>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register</value>\n      </field>\n      <field type='text-single' label='Given Name' var='first'>\n        <required/>\n      </field>\n      <field type='text-single' label='Family Name' var='last'>\n        <required/>\n      </field>\n      <field type='text-single' label='Email Address' var='email'>\n        <required/>\n      </field>\n      <field type='list-single' label='Gender' var='x-gender'>\n        <option label='Male'><value>M</value></option>\n        <option label='Female'><value>F</value></option>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\n#### 7.客户端提供信息\n\n```xml\n<iq type='set'\n    from='juliet@capulet.com/balcony'\n    to='contests.shakespeare.lit'\n    id='reg4'>\n  <query xmlns='jabber:iq:register'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register</value>\n      </field>\n      <field type='text-single' label='Given Name' var='first'>\n        <value>Juliet</value>\n      </field>\n      <field type='text-single' label='Family Name' var='last'>\n        <value>Capulet</value>\n      </field>\n      <field type='text-single' label='Email Address' var='email'>\n        <value>juliet@capulet.com</value>\n      </field>\n      <field type='list-single' label='Gender' var='x-gender'>\n        <value>F</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\n## Cancellation of Existing Registration\n\n#### 1. cilent req: \n```xml\n<iq type='set' from='bill@shakespeare.lit/globe' id='unreg1'>\n  <query xmlns='jabber:iq:register'>\n    <remove/>\n  </query>\n</iq>\n```\n跟注册不同的是 `query` 的child多了个`<remove/>`\n\n#### 2.1. 成功注销,server response: \n  \n```xml\n\n<iq type='result' to='bill@shakespeare.lit/globe' id='unreg1'/>\n\n```\n\n#### 2.2.Error Case  \n\n|Condition | Description  |\n| --- | --- |\n| ``<bad-request/>``|\tThe <remove/> element was not the only child element of the <query/> element.|\n|``<forbidden/>``\t| 权限不够|\n|``<not-allowed/>``\t|不允许用户注销账户|\n|``<registration-required/>``|要注销的账户本来就不存在|\n|``<unexpected-request/>``\t| The host is an instant messaging server and the IQ get does not contain a 'from' address because the entity is not registered with the server.|\n\n## 用户修改密码\n\n#### 1. Client:\n```xml\n<iq type='set' to='shakespeare.lit' id='change1'>\n  <query xmlns='jabber:iq:register'>\n    <username>bill</username>\n    <password>newpass</password>\n  </query>\n</iq>\n\n```\n\n这里的密码是明文， 要留意客户端服务端通信是否用SSL或者TLS加密，而且服务端证书可信。\n\n#### 2.1. 成功, Server: \n\n```xml\n<iq type='result' id='change1'/>\n\n```\n\n\n#### 2.2. 失败 Case \n\n\n|Condition | Description  |\n| --- | --- |\n| ``<bad-request/>``| request请求体拼写有问题，比如没带username |\n|``<not-authorized/>`` | 没通过server的安全验证 |\n|``<not-allowed/>`` |\tserver 不允许|\n|``<unexpected-request/>`` | The host is an instant messaging server and the IQ set does not contain a 'from' address because the entity is not registered with the server. |\n\n比如：\n```xml\n// Bad  request\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <error code='400' type='modify'>\n    <bad-request xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n\n// Not Authorized\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <error code='401' type='modify'>\n    <not-authorized xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n\n// Not Allowed\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <error code='405' type='cancel'>\n    <not-allowed xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n```\n\n有时候，服务端需要更多的信息来改密码，这时候它会返回信息提示客户端\n\n```xml\n<iq type='error' from='shakespeare.lit' to='bill@shakespeare.lit/globe' id='change1'>\n  <query xmlns='jabber:iq:register'>\n    <x xmlns='jabber:x:data' type='form'>\n      <title>Password Change</title>\n      <instructions>Use this form to change your password.</instructions>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register:changepassword</value>\n      </field>\n      <field type='text-single' label='Username' var='username'>\n        <required/>\n      </field>\n      <field type='text-private' label='Old Password' var='old_password'>\n        <required/>\n      </field>\n      <field type='text-private' label='New Password' var='password'>\n        <required/>\n      </field>\n      <field type='text-single' label='Mother&apos;s Maiden Name' var='x-mmn'>\n        <required/>\n      </field>\n    </x>\n  </query>\n  <error code='401' type='modify'>\n    <not-authorized xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/>\n  </error>\n</iq>\n\n```\n\n然后客户端返回相关信息\n\n```xml\n<iq type='set' from='bill@shakespeare.lit/globe' to='shakespeare.lit' id='change2'>\n  <query xmlns='jabber:iq:register'>\n    <x xmlns='jabber:x:data' type='submit'>\n      <field type='hidden' var='FORM_TYPE'>\n        <value>jabber:iq:register:changepassword</value>\n      </field>\n      <field type='text-single' var='username'>\n        <value>bill@shakespeare.lit</value>\n      </field>\n      <field type='text-private' var='old_password'>\n        <value>theglobe</value>\n      </field>\n      <field type='text-private' var='password'>\n        <value>groundlings</value>\n      </field>\n      <field type='text-single' var='x-mmn'>\n        <value>Throckmorton</value>\n      </field>\n    </x>\n  </query>\n</iq>\n```\n\nref: [XEP-0077: In-Band Registration](https://xmpp.org/extensions/xep-0077.html#usecases)\n","categories":["XMPP"]},{"title":"XMPP Overview","url":"/2019/03/26/XMPP-Overview/","content":"\n\n\n跟朋友做一个项目，想快速开发，选了XMPP协议。它是一套通信协议。分为两部分，[XMPP Core Services](https://xmpp.org/rfcs/rfc6121.html#A%20Sample%20Session) 和 XMPP Extension Protocols. 核心由基础feature组成，扩展协议就非常丰富，而且一直在发展。Wiki上有张各种IM协议的汇总表，推荐！\n\n- [Comparison of instant messaging protocols - Wikipedia](https://en.wikipedia.org/wiki/Comparison_of_instant_messaging_protocols)\n\n\n## XMPP Addressing \n\n这是一张Client-Server的图，图里的server、client都遵循XMPP协议。叫 XMPP entity. 它们有各自唯一的Address, 格式如'username@server.com', 叫 JID (Jaber ID)\n [RFC 7622 - Extensible Messaging and Presence Protocol (XMPP): Address Format](https://datatracker.ietf.org/doc/rfc7622/)\n \n ![28a215f7.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/28a215f7.png)\n \n其中resource是拿来做同一账号多客户端标记的， 比如图中`User1` 从 pc ,phone1 和 phone2登录同一账号，resource分别是 `pc`, `iphone1`,`iphone2`\n \n \n ## XMPP Client- Server Streams\n \n 客户端与服务端通过长链接方式通信，现在多用WebSocket。当客户端跟服务端握手成功，它们开始用 XML stream通信。\n \n ![f1565a2e.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/f1565a2e.png)\\\n\n \nXML stream 总是以  ``<stream>`` 开头， ``</stream>`` tag结尾。是xml消息的容器。\n\n```\nAn XML stream is a container for the exchange of XML elements between any two entities over a network. \nDuring the life of the stream, the entity that initiated it can send an unbounded number of XML elements over the stream, either elements used to negotiate the stream (e.g., to complete TLS negotiation or SASL negotiation) or XML stanzas. \n```\n\n下面是client跟server的一次消息交互， 绿色来自client的，黑色消息来自server\n\n \n  ![f97e583b.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/65d38868.png)\n\n ### XML stanza\n An XML stanza is the basic unit of meaning in XMPP. A stanza is a first-level element (at depth=1 of the stream) whose element name is \"message\", \"presence\", or \"iq\" and whose qualifying namespace is 'jabber:client' or 'jabber:server'. \n \n \n ### XMPP Communication Primitives\n\nA `stanza` is the smallest piece of XML data a client can send to a server ( server send to client) in one package.\n\nxmpp中，服务端、客户数据交换时，最小XML数据单位 叫 stanza。如上图，绿色的就是一个stanza，黑色的也是一个stanza。Stanza有几种类型: `message`, `iq`, `presence`。 \n\n#### The Message Stanza\n\nThe <message/> stanza is meant to be used to send data between XMPP entities.\n\n![6fe8a15e.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/6fe8a15e.png)\n\n - from：发送方\n - to： 接收方\n - body: 消息内容\n - type 有几种类型:\n     -`<message type=”chat”/>` ( chat message stanza) \n     - `< message type=”groupchat”/>` ( groupchat message stanza)\n     - `< message type=”error”/>` (error message stanza)\n\n#### The Presence Stanza\n\n用来表示在线状态的\n \n\n![0fbe995b.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/0fbe995b.png)\n\n`show` 标签里可能会有的几种状态: \n`chat` : online and available for chat ; \n`away` : 暂时离开\n`xa` : 长时间离开\n`dnd`: 请勿打扰\n\n如果你想知道别的状态，需要先发消息给Server，subscribe别人。 \n\n\n#### The IQ stanza\n \n The IQ( Info/Query) stanza is used to get some information from the server ( info about the server or its registered clients) or to apply some settings to the server.\n \n 用来获取消息，或者请求设置\n  \nType属性中的类型 :get ,set ,result or error. \n- `< iq type=”get”/>` stanzas are used to get(ask) some information ( from the server). \n- `<iq type=”set”/>` stanzas are used to apply some settings to the server.When you send get/set IQ stanzas to the server ,\n- it can reply either with an `< iq type=”result”/>` stanza when your request has been successfully processed by the server or \n- `<iq type=”error”/>` stanza when something has gone wrong with your request.The figure below shows an IQ stanza that we send to the server and the reply we get from the server.\n\n\n![30c96f66.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/30c96f66.png)\n\n\nThe client sends an IQ get stanza to the server to request its contact list.We know it is asking for the contact list because of the `jabber:iq:roster` XML namespace.\n\nThe XMPP engine in the server is programmed to know that when a client sends `jabber:iq:roster` namespaced IQ ,it wants to retrieve its contact list.There are other `namespaces` in XMPP for other uses and you will surely come accross them in your XMPPing journey.\n\nThe server responds with a list of the JID’s contacts wraped within a `jabber:iq:roster` namespaced `<query/>`tag.\n\n\n## 本地搭建 Server \n\n我搭的是ejabberd. 官方安装教程: [Installing ejabberd \\| ejabberd Docs](https://docs.ejabberd.im/admin/installation/#install-on-macos)\n\n#### 启动服务\n\n```\ncd /Applications/ejabberd-19.02\n//开启服务\n./bin/ejabberdctl start  \n//状态\n./bin/ejabberdctl status  \n\n// help 查看更多功能哦\n./bin/ejabberdctl help \n```\n\n#### 注册账户\n\n打开 [admin 页面](http://localhost:5280/admin/), 虚拟主机 -> localhost(可能你的名字不一样) -> 用户。 现在你可以自己创建账户了。\n\n![578b88b6.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/578b88b6.png)\n\n\n如果有自定义需求,配置教程 [Configuring ejabberd \\| ejabberd Docs](https://docs.ejabberd.im/admin/configuration/#mod-http-ws) \n \n#### 客户端玩起来\n\n客户端有很多[选择](https://xmpp.org/software/clients.html)，不过大多数都是渣。如果是WebSocket，用这个 [GitHub - processone/xmpp-websocket-client: Test XMPP Websocket client](https://github.com/processone/xmpp-websocket-client) 调试可以看到stanza，挺方便的。\n\n如果Mac用户报auth问题，可以打开`vim conf/ejabberd.yml`, `tls`配置成`false`\n![5202ee46.png](/img/32c16f22-9862-45e8-b15f-1b1eceb7b30f/5202ee46.png)\n\n#### 关于js lib\n打算用React Native写，lib选了 [GitHub - xmppjs/xmpp.js: XMPP for JavaScript](https://github.com/xmppjs/xmpp.js) 。当然 Web多用框架 Strophe.js。这儿有个简单比较[How do you compare to strophe.js · Issue #217 · xmppjs/xmpp.js · GitHub](https://github.com/xmppjs/xmpp.js/issues/217)\n\n### 其他资料\n\n- 简单介绍 [A friendly introduction to XMPP – blikoon](https://www.blikoontech.com/xmpp/xmpp-a-soft-friendly-introduction)\n\n- 官方协议很详细，例子也很形象。 [Extensible Messaging and Presence Protocol (XMPP): Core](https://xmpp.org/rfcs/rfc6120.html#tls)\n\n- 如何选择即时通讯应用的数据传输格式 [如何选择即时通讯应用的数据传输格式-其它分享/专项技术区 - 即时通讯开发者社区!](http://www.52im.net/thread-276-1-1.html)\n- 强列建议将Protobuf作为你的即时通讯应用数据传输格式 [强列建议将Protobuf作为你的即时通讯应用数据传输格式-其它分享/专项技术区 - 即时通讯开发者社区!](http://www.52im.net/thread-277-1-1.html) \n\n\n\n\n","categories":["Network"]}]