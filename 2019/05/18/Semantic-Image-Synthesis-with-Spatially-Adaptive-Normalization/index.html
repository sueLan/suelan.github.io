<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="RY&#39;s blog">
  <meta name="keyword" content="hexo-theme, vuejs">
  
    <link rel="shortcut icon" type="image/ico" href="[object Object]"/>
  
  <title>
    
      小白读论文:Semantic Image Synthesis with Spatially-Adaptive Normalization | RY &#39;s Blog
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/style.css">

  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
    
<script src="/js/qrious.js"></script>

  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
  
    
<script src="/js/local-search.js"></script>


<meta name="generator" content="Hexo 5.2.0"></head>
<div class="wechat-share">
  <img src="/css/images/logo.png" />
</div>
  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>RY 's Blog</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/series/" class="item-link">Series</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/project/" class="item-link">Projects</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
      
        <li class="menu-item menu-item-search right-list">
    <a role="button" class="popup-trigger">
        <i class="fa fa-search fa-fw"></i>
    </a>
</li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/series/" class="menu-link">Series</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/project/" class="menu-link">Projects</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
    
      <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
            <span class="search-icon">
                <i class="fa fa-search"></i>
            </span>
            <div class="search-input-container">
                <input autocomplete="off" autocapitalize="off"
                    placeholder="Please enter your keyword(s) to search." spellcheck="false"
                    type="search" class="search-input">
            </div>
            <span class="popup-btn-close">
                <i class="fa fa-times-circle"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>
    
  </div>
</header>

    <div id="article-banner">
  <h2>小白读论文:Semantic Image Synthesis with Spatially-Adaptive Normalization</h2>
  <p class="post-date">2019-05-18</p>
  <div class="arrow-down">
    <a href="javascript:;"></a>
  </div>
</div>
<main class="app-body flex-box">
  <!-- Article START -->
  <article class="post-article">
    <section class="markdown-content"><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=p5U4NgVGAwg&amp;feature=youtu.be">GauGAN: Changing Sketches into Photorealistic Masterpieces</a> 3月的时候，英伟达发布了一个视频挺火的： 你只要粗略勾勒简单的线条，AI就能生成逼真的写实图片。</p>
<a id="more"></a>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=p5U4NgVGAwg&amp;feature=youtu.be">GauGAN: Changing Sketches into Photorealistic Masterpieces</a> 3月的时候，英伟达发布了一个视频挺火的： 你只要粗略勾勒简单的线条，AI就能生成逼真的写实图片。</p>
<p><img src="https://camo.githubusercontent.com/a295a79daea9d1dd0cb16b48055607d0f17258b2/68747470733a2f2f6e766c6162732e6769746875622e696f2f53504144452f2f696d616765732f6f6365616e2e676966" alt="68747470733a2f2f6e766c6162732e6769746875622e696f2f53504144452f2f696d616765732f6f6365616e2e676966"><br><a target="_blank" rel="noopener" href="https://github.com/NVlabs/SPADE">GitHub地址</a><br>那它是怎么实现的呢？ 这个项目用的是GAN算法。</p>
<h2 id="GAN模型的任务："><a href="#GAN模型的任务：" class="headerlink" title="GAN模型的任务："></a>GAN模型的任务：</h2><p><strong>学习任务</strong> : 输入semantic segmentation mask, 合成 photorealistic images。 </p>
<p><code>Semantic Image</code> 是啥叻？ 直观上理解，如下图： </p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/31085460.png" alt="31085460.png"></p>
<p><code>Image segmentation</code>呢？<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Image segmentation is a computer vision task in which we label specific regions of an image according to what&#x27;s being shown. </span><br><span class="line">the goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented.</span><br></pre></td></tr></table></figure><br>如下图里的每个像素都被分类归属到不同的class<br><img src="https://www.jeremyjordan.me/content/images/2018/05/Screen-Shot-2018-05-17-at-9.02.15-PM.png" alt="Screen-Shot-2018-05-17-at-9.02.15-PM.png"><br><a target="_blank" rel="noopener" href="https://www.jeremyjordan.me/semantic-segmentation/#representing">图片来源</a></p>
<h2 id="SPADE-SPatially-Adaptive-DE-normalization"><a href="#SPADE-SPatially-Adaptive-DE-normalization" class="headerlink" title="SPADE:  SPatially-Adaptive (DE)normalization"></a>SPADE:  SPatially-Adaptive (DE)normalization</h2><h3 id="Normalizaing-training-sets"><a href="#Normalizaing-training-sets" class="headerlink" title="Normalizaing training sets"></a><a target="_blank" rel="noopener" href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=5c39b3d9b1544824a0675bd3f4ed78d5#/learn/content?type=detail&amp;id=2001701046">Normalizaing training sets</a></h3><p>首先，要了解一下Normalization的处理跟好处。</p>
<p><strong>处理</strong>： 以逻辑回归为例, 它的输入特征$X$,权重$W$, map函数如下<br>$$f(x) = \sum_{i=1}^{n}x_i*w_i$$</p>
<ol>
<li><p>先求输入的特征$x$的期望<br>$$\mu=\frac{1}{n}\sum_{i=1}^{n}x_i$$</p>
</li>
<li><p>再求$x$的方差</p>
</li>
</ol>
<p>$$\sigma^2 = \frac{1}{n} \sum_{i=1}^{n}(x_i - \mu)^2$$</p>
<ol start="3">
<li>再对输入特征做Normalization:<br>$$\frac{x-u}{\sigma^2}$$</li>
</ol>
<p><strong>好处</strong>是，经过处理的input特征值分布更集中均匀， 如下图的第三个坐标系，<br><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/826f032b.png" alt="826f032b.png"></p>
<p>对于损失函数，<br>$$J(w, x) = \frac{1}{m}\sum_{i=1}^{m}L(\hat{y}, y)$$<br>用梯度下降训练W，B的时候，Normalization后，形状更圆一些，更容易优化。无论初始从哪个位置开始，你都可以用较大的步长,比较容易找到适合的w,b的值，使得J（w,b)的值最小。<br><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/6ad7add2.png" alt="6ad7add2.png"></p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a><a target="_blank" rel="noopener" href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=f3e0afd9612c439a9f25d08040d39eab#/learn/content?type=detail&amp;id=2001701055">Batch Normalization</a></h3><p><a target="_blank" rel="noopener" href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=f3e0afd9612c439a9f25d08040d39eab#/learn/content?type=detail&amp;id=2001701055">改善深层神经网络：超参数调试、正则化以及优化 - 网易云课堂</a></p>
<p>Batch Norm不止normailize input feature;也可将normalization process应用在神经网络中的hidden layer上。</p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/747a0d26.png" alt="747a0d26.png"></p>
<p>比如对隐藏层$a^{[2]}$的输出进行正则化处理，加速下一层的参数$w^{[3]}$,$b^{[3]}$的训练速度。比如$a^{[2]}$层的神经单元分别是 $z^{(1)}, z^{(2)}…z^{(m)}$</p>
<p>对它的处理是</p>
<ol>
<li>求期望:<br>$$\mu = \frac{1}{m}\sum_{i=1}^{m}z_i$$</li>
<li>求方差:<br>$$\sigma^2 = \frac{1}{m}\sum_{i=1}^{m}(z_i - u)^2$$</li>
<li>norimal<br>$$z_i = \frac{z_i-u}{\sqrt{\sigma^2 + \varepsilon}}$$<br>加上$\varepsilon$是防止$\sigma^2$为0</li>
<li>加上 $\gamma$ 跟 $\beta$； <code>scale and shift the normalized value</code><br>$$\hat{z} = \gamma z_i + \beta$$</li>
</ol>
<p>$\gamma$ 跟 $\beta$ 也是参数，跟<code>w, b</code>一样在训练过程中迭代学习。 神经网络中他们也常在激活层之前进行Batch Normalization处理。 </p>
<h3 id="Spatially-Adaptive-normalization-SPADE"><a href="#Spatially-Adaptive-normalization-SPADE" class="headerlink" title="(Spatially-Adaptive normalization)SPADE"></a>(Spatially-Adaptive normalization)SPADE</h3><p>这篇论文提出自己的normalization思路，$h^i$是 i-th层的激活函数输出。<br>正则化处理:<br>$$\gamma_{c, y, x}^i (m)\frac{h_{n, c, y, x}^i - \mu_c^i}{\sigma_c^i} + \beta_{c, y, x}^{i}(m)$$</p>
<p>c: $c \epsilon C^i, C^i$是i-th层的channel个数<br>x: $x \epsilon W^i, W^i$是i-th层的宽<br>y: $y \epsilon H^i$, 高<br>m: segmentation mask m<br>$\gamma_{c, y, x}^i$跟$\beta_{c, y, x}^{i}$ 是函数，用卷积网络实现</p>
<p><strong>结构图</strong>： </p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/1ec7011c.png" alt="2f3fe4e8.png"></p>
<ul>
<li><code>3x3-Conv-k</code>是 3x3卷积层，有k个卷积filter, filter size 3x3</li>
<li><code>ReLU</code> 激活函数 </li>
<li>这里的<code>Resize</code>用的是<code>nearest-neighbor downsampling</code>，不细说了。</li>
</ul>
<p>它的处理流程是这样，对sematic image 进行resize、卷积、ReLU激活处理， 即$\gamma_{c, y, x}^i(m)$跟$\beta_{c, y, x}^{i}(m)$， 乘、加上<code>Batch Normalization</code>的输出数据$\frac{h_{n, c, y, x}^i - \mu_c^i}{\sigma_c^i}$ ，<br><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/ad9094aa.png" alt="ab4c46cb.png"></p>
<p>比起传统Batch Normal,SPADE的$\gamma_{c, y, x}^i(m)$跟$\beta_{c, y, x}^{i}(m)$是对sematic image做卷积操作，它在normalization过程中保存更多semantic的信息。论文中也认为这是SPADE效果更好的原因。</p>
<h4 id="相关代码："><a href="#相关代码：" class="headerlink" title="相关代码："></a>相关代码：</h4><p><code>normalization.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//  用传统的normalization method正则化激活函数输出</span><br><span class="line">  <span class="keyword">if</span> param_free_norm_type == <span class="string">&#x27;instance&#x27;</span>:</span><br><span class="line">      self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=<span class="literal">False</span>)</span><br><span class="line">  <span class="keyword">elif</span> param_free_norm_type == <span class="string">&#x27;syncbatch&#x27;</span>:</span><br><span class="line">      self.param_free_norm = SynchronizedBatchNorm2d(norm_nc, affine=<span class="literal">False</span>)</span><br><span class="line">  <span class="keyword">elif</span> param_free_norm_type == <span class="string">&#x27;batch&#x27;</span>:</span><br><span class="line">      self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=<span class="literal">False</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&#x27;%s is not a recognized param-free norm type in SPADE&#x27;</span></span><br><span class="line">                             % param_free_norm_type)</span><br><span class="line"></span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 构建gamma,beta函数, 卷积层实现</span><br><span class="line">self.mlp_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)</span><br><span class="line">self.mlp_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, segmap</span>):</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Part 1. generate parameter-free normalized activations</span></span><br><span class="line">      normalized = self.param_free_norm(x)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># ✨✨✨ Part 2. produce scaling and bias conditioned on semantic map</span></span><br><span class="line">      segmap = F.interpolate(segmap, size=x.size()[<span class="number">2</span>:], mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">      actv = self.mlp_shared(segmap)</span><br><span class="line">      gamma = self.mlp_gamma(actv)</span><br><span class="line">      beta = self.mlp_beta(actv)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># apply scale and bias</span></span><br><span class="line">      out = normalized * (<span class="number">1</span> + gamma) + beta</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h2 id="模型架构-GANs"><a href="#模型架构-GANs" class="headerlink" title="模型架构 GANs"></a>模型架构 GANs</h2><p>GANs由两部分组成： </p>
<ol>
<li>generator：负责合成写实风格的图片</li>
<li>discriminator: 负责找茬。认出这是张合成图片， 而不是真实的照片（or 写实图片）<h3 id="generator-架构"><a href="#generator-架构" class="headerlink" title="generator 架构"></a>generator 架构</h3></li>
</ol>
<p>首先</p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/d3313a9e.png" alt="d3313a9e.png"></p>
<p>这幅图里好多SPADE ResBlk啊，啥是SPADE ResBlk? 下面是它的结构图： </p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/630b2d2a.png" alt="630b2d2a.png"></p>
<ul>
<li><code>3x3-Conv-k</code>是 3x3卷积层，有k个卷积filter, filter size 3x3</li>
<li><code>ReLU</code> 激活函数</li>
<li>SPADE激活见上文分析</li>
</ul>
<p>那<code>ResBlk</code>呢？<br>这要从大名鼎鼎的残差网络说起 <a target="_blank" rel="noopener" href="https://mooc.study.163.com/learn/2001281004?tid=2001392030&amp;_trace_c_p_k2_=5c60eb2c1e0d4adbb2516471e9ebb431#/learn/content?type=detail&amp;id=2001728692">Residual block</a> （强烈推荐Andrew Ng公开课; 弄明白几个点： 1. Residual Block要解决什么问题;  2. 它的设计;  3. 为啥有效。 再回来看SPADE ResBlk)</p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/fd021761.png" alt="fd021761.png"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, fin, fout, opt</span>):</span></span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="comment"># Attributes</span></span><br><span class="line">    self.learned_shortcut = (fin != fout)</span><br><span class="line">    fmiddle = <span class="built_in">min</span>(fin, fout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create conv layers</span></span><br><span class="line">    self.conv_0 = nn.Conv2d(fin, fmiddle, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">    self.conv_1 = nn.Conv2d(fmiddle, fout, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> self.learned_shortcut:</span><br><span class="line">        self.conv_s = nn.Conv2d(fin, fout, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply spectral norm if specified</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;spectral&#x27;</span> <span class="keyword">in</span> opt.norm_G:</span><br><span class="line">        self.conv_0 = spectral_norm(self.conv_0)</span><br><span class="line">        self.conv_1 = spectral_norm(self.conv_1)</span><br><span class="line">        <span class="keyword">if</span> self.learned_shortcut:</span><br><span class="line">            self.conv_s = spectral_norm(self.conv_s)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ✨✨✨ define normalization layers</span></span><br><span class="line">    spade_config_str = opt.norm_G.replace(<span class="string">&#x27;spectral&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    self.norm_0 = SPADE(spade_config_str, fin, opt.semantic_nc)</span><br><span class="line">    self.norm_1 = SPADE(spade_config_str, fmiddle, opt.semantic_nc)</span><br><span class="line">    <span class="keyword">if</span> self.learned_shortcut:</span><br><span class="line">        self.norm_s = SPADE(spade_config_str, fin, opt.semantic_nc)</span><br></pre></td></tr></table></figure></p>
<h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><p>discriminator架构图。 (segmentation image,  image)作为输入， 任务是识别image是不是假的。<br><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/c5347e81.png" alt="c5347e81.png"></p>
<p>image encoder将图片encode生成均值向量跟方差向量， 计算出noise input输入给generator, segmentation mask也会通过SPADE ResBlks输入给generator。 generator生成image跟segmentation image contact后，再输入给discriminator, discriminator来辨别真伪。<br><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/f4341bd9.png" alt="f4341bd9.png"></p>
<h3 id="Training-Data"><a href="#Training-Data" class="headerlink" title="Training Data"></a>Training Data</h3><p>成对的segmentation masks跟真实图片。 (segmentation mask, real image) </p>
<h3 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h3><p>1.安装:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/NVlabs/SPADE.git</span><br><span class="line"><span class="built_in">cd</span> SPADE/</span><br></pre></td></tr></table></figure>
<p>2.这个项目依赖PyTorch 1.0跟python3.0+. 还依赖Synchronized-BatchNorm-PyTorch仓库。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// SPADE目录下</span><br><span class="line">cd models/networks/</span><br><span class="line">git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch</span><br><span class="line">cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .</span><br><span class="line">cd ../../</span><br></pre></td></tr></table></figure>
<p>3.用PyCharm打开这个项目, Preference -&gt; Project Interpreter -&gt; Project -&gt; Project Interpreter; 选python3.+的解释器, PyCharm会提示安装依赖的package。依赖包安装好后，如下图: </p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/ed349b19.png" alt="ed349b19.png"></p>
<p>4.下载提前训练好的模型<br><a target="_blank" rel="noopener" href="https://drive.google.com/file/d/12gvlTbMvUcJewQlSEaZdeb2CdOB-b8kQ/view">checkpoints.tar.gz - Google 云端硬盘</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd checkpoints</span><br><span class="line">tar xvf checkpoints.tar.gz</span><br><span class="line">cd ../</span><br><span class="line"></span><br><span class="line">ls</span><br><span class="line">// checkpoints目录如下:</span><br><span class="line">ade20k_pretrained     checkpoints.tar.gz    cityscapes_pretrained coco_pretrained</span><br></pre></td></tr></table></figure>
<p>5.编辑Configuration, 运行test.py脚本。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python test.py --name [<span class="built_in">type</span>]_pretrained --dataset_mode [dataset] --dataroot [path_to_dataset]</span><br></pre></td></tr></table></figure></p>
<p>参数： </p>
<ul>
<li><code>[type]_pretrained</code> 先渲染好的模型，coco_pretrained， ade20k_pretrained， cityscapes_pretrained中任选一个。</li>
<li><code>[dataset]</code> 填coco, ade20k, 或者cityscapes </li>
<li><code>[path_to_dataset]</code> 数据，比如./datasets/coco_stuff</li>
</ul>
<p>比如，我的参数:<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--name</span><br><span class="line">coco_pretrained</span><br><span class="line">--dataset_mode</span><br><span class="line">coco</span><br><span class="line">--dataroot</span><br><span class="line">./datasets/coco_stuff</span><br><span class="line">--gpu_ids</span><br><span class="line">-1</span><br></pre></td></tr></table></figure><br>输出的路径： <code>./results/[type]_pretrained/</code> 我的是<code>./results/coco_pretrained/</code></p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/412b71cb.png" alt="412b71cb.png"></p>
<p>这几张图片真是看的我有点失望，再看看下图论文的图片。 果然论文的图片都是精挑细选, 套路满满。</p>
<p><img src="/img/7c2b5608-840f-411f-bcd4-024df194b0de/b037261d.png" alt="b037261d.png"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jeremyjordan.me/semantic-segmentation/">An overview of semantic image segmentation.</a></li>
</ul>
</section>
    <!-- Tags START -->
    
      <div class="tags">
        <span>Tags:</span>
        
  <a href="/tags#Image Segment" >
    <span class="tag-code">Image Segment</span>
  </a>

      </div>
    
    <!-- Tags END -->
    <!-- NAV START -->
    
  <div class="nav-container">
    <!-- reverse left and right to put prev and next in a more logic postition -->
    
      <a class="nav-left" href="/2019/05/12/The-Weights-of-the-YOLO-Neural-Network/">
        <span class="nav-arrow">← </span>
        
          The Weights of the YOLO Neural Network
        
      </a>
    
    
      <a class="nav-right" href="/2019/05/20/LeetCode-650-2-Keys-Keyboard/">
        
          LeetCode:650. 2 Keys Keyboard
        
        <span class="nav-arrow"> →</span>
      </a>
    
  </div>

    <!-- NAV END -->
    <!-- 打赏 START -->
  
    <!-- 二维码 START -->
    
      <div class="qrcode">
        <canvas id="share-qrcode"></canvas>
        <p class="notice">scan qr code and share this article</p>
      </div>
    
    <!-- 二维码 END -->
    
      <!-- Utterances START -->
      <div id="utterances"></div>
      <script src="https://utteranc.es/client.js"
        repo="null"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async></script>    
      <!-- Utterances END -->
    
  </article>
  <!-- Article END -->
  <!-- Catalog START -->
  
    <aside class="catalog-container">
  <div class="toc-main">
    <strong class="toc-title">Catalog</strong>
    
      <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#GAN%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%BB%E5%8A%A1%EF%BC%9A"><span class="toc-nav-text">GAN模型的任务：</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#SPADE-SPatially-Adaptive-DE-normalization"><span class="toc-nav-text">SPADE:  SPatially-Adaptive (DE)normalization</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Normalizaing-training-sets"><span class="toc-nav-text">Normalizaing training sets</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Batch-Normalization"><span class="toc-nav-text">Batch Normalization</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Spatially-Adaptive-normalization-SPADE"><span class="toc-nav-text">(Spatially-Adaptive normalization)SPADE</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%9B%B8%E5%85%B3%E4%BB%A3%E7%A0%81%EF%BC%9A"><span class="toc-nav-text">相关代码：</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84-GANs"><span class="toc-nav-text">模型架构 GANs</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#generator-%E6%9E%B6%E6%9E%84"><span class="toc-nav-text">generator 架构</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Discriminator"><span class="toc-nav-text">Discriminator</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Training-Data"><span class="toc-nav-text">Training Data</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Test"><span class="toc-nav-text">Test</span></a></li></ol></li></ol>
    
  </div>
</aside>
  
  <!-- Catalog END -->
</main>

<script>
  (function () {
    var url = 'https://suelan.github.io/2019/05/18/Semantic-Image-Synthesis-with-Spatially-Adaptive-Normalization/';
    var banner = 'undefined'
    if (banner !== '' && banner !== 'undefined' && banner !== 'null') {
      $('#article-banner').css({
        'background-image': 'url(' + banner + ')'
      })
    } else {
      $('#article-banner').geopattern(url)
    }
    $('.header').removeClass('fixed-header')

    // error image
    $(".markdown-content img").on('error', function() {
      $(this).attr('src', '/css/images/error_icon.png')
      $(this).css({
        'cursor': 'default'
      })
    })

    // zoom image
    $(".markdown-content img").on('click', function() {
      var src = $(this).attr('src')
      if (src !== '/css/images/error_icon.png') {
        var imageW = $(this).width()
        var imageH = $(this).height()

        var zoom = ($(window).width() * 0.95 / imageW).toFixed(2)
        zoom = zoom < 1 ? 1 : zoom
        zoom = zoom > 2 ? 2 : zoom
        var transY = (($(window).height() - imageH) / 2).toFixed(2)

        $('body').append('<div class="image-view-wrap"><div class="image-view-inner"><img src="'+ src +'" /></div></div>')
        $('.image-view-wrap').addClass('wrap-active')
        $('.image-view-wrap img').css({
          'width': `${imageW}`,
          'transform': `translate3d(0, ${transY}px, 0) scale3d(${zoom}, ${zoom}, 1)`
        })
        $('html').css('overflow', 'hidden')

        $('.image-view-wrap').on('click', function() {
          $(this).remove()
          $('html').attr('style', '')
        })
      }
    })
  })();
</script>


  <script>
    var qr = new QRious({
      element: document.getElementById('share-qrcode'),
      value: document.location.href
    });
  </script>






    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2022 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a target="_blank" rel="noopener" href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      hljs.configure({useBR: true});
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->


<script src="/js/script.js"></script>


  </body>
</html>